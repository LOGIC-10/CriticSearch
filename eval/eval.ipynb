{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook:\n",
    "## Author: William Diaz\n",
    "### Artificial Agents @ JHU\n",
    "**Evaluation for the Critic Agent Using a modified version of the hotpotQA dataset.**\n",
    "***We drop all context for the questions, instead opting to use the search and reasoning capabilities of each model we evaluate against.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamdiaz/Downloads/agents_project/AgentFactory/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "GPT4O_API_KEY = os.getenv(\"GPT4O_API_KEY\")\n",
    "\n",
    "PERPLEXITY_BASE_URL = \"https://api.perplexity.ai\"\n",
    "GPT4O_BASE_URL = \"https://api.openai.com/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 566M/566M [01:10<00:00, 8.01MB/s] \n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:05<00:00, 8.98MB/s]\n",
      "Downloading data: 100%|██████████| 46.2M/46.2M [00:05<00:00, 8.22MB/s]\n",
      "Generating train split: 100%|██████████| 90447/90447 [00:11<00:00, 7892.51 examples/s] \n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:00<00:00, 8157.17 examples/s] \n",
      "Generating test split: 100%|██████████| 7405/7405 [00:00<00:00, 10007.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"hotpot_qa\", \"fullwiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'question', 'answer', 'type', 'level', 'supporting_facts', 'context'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will sample from the validation dataset, though this should not matter\n",
    "validation_data = dataset['validation']\n",
    "sample_size = 200\n",
    "random_indices = random.sample(range(len(validation_data)), sample_size)\n",
    "sampled_data = [validation_data[i] for i in random_indices]\n",
    "sampled_data[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output CSV\n",
    "output_file = \"results.csv\"\n",
    "fieldnames = [\n",
    "    \"id\",\n",
    "    \"question\",\n",
    "    \"ground_truth_answer\",\n",
    "    \"perplexity_answer\",\n",
    "    \"binary_success\",\n",
    "    \"context\",\n",
    "    \"type\",\n",
    "    \"level\",\n",
    "    \"supporting_facts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's already a partial file\n",
    "processed_ids = set()\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            processed_ids.add(row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_backoff_retry(func, max_retries=5, initial_wait=1):\n",
    "    \"\"\"Utility for exponential backoff retries.\"\"\"\n",
    "    wait = initial_wait\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except Exception as e:\n",
    "            if i == max_retries - 1:\n",
    "                raise e\n",
    "            time.sleep(wait)\n",
    "            wait *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_perplexity(question):\n",
    "    \"\"\"Query the perplexity API with a given question.\"\"\"\n",
    "    def do_request():\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an artificial intelligence assistant and you need to \"\n",
    "                    \"engage in a helpful, detailed, polite conversation with a user.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        json_payload = {\n",
    "            \"model\": \"llama-3.1-sonar-large-128k-online\",\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"{PERPLEXITY_BASE_URL}/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        resp_json = response.json()\n",
    "        # Assuming response JSON structure: {'choices': [{'message': {'content': 'answer'}}], ...}\n",
    "        # If different, adjust accordingly.\n",
    "        return resp_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    answer = exponential_backoff_retry(do_request)\n",
    "    # Sleep to avoid rate limits\n",
    "    time.sleep(1)\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
