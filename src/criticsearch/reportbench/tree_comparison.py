import json
from collections import defaultdict
import spacy
from scipy.optimize import linear_sum_assignment
import numpy as np

# 加载语义模型
nlp = spacy.load("en_core_web_md")

def parse_tree(node, current_depth=0, levels=None):
    if levels is None:
        levels = defaultdict(list)
    if 'title' in node:
        levels[current_depth].append(node['title'])
    if 'children' in node:
        for child in node['children']:
            parse_tree(child, current_depth + 1, levels)
    return levels

def text_similarity(text1, text2):
    doc1 = nlp(text1)
    doc2 = nlp(text2)
    return doc1.similarity(doc2)

def level_similarity(nodes_A, nodes_B):
    if not nodes_A and not nodes_B:
        return 1.0  # 双方无节点视为完全匹配
    sim_matrix = np.zeros((len(nodes_A), len(nodes_B)))
    for i, a in enumerate(nodes_A):
        for j, b in enumerate(nodes_B):
            sim_matrix[i][j] = text_similarity(a, b)
    row_ind, col_ind = linear_sum_assignment(-sim_matrix)
    total_sim = sim_matrix[row_ind, col_ind].sum()
    max_possible = max(len(nodes_A), len(nodes_B))
    return total_sim / max_possible if max_possible > 0 else 0

def tree_similarity(std_tree, student_tree, depth_decay=0.8, alpha=0.3, beta=0.02, gamma=0.02):
    # 解析层级
    std_levels = parse_tree(std_tree)
    student_levels = parse_tree(student_tree)
    
    max_std_depth = max(std_levels.keys(), default=0)
    max_student_depth = max(student_levels.keys(), default=0)
    max_depth = max(max_std_depth, max_student_depth)
    
    total_score = 0.0
    total_weight = 0.0
    missing_layers = 0
    redundant_layers = 0
    
    # 遍历每个可能的层级（从0到最大深度）
    for depth in range(max_depth + 1):
        in_std = depth in std_levels
        in_student = depth in student_levels
        weight = 1.0 / (depth_decay ** depth)  # 深层权重更高
        
        # 层级存在性检查
        if in_std and not in_student:
            missing_layers += 1
            continue  # 学生缺失该层，跳过权重累加
        elif not in_std and in_student:
            redundant_layers += 1
            continue  # 学生多出该层，跳过权重累加
        
        # 获取该层节点
        nodes_std = std_levels.get(depth, [])
        nodes_student = student_levels.get(depth, [])
        m, n = len(nodes_std), len(nodes_student)
        
        # 计算语义相似度
        semantic_score = level_similarity(nodes_std, nodes_student)
        
        # 节点数量差异惩罚
        if m == 0:
            num_penalty = 0  # 标准无节点时不惩罚
        else:
            num_diff = abs(m - n)
            num_penalty = alpha * (num_diff / m)
        structure_coeff = max(0, 1 - num_penalty)
        
        # 层级得分
        layer_score = semantic_score * structure_coeff
        total_score += layer_score * weight
        total_weight += weight
    
    # 计算加权平均得分
    weighted_avg = total_score / total_weight if total_weight > 0 else 0
    
    # 总结构惩罚
    structure_penalty = beta * missing_layers + gamma * redundant_layers
    final_score = weighted_avg * max(0, 1 - structure_penalty)
    
    return round(final_score, 2)


if __name__ == "__main__":

    # 加载你的JSON数据
    std_tree = {'title': '2024_CrowdStrike-related_IT_outages', 'children': [{'title': 'Preface'}, {'title': 'Background'}, {'title': 'Outage', 'children': [{'title': 'Remedy'}]}, {'title': 'Impact', 'children': [{'title': 'CrowdStrike liability'}, {'title': 'Air transport', 'children': [{'title': 'Oceania'}, {'title': 'Asia'}, {'title': 'Europe'}, {'title': 'Middle East and North Africa'}, {'title': 'North America'}]}, {'title': 'Finance'}, {'title': 'Government'}, {'title': 'Ground transport'}, {'title': 'Healthcare'}, {'title': 'Media and communications'}, {'title': 'Retail'}, {'title': 'Other sectors'}]}, {'title': 'Response', 'children': [{'title': 'Political'}, {'title': 'Industry'}, {'title': 'Criminal'}]}, {'title': 'Analysis', 'children': [{'title': 'Cause'}, {'title': 'Centralisation and homogeneity'}, {'title': 'IT practices'}, {'title': 'Operating system design and antitrust enforcement'}]}]}  # 你的第一个树结构
    student_tree = {} # should be generated by the model

    similarity = tree_similarity(std_tree, student_tree)
    print(f"广度评分（百分制）: {similarity * 100:.1f}分")
