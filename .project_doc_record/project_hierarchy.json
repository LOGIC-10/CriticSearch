{
  "eval.py": [],
  "report_benchmark.py": [
    {
      "type": "ClassDef",
      "name": "ReportBenchmark",
      "md_content": [
        "**ReportBenchmark**: The function of ReportBenchmark is to generate benchmark evaluations for reports by processing input data, performing fact extraction, running factual question answering, and optionally visualizing the results.\n\n**attributes**:\n· json_path: Path to the input JSON file.\n· agent: Instance of BaseAgent used for rendering prompts and handling communication with the model.\n· breadth_gt: Ground truth representing the breadth of the report, extracted from the input JSON.\n· article_content: The content of the report, extracted from the input file.\n· sections: List of sections in the article, parsed from the markdown content.\n· user_query: A query string for generating a comprehensive report about the breadth ground truth.\n\n**Code Description**:  \nThe `ReportBenchmark` class is designed to assist in the evaluation of reports through a series of steps that include extracting data, querying models, and presenting results. The class interacts with an external `BaseAgent` instance, which is used to render prompts and handle the communication with a model (such as GPT-4).\n\n- The `__init__` method initializes the class by taking a JSON input file path and an optional user query. It processes the input file to extract both the breadth ground truth (a structured JSON representation of the report) and the article's content (extracted from markdown format). The sections of the article are parsed from the markdown content, and if no user query is provided, a default query is generated based on the title from the breadth ground truth.\n\n- The `run_fact_extraction` method performs the fact extraction for each section of the report. It calls a helper function `process_section`, which uses a retry mechanism (attempting up to 10 times) to send each section's content to the model for fact extraction. The method returns a list of extracted facts for each section.\n\n- The `run_factualqa` method prepares a query to evaluate the factual accuracy of the report using the breadth ground truth and an optional depth ground truth. It loads and renders a specific template for factual question answering, then passes the generated prompt to the model via the `common_chat` method of the `BaseAgent`. The result of the evaluation is returned.\n\n- The `generate_benchmark_item` method combines the fact extraction and factual evaluation steps to build a full benchmark item. It calls `run_fact_extraction` to retrieve fact extraction results and then processes these results into a table format using the `parse_tagged_data_to_table` method. If visualization is requested, it generates a DataFrame from the parsed data and exports it as a CSV file. It returns a dictionary containing the title of the report, the breadth ground truth, and the fact extraction results.\n\n- The `parse_tagged_data_to_table` method is used to process the fact extraction results. It expects the input to be a list of strings containing tagged data (e.g., questions, answers, and format descriptions). It extracts the relevant information from each entry and returns it in a table format (list of dictionaries). If a CSV path is provided, the table is saved as a CSV file.\n\n- The `verify_extraction_meaningful` method, which is not yet implemented, is meant to verify if the fact extraction results are meaningful and correct.\n\nThe `ReportBenchmark` class is called by other parts of the project, such as in `report_evaluation.py` where an instance of `ReportBenchmark` is used in conjunction with a `student_report` to compare and evaluate a student's report against the generated benchmark.\n\n**Note**: The `ReportBenchmark` class relies on the `BaseAgent` class for interacting with models, and its functionality is highly dependent on how the model responds to the prompts. If a section fails to be processed after multiple attempts, it is skipped with a warning. The `verify_extraction_meaningful` method is currently a placeholder and has not been implemented.\n\n**Output Example**:\nAn example return value from `generate_benchmark_item` might look like this:\n\n```python\n{\n    \"title\": \"Comprehensive Report on Environmental Impact\",\n    \"breadth_gt\": {\n        \"title\": \"Comprehensive Report on Environmental Impact\",\n        \"sections\": [...]\n    },\n    \"fact_extraction\": [\n        [\n            {\"Question\": \"What is the environmental impact of deforestation?\", \"Format\": \"Short answer\", \"Answer\": \"Deforestation contributes to habitat loss and increased carbon emissions.\"},\n            {\"Question\": \"How can we mitigate deforestation?\", \"Format\": \"Short answer\", \"Answer\": \"Reforestation and sustainable forestry practices are key methods.\"}\n        ],\n        [\n            {\"Question\": \"What is the carbon footprint of industrialization?\", \"Format\": \"Short answer\", \"Answer\": \"Industrialization increases carbon emissions significantly.\"},\n            {\"Question\": \"How can industrialization reduce its carbon footprint?\", \"Format\": \"Short answer\", \"Answer\": \"By adopting green technologies and energy-efficient processes.\"}\n        ]\n    ]\n}\n```"
      ],
      "code_start_line": 26,
      "code_end_line": 182,
      "params": [],
      "have_return": true,
      "code_content": "class ReportBenchmark:\n    \"\"\"\n    A benchmarking class for generating report evaluations.\n    Builds ground truths for report breadth & depth using two modules,\n    and calls prompts (fact_extraction, outline_generation) via BaseAgent's common_chat.\n    Also includes a method for FactualQA evaluation using a model (e.g., GPT-4o).\n    \"\"\"\n\n    def __init__(self, json_input_path, user_query=None):\n        self.json_path = json_input_path\n        self.agent = BaseAgent()\n        self.breadth_gt = extractDirectoryTree(\n            self.json_path\n        )  # Extract breadth ground truth，得到一个json结构的广度树\n        self.article_content = extractMarkdownContent(self.json_path)\n        self.sections = extract_markdown_sections(self.article_content)\n        self.user_query = (\n            f\"Generate a comprehensive long report about {self.breadth_gt.get('title', '')}\"\n            if user_query is None\n            else user_query\n        )\n\n    def run_fact_extraction(self):\n        \"\"\"\n        使用 self.sections 中的每个 markdown 文本调用 fact_extraction，\n        并行执行，返回一个包含各 section 响应的列表。\n        如果对某个 section 10 次尝试后都失败，则发出警告并跳过该 section。\n        \"\"\"\n\n        def process_section(section_text):\n            @retry(stop=stop_after_attempt(10), wait=wait_fixed(1), reraise=True)\n            def attempt():\n                template_str = self.agent.load_template(\"fact_extraction.txt\")\n                data = {\n                    \"wiki_text\": section_text,\n                    \"UserQuery\": self.user_query,\n                }\n                prompt = self.agent.render_template(template_str, data)\n                response = self.agent.common_chat(usr_prompt=prompt)\n                if not isinstance(response, list):\n                    if not response.strip():\n                        raise Exception(\"Empty response received from common_chat\")\n                    try:\n                        candidate = json.loads(response)\n                        print(candidate)\n                        if isinstance(candidate, list):\n                            return candidate\n                    except Exception as e:\n                        raise Exception(\"Section response conversion failed\") from e\n                    raise Exception(\"Section response is not a list\")\n                return response\n\n            try:\n                return attempt()\n            except Exception as e:\n                print(\n                    f\"Warning: Failed to process section after 10 attempts. Skipping this section. Error: {e}\"\n                )\n                return None\n\n        with ThreadPoolExecutor() as executor:\n            raw_results = list(executor.map(process_section, self.sections))\n        # Filter out any sections that failed after 10 attempts\n        results = [result for result in raw_results if result is not None]\n        return results  # 返回 List[List[str]]，每个元素是一个 section 的 fact extraction 结果\n\n    def run_factualqa(self):\n        # Load and render a template \"factual_qa.txt\" for FactualQA evaluation.\n        # Pass Query, BreadthGT (converted to JSON string) and DepthGT.\n        template_str = self.agent.load_template(\"factual_qa.txt\")\n        data = {\n            \"Query\": self.user_query,  # Updated from self.query to self.user_query\n            \"BreadthGT\": json.dumps(self.breadth_gt),\n            \"DepthGT\": self.depth_gt,\n        }\n        prompt = self.agent.render_template(template_str, data)\n        response = self.agent.common_chat(usr_prompt=prompt)\n        return response\n\n    def generate_benchmark_item(self, visualization=False):\n        # Build both GTs and then run all benchmark evaluations.\n        fact_extraction_result = self.run_fact_extraction()\n        final_parsed_data = []\n        for section in fact_extraction_result:\n            parsed_data = self.parse_tagged_data_to_table(section)\n            final_parsed_data.append(parsed_data)\n\n        if visualization:\n            # Merge all parsed data into single list\n            merged_data = []\n            for parsed_data in final_parsed_data:\n                merged_data.extend(parsed_data)\n            # Create DataFrame and export CSV\n            df = pd.DataFrame(merged_data)\n            csv_file = \"visualization.csv\"\n            df.to_csv(csv_file, index=False)\n            print(\"Visualization DataFrame:\")\n            print(df)\n\n        return {\n            \"title\": self.breadth_gt.get(\"title\", \"\"),\n            \"breadth_gt\": self.breadth_gt,\n            \"fact_extraction\": final_parsed_data,\n        }\n\n    def parse_tagged_data_to_table(self, entries, csv_path=None):\n        \"\"\"\n        Parse a list of strings with tagged data and convert them into a table.\n\n        Each entry in the list is expected to contain:\n        - A question enclosed between </question> and </question>\n        - A format description enclosed between </constrained_format> and </constrained_format>\n        - An answer enclosed in </answer> and </answer>\n\n        Parameters:\n            entries (list of str): List of strings with tagged content.\n            csv_path (str): Optional file path to save CSV.\n\n        Returns:\n            list of dict: List of dictionaries with parsed data.\n        \"\"\"\n\n        parsed_data = []\n\n        for entry in entries:\n            # Extract question\n            question_match = re.search(r\"</question>(.*?)</question>\", entry)\n            question = question_match.group(1).strip() if question_match else \"\"\n\n            # Extract format description\n            format_match = re.search(\n                r\"</constrained_format>(.*?)</constrained_format>\", entry\n            )\n            format_desc = format_match.group(1).strip() if format_match else \"\"\n\n            # Extract answer\n            answer_match = re.search(r\"</answer>(.*?)</answer>\", entry)\n            answer = answer_match.group(1).strip() if answer_match else \"\"\n\n            # Append to parsed data\n            parsed_data.append(\n                {\"Question\": question, \"Format\": format_desc, \"Answer\": answer}\n            )\n\n        # Save to CSV if path is provided and ends with '.csv'\n        if csv_path and csv_path.endswith(\".csv\"):\n            # Create DataFrame\n            df = pd.DataFrame(parsed_data)\n            df.to_csv(csv_path, index=False)\n            print(f\"Table saved to {csv_path}\")\n            return df\n\n        return parsed_data\n\n    def verify_extraction_meaningful(self):\n        # Check if the fact extraction result is meaningful enough and correct.\n        pass\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_evaluation.py",
        "report_evaluation.py/ReportEvaluation/__init__"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the ReportBenchmark class, setting up necessary attributes and processing input data.\n\n**parameters**: The parameters of this Function.\n· json_input_path: A string representing the file path to the input JSON file that contains the data to be processed.\n· user_query: An optional string that allows the user to specify a custom query for report generation.\n\n**Code Description**: The __init__ method is the constructor for the ReportBenchmark class. It is responsible for initializing the instance by setting up various attributes and processing the input data provided through the parameters. \n\nWhen an instance of ReportBenchmark is created, the method takes two parameters: json_input_path and an optional user_query. The json_input_path is used to specify the location of a JSON file that contains the data necessary for generating a report. The user_query parameter allows for customization of the report generation prompt; if it is not provided, a default query is generated based on the title extracted from the JSON data.\n\nThe method begins by assigning the json_input_path to the instance variable self.json_path. It then creates an instance of the BaseAgent class, which is stored in self.agent. The BaseAgent class serves as a foundational component for managing conversations and performing searches, which may be utilized later in the report generation process.\n\nNext, the method calls the extractDirectoryTree function, passing the json_input_path as an argument. This function processes the JSON file to extract a breadth ground truth structure, which is then stored in the instance variable self.breadth_gt. The extractDirectoryTree function is crucial as it constructs a hierarchical representation of the data, filtering out unnecessary nodes based on specific criteria.\n\nFollowing this, the method calls extractMarkdownContent with the json_input_path to read the content of the JSON file and convert it into a markdown format. The resulting markdown content is stored in self.article_content. This content is essential for generating the report as it provides the textual basis from which sections can be derived.\n\nThe method then calls extract_markdown_sections, passing the article content to extract distinct sections based on header lines in the markdown text. The extracted sections are stored in self.sections, which can be utilized later for report generation.\n\nFinally, the user_query is processed. If it is not provided, a default query is generated that requests a comprehensive report based on the title found in the breadth ground truth. This default query is constructed using the title extracted from self.breadth_gt, ensuring that the report generation is contextually relevant.\n\nOverall, the __init__ method establishes the foundational elements required for the ReportBenchmark instance to function effectively, setting up the necessary data structures and preparing for subsequent operations.\n\n**Note**: It is important to ensure that the input JSON file is correctly formatted and contains the necessary fields for the extractDirectoryTree and extractMarkdownContent functions to operate as expected. Any inconsistencies in the data may lead to errors during processing."
      ],
      "code_start_line": 34,
      "code_end_line": 46,
      "params": [
        "self",
        "json_input_path",
        "user_query"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, json_input_path, user_query=None):\n        self.json_path = json_input_path\n        self.agent = BaseAgent()\n        self.breadth_gt = extractDirectoryTree(\n            self.json_path\n        )  # Extract breadth ground truth，得到一个json结构的广度树\n        self.article_content = extractMarkdownContent(self.json_path)\n        self.sections = extract_markdown_sections(self.article_content)\n        self.user_query = (\n            f\"Generate a comprehensive long report about {self.breadth_gt.get('title', '')}\"\n            if user_query is None\n            else user_query\n        )\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "extract_ground_truth.py/extractDirectoryTree",
        "extract_ground_truth.py/extractMarkdownContent",
        "extract_ground_truth.py/extract_markdown_sections",
        "src/criticsearch/base_agent.py/BaseAgent"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "run_fact_extraction",
      "md_content": [
        "**run_fact_extraction**: The function of run_fact_extraction is to extract facts from sections of markdown text by using the fact extraction agent in a parallelized manner and returning a list of extracted facts for each section.\n\n**parameters**:\n· None\n\n**Code Description**: \nThe `run_fact_extraction` function is a method within a class that performs fact extraction on a set of markdown sections stored in `self.sections`. The function proceeds as follows:\n\n1. **Helper function (process_section)**: \n   The function contains a nested helper function `process_section`, which handles the fact extraction for each individual section of markdown text. This function attempts to extract facts by calling the `fact_extraction` method 10 times, using the `retry` decorator to handle temporary failures. If the attempt fails after 10 retries, a warning is printed, and the section is skipped.\n\n2. **Fact Extraction Process**:\n   - The `process_section` function attempts to load a template called `\"fact_extraction.txt\"`, which is used to generate a prompt for the fact extraction agent.\n   - It then prepares the data with the section text (`section_text`) and a user query (`self.user_query`), rendering the prompt with this data.\n   - A call is made to the agent's `common_chat` method with the generated prompt. The response from this call is expected to be in JSON format, and if successful, it is parsed into a list of facts.\n   - If the response is invalid (either empty or not in the expected format), an exception is raised to trigger the retry mechanism.\n\n3. **Parallel Execution**:\n   The `ThreadPoolExecutor` is used to parallelize the execution of the `process_section` function for each section in `self.sections`. This helps improve efficiency, especially when dealing with large numbers of sections.\n\n4. **Result Filtering**:\n   After attempting to process all sections, the results are filtered to exclude any sections that failed after the maximum number of retries (10 attempts). The function then returns a list of valid fact extraction results.\n\nThe function is called within `generate_benchmark_item`, where it processes sections of text and extracts facts in preparation for further analysis and benchmarking. The results of `run_fact_extraction` are parsed and used to generate a benchmark evaluation.\n\n**Note**: \n- The retry mechanism is crucial for handling transient issues when interacting with the fact extraction agent.\n- The function assumes that the agent's responses are in a specific format, and any deviation will result in an exception.\n- If a section fails after the maximum retry attempts, it will be skipped, and no facts will be extracted for that section.\n\n**Output Example**: \nGiven a list of sections, the returned value could look like the following:\n\n```\n[\n  [\"Fact 1 from section 1\", \"Fact 2 from section 1\"],\n  [\"Fact 1 from section 2\", \"Fact 2 from section 2\", \"Fact 3 from section 2\"],\n  [\"Fact 1 from section 3\"]\n]\n```\n\nIn this case, each element in the outer list corresponds to the extracted facts from each section, with each inner list containing the facts for a particular section. Sections that failed extraction after 10 attempts will not be present in the output."
      ],
      "code_start_line": 48,
      "code_end_line": 90,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def run_fact_extraction(self):\n        \"\"\"\n        使用 self.sections 中的每个 markdown 文本调用 fact_extraction，\n        并行执行，返回一个包含各 section 响应的列表。\n        如果对某个 section 10 次尝试后都失败，则发出警告并跳过该 section。\n        \"\"\"\n\n        def process_section(section_text):\n            @retry(stop=stop_after_attempt(10), wait=wait_fixed(1), reraise=True)\n            def attempt():\n                template_str = self.agent.load_template(\"fact_extraction.txt\")\n                data = {\n                    \"wiki_text\": section_text,\n                    \"UserQuery\": self.user_query,\n                }\n                prompt = self.agent.render_template(template_str, data)\n                response = self.agent.common_chat(usr_prompt=prompt)\n                if not isinstance(response, list):\n                    if not response.strip():\n                        raise Exception(\"Empty response received from common_chat\")\n                    try:\n                        candidate = json.loads(response)\n                        print(candidate)\n                        if isinstance(candidate, list):\n                            return candidate\n                    except Exception as e:\n                        raise Exception(\"Section response conversion failed\") from e\n                    raise Exception(\"Section response is not a list\")\n                return response\n\n            try:\n                return attempt()\n            except Exception as e:\n                print(\n                    f\"Warning: Failed to process section after 10 attempts. Skipping this section. Error: {e}\"\n                )\n                return None\n\n        with ThreadPoolExecutor() as executor:\n            raw_results = list(executor.map(process_section, self.sections))\n        # Filter out any sections that failed after 10 attempts\n        results = [result for result in raw_results if result is not None]\n        return results  # 返回 List[List[str]]，每个元素是一个 section 的 fact extraction 结果\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/generate_benchmark_item"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "process_section",
      "md_content": [
        "**process_section**: The function of process_section is to process a given section of text by extracting relevant facts using a predefined template and handling potential errors through retries.\n\n**parameters**: The parameters of this Function.\n· section_text: A string containing the text of the section to be processed.\n\n**Code Description**: The process_section function is designed to handle the extraction of facts from a specified section of text. It utilizes a retry mechanism to attempt the extraction process multiple times in case of failure. The function begins by defining an inner function, attempt, which is decorated with a retry strategy that allows it to retry up to 10 times with a fixed wait time of 1 second between attempts.\n\nWithin the attempt function, the following steps are executed:\n1. A template string is loaded from a file named \"fact_extraction.txt\" using the agent's load_template method.\n2. A data dictionary is created, containing the section text and a user query.\n3. The template is rendered with the data to create a prompt for the agent.\n4. The agent's common_chat method is called with the generated prompt to obtain a response.\n\nThe response is then validated:\n- If the response is not a list, it checks if the response is empty, raising an exception if so.\n- It attempts to parse the response as JSON. If parsing fails, an exception is raised indicating that the conversion failed.\n- If the parsed response is not a list, another exception is raised.\n\nIf the attempt function is successful, it returns the candidate list. If all attempts fail, the outer try-except block catches the exception, logs a warning message, and returns None, indicating that the section could not be processed.\n\n**Note**: It is important to ensure that the template file \"fact_extraction.txt\" is accessible and correctly formatted. Additionally, the user_query should be defined in the context where this function is called to ensure accurate processing.\n\n**Output Example**: A possible return value from the function could be a list of extracted facts, such as:\n[\n    {\"fact\": \"Fact 1\", \"source\": \"Source A\"},\n    {\"fact\": \"Fact 2\", \"source\": \"Source B\"}\n]"
      ],
      "code_start_line": 55,
      "code_end_line": 84,
      "params": [
        "section_text"
      ],
      "have_return": true,
      "code_content": "        def process_section(section_text):\n            @retry(stop=stop_after_attempt(10), wait=wait_fixed(1), reraise=True)\n            def attempt():\n                template_str = self.agent.load_template(\"fact_extraction.txt\")\n                data = {\n                    \"wiki_text\": section_text,\n                    \"UserQuery\": self.user_query,\n                }\n                prompt = self.agent.render_template(template_str, data)\n                response = self.agent.common_chat(usr_prompt=prompt)\n                if not isinstance(response, list):\n                    if not response.strip():\n                        raise Exception(\"Empty response received from common_chat\")\n                    try:\n                        candidate = json.loads(response)\n                        print(candidate)\n                        if isinstance(candidate, list):\n                            return candidate\n                    except Exception as e:\n                        raise Exception(\"Section response conversion failed\") from e\n                    raise Exception(\"Section response is not a list\")\n                return response\n\n            try:\n                return attempt()\n            except Exception as e:\n                print(\n                    f\"Warning: Failed to process section after 10 attempts. Skipping this section. Error: {e}\"\n                )\n                return None\n",
      "name_column": 12,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "attempt",
      "md_content": [
        "**attempt**: The function of attempt is to execute a series of operations to extract facts based on a user query and a specific section of text.\n\n**parameters**: The parameters of this Function.\n· section_text: The text from which facts are to be extracted, provided as input to the function.\n· self: Refers to the instance of the class in which the attempt function is defined, allowing access to its attributes and methods.\n\n**Code Description**: The attempt function is designed to facilitate the extraction of factual information by performing several key operations. Initially, it loads a template for fact extraction using the `load_template` method from the `BaseAgent` class, which retrieves the content of a file named \"fact_extraction.txt\". This template serves as a structured format for the subsequent query.\n\nNext, the function constructs a data dictionary containing two key pieces of information: `wiki_text`, which holds the content of the section being analyzed, and `UserQuery`, which contains the user's query. This data is then passed to the `render_template` method, which processes the template string with the provided data, effectively creating a prompt that is tailored to the user's request.\n\nThe generated prompt is then sent to the `common_chat` method, which interacts with the conversational model to obtain a response. This method is crucial as it manages the communication with the model, sending the prompt and receiving the output.\n\nUpon receiving the response, the function checks if the response is a list. If the response is not a list or is empty, appropriate exceptions are raised to handle these scenarios. If the response is valid and in the expected format, it is returned as the output of the attempt function.\n\nThe attempt function is integral to the overall functionality of the application, as it combines template loading, data rendering, and model interaction to achieve its goal of fact extraction. It relies on the methods of the `BaseAgent` class, specifically `load_template`, `render_template`, and `common_chat`, to perform its operations effectively.\n\n**Note**: It is essential to ensure that the `section_text` and `self.user_query` are properly defined and contain relevant information before invoking the attempt function. Additionally, error handling is implemented to manage cases where the response from the model does not meet the expected criteria.\n\n**Output Example**: A possible return value from the attempt function could be a list of extracted facts, such as:\n[\n    {\"fact\": \"The capital of France is Paris.\"},\n    {\"fact\": \"The largest planet in our solar system is Jupiter.\"}\n]"
      ],
      "code_start_line": 57,
      "code_end_line": 76,
      "params": [],
      "have_return": true,
      "code_content": "            def attempt():\n                template_str = self.agent.load_template(\"fact_extraction.txt\")\n                data = {\n                    \"wiki_text\": section_text,\n                    \"UserQuery\": self.user_query,\n                }\n                prompt = self.agent.render_template(template_str, data)\n                response = self.agent.common_chat(usr_prompt=prompt)\n                if not isinstance(response, list):\n                    if not response.strip():\n                        raise Exception(\"Empty response received from common_chat\")\n                    try:\n                        candidate = json.loads(response)\n                        print(candidate)\n                        if isinstance(candidate, list):\n                            return candidate\n                    except Exception as e:\n                        raise Exception(\"Section response conversion failed\") from e\n                    raise Exception(\"Section response is not a list\")\n                return response\n",
      "name_column": 16,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "run_factualqa",
      "md_content": [
        "**run_factualqa**: The function of run_factualqa is to load a template for FactualQA evaluation, populate it with user query and ground truth data, and obtain a response from a conversational model.\n\n**parameters**: The parameters of this Function.\n· self: The instance of the class that contains the run_factualqa method, which holds the necessary attributes for execution.\n\n**Code Description**: The run_factualqa function is designed to facilitate the evaluation of factual questions by leveraging a template-based approach. It begins by loading a specific template file named \"factual_qa.txt\" using the load_template method from the BaseAgent class. This method retrieves the content of the template, which serves as a structured format for the subsequent evaluation process.\n\nNext, the function prepares a data dictionary that includes:\n- \"Query\": This is populated with the user's query, specifically accessed through the self.user_query attribute. This represents the updated user input that the function will evaluate.\n- \"BreadthGT\": This is a JSON string representation of the ground truth data for breadth, obtained from self.breadth_gt. This data is crucial for assessing the breadth of knowledge related to the user's query.\n- \"DepthGT\": This is directly taken from self.depth_gt, representing the ground truth data for depth.\n\nThe function then calls the render_template method, passing the loaded template string and the data dictionary. This method processes the template and replaces placeholders with the corresponding values from the data dictionary, resulting in a fully rendered prompt.\n\nFollowing the rendering process, the function invokes the common_chat method, providing the rendered prompt as the usr_prompt parameter. This method is responsible for sending the prompt to a conversational model and receiving a response. The common_chat function manages the interaction with the model, ensuring that the prompt is processed correctly and that the response is relevant to the user's query.\n\nFinally, the run_factualqa function returns the response obtained from the common_chat method, which encapsulates the model's answer to the user's query based on the provided ground truth data.\n\nThis function is integral to the overall evaluation process in the application, as it combines template loading, data preparation, and model interaction to deliver accurate responses to factual questions.\n\n**Note**: It is important to ensure that the attributes self.user_query, self.breadth_gt, and self.depth_gt are properly initialized and contain valid data before invoking this function. Any issues with these attributes may lead to errors during template rendering or model interaction.\n\n**Output Example**: A possible return value from the run_factualqa function could be a structured response such as: \n{\n  \"answer\": \"The capital of France is Paris.\",\n  \"confidence\": 0.95,\n  \"source\": \"Wikipedia\"\n} \nThis output indicates the model's answer to the user's query, along with a confidence score and the source of the information."
      ],
      "code_start_line": 92,
      "code_end_line": 103,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def run_factualqa(self):\n        # Load and render a template \"factual_qa.txt\" for FactualQA evaluation.\n        # Pass Query, BreadthGT (converted to JSON string) and DepthGT.\n        template_str = self.agent.load_template(\"factual_qa.txt\")\n        data = {\n            \"Query\": self.user_query,  # Updated from self.query to self.user_query\n            \"BreadthGT\": json.dumps(self.breadth_gt),\n            \"DepthGT\": self.depth_gt,\n        }\n        prompt = self.agent.render_template(template_str, data)\n        response = self.agent.common_chat(usr_prompt=prompt)\n        return response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "generate_benchmark_item",
      "md_content": [
        "**generate_benchmark_item**: The function of generate_benchmark_item is to perform benchmark evaluations by running fact extraction, parsing the results into structured tables, and optionally visualizing the data in a CSV format.\n\n### Function Overview\nThe `generate_benchmark_item` method is responsible for orchestrating the benchmark process within the ReportBenchmark class. It performs several key tasks, including running a fact extraction process, parsing the extracted data into structured tables, and optionally exporting the results into a CSV file for visualization. The method returns a dictionary that includes the title of the benchmark, the breadth ground truth (GT), and the parsed fact extraction results.\n\n### Parameters\n- **visualization** (optional, default: `False`): A boolean flag that determines whether to visualize the parsed data in the form of a CSV file. If set to `True`, the method will merge the parsed data, create a Pandas DataFrame, and export it to a CSV file named `visualization.csv`.\n\n### Workflow and Logic\n1. **Fact Extraction**: \n   The method begins by invoking the `run_fact_extraction()` function, which performs parallelized fact extraction on a set of markdown sections. This function returns a list of fact extraction results for each section of text.\n\n2. **Parsing Data**: \n   Once the fact extraction results are obtained, the method proceeds to parse the extracted facts. For each section of the fact extraction result, the method calls the `parse_tagged_data_to_table()` function. This function transforms the tagged data into structured table formats, and the results are collected into a list.\n\n3. **Visualization (Optional)**: \n   If the `visualization` parameter is set to `True`, the method combines the parsed data from all sections into a single list. It then creates a Pandas DataFrame using this merged data and exports it to a CSV file called `visualization.csv`. Additionally, the DataFrame is printed for visualization purposes.\n\n4. **Return Value**: \n   The method returns a dictionary containing the following keys:\n   - **title**: The title of the breadth ground truth (GT).\n   - **breadth_gt**: The breadth ground truth object itself.\n   - **fact_extraction**: The parsed fact extraction results for all sections.\n\n### Example Output\nThe returned dictionary would typically look as follows:\n\n```python\n{\n    \"title\": \"Benchmark Title\",\n    \"breadth_gt\": { ... },  # Breadth ground truth object\n    \"fact_extraction\": [\n        [{\"Question\": \"What is the capital of France?\", \"Format\": \"text\", \"Answer\": \"Paris\"}],\n        [{\"Question\": \"What is 2 + 2?\", \"Format\": \"number\", \"Answer\": \"4\"}]\n    ]\n}\n```\n\n### Notes:\n- The `run_fact_extraction()` method is crucial in this workflow as it retrieves the factual data from the markdown sections, while `parse_tagged_data_to_table()` organizes this data into a usable format.\n- If the `visualization` flag is set to `True`, the resulting CSV file will contain a tabular representation of the extracted and parsed facts, which can be used for further analysis or visualization."
      ],
      "code_start_line": 105,
      "code_end_line": 129,
      "params": [
        "self",
        "visualization"
      ],
      "have_return": true,
      "code_content": "    def generate_benchmark_item(self, visualization=False):\n        # Build both GTs and then run all benchmark evaluations.\n        fact_extraction_result = self.run_fact_extraction()\n        final_parsed_data = []\n        for section in fact_extraction_result:\n            parsed_data = self.parse_tagged_data_to_table(section)\n            final_parsed_data.append(parsed_data)\n\n        if visualization:\n            # Merge all parsed data into single list\n            merged_data = []\n            for parsed_data in final_parsed_data:\n                merged_data.extend(parsed_data)\n            # Create DataFrame and export CSV\n            df = pd.DataFrame(merged_data)\n            csv_file = \"visualization.csv\"\n            df.to_csv(csv_file, index=False)\n            print(\"Visualization DataFrame:\")\n            print(df)\n\n        return {\n            \"title\": self.breadth_gt.get(\"title\", \"\"),\n            \"breadth_gt\": self.breadth_gt,\n            \"fact_extraction\": final_parsed_data,\n        }\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction",
        "report_benchmark.py/ReportBenchmark/parse_tagged_data_to_table"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "parse_tagged_data_to_table",
      "md_content": [
        "**parse_tagged_data_to_table**: The function of parse_tagged_data_to_table is to parse a list of strings containing tagged data and convert them into a structured table format.\n\n**parameters**: The parameters of this Function.\n· entries: List of strings with tagged content, where each string contains a question, a format description, and an answer, each enclosed in specific tags.\n· csv_path: Optional string that specifies the file path to save the parsed data as a CSV file.\n\n**Code Description**: The parse_tagged_data_to_table function processes a list of strings, each representing an entry with tagged data. The function uses regular expressions to extract the question, format description, and answer from each entry. The extracted data is then organized into a list of dictionaries, where each dictionary corresponds to an entry and contains keys for \"Question\", \"Format\", and \"Answer\".\n\nIf a valid csv_path is provided (i.e., it ends with '.csv'), the function will create a Pandas DataFrame from the parsed data and save it to the specified CSV file. This feature allows for easy export and further analysis of the data in a tabular format. If no csv_path is provided, the function simply returns the list of dictionaries containing the parsed data.\n\nThis function is called by the generate_benchmark_item method within the ReportBenchmark class. In this context, it is used to process the results of a fact extraction operation. The generate_benchmark_item method collects the fact extraction results, iterates through each section, and calls parse_tagged_data_to_table to convert the tagged data into a structured format. The results from each call are aggregated into a final list, which can be further processed or visualized as needed.\n\n**Note**: When using this function, ensure that the entries provided are correctly formatted with the required tags. Additionally, if saving to a CSV file, verify that the provided path is valid and ends with '.csv' to avoid errors.\n\n**Output Example**: A possible return value from the function could look like this:\n[\n    {\"Question\": \"What is the capital of France?\", \"Format\": \"text\", \"Answer\": \"Paris\"},\n    {\"Question\": \"What is 2 + 2?\", \"Format\": \"number\", \"Answer\": \"4\"}\n]"
      ],
      "code_start_line": 131,
      "code_end_line": 178,
      "params": [
        "self",
        "entries",
        "csv_path"
      ],
      "have_return": true,
      "code_content": "    def parse_tagged_data_to_table(self, entries, csv_path=None):\n        \"\"\"\n        Parse a list of strings with tagged data and convert them into a table.\n\n        Each entry in the list is expected to contain:\n        - A question enclosed between </question> and </question>\n        - A format description enclosed between </constrained_format> and </constrained_format>\n        - An answer enclosed in </answer> and </answer>\n\n        Parameters:\n            entries (list of str): List of strings with tagged content.\n            csv_path (str): Optional file path to save CSV.\n\n        Returns:\n            list of dict: List of dictionaries with parsed data.\n        \"\"\"\n\n        parsed_data = []\n\n        for entry in entries:\n            # Extract question\n            question_match = re.search(r\"</question>(.*?)</question>\", entry)\n            question = question_match.group(1).strip() if question_match else \"\"\n\n            # Extract format description\n            format_match = re.search(\n                r\"</constrained_format>(.*?)</constrained_format>\", entry\n            )\n            format_desc = format_match.group(1).strip() if format_match else \"\"\n\n            # Extract answer\n            answer_match = re.search(r\"</answer>(.*?)</answer>\", entry)\n            answer = answer_match.group(1).strip() if answer_match else \"\"\n\n            # Append to parsed data\n            parsed_data.append(\n                {\"Question\": question, \"Format\": format_desc, \"Answer\": answer}\n            )\n\n        # Save to CSV if path is provided and ends with '.csv'\n        if csv_path and csv_path.endswith(\".csv\"):\n            # Create DataFrame\n            df = pd.DataFrame(parsed_data)\n            df.to_csv(csv_path, index=False)\n            print(f\"Table saved to {csv_path}\")\n            return df\n\n        return parsed_data\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/generate_benchmark_item"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "verify_extraction_meaningful",
      "md_content": [
        "**verify_extraction_meaningful**: The function of verify_extraction_meaningful is to check if the fact extraction result is meaningful enough and correct.\n\n**parameters**: This function does not accept any parameters.\n\n**Code Description**:  \nThe function `verify_extraction_meaningful` is defined within a class, but the exact functionality is not implemented in the provided code. The comment above the function suggests its intended purpose: to validate whether the result of a fact extraction process is both meaningful and correct. However, the function body is empty (`pass`), indicating that the actual logic for verifying the extraction has yet to be defined. The comment implies that this function is designed to evaluate the quality and accuracy of extracted facts, possibly comparing them to predefined criteria or assessing their relevance to the context of the application.\n\n**Note**:  \nSince the function body has not been implemented, it does not currently perform any actions. Developers will need to implement the specific logic to evaluate the meaningfulness and correctness of the extracted facts when integrating this function into the application."
      ],
      "code_start_line": 180,
      "code_end_line": 182,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def verify_extraction_meaningful(self):\n        # Check if the fact extraction result is meaningful enough and correct.\n        pass\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "extract_ground_truth.py": [
    {
      "type": "FunctionDef",
      "name": "filter_node",
      "md_content": [
        "**filter_node**: The function of filter_node is to recursively filter a data structure, removing any dictionary entries that contain an 'id' with the letter \"s\" in it.\n\n**parameters**: The parameters of this Function.\n· node: The input data structure, which can be a dictionary, list, or any other data type.\n\n**Code Description**: The filter_node function processes a given input, which can be a dictionary, list, or other data types. If the input is a dictionary, the function checks for the presence of an 'id' key. If the value associated with 'id' contains the letter \"s\" (case insensitive), the function returns None, effectively filtering out that dictionary. If the dictionary does not contain an 'id' with \"s\", the function iterates through its items, recursively calling filter_node on each value. It constructs a new dictionary containing only the filtered values.\n\nIf the input is a list, the function iterates through each item, applying the same filtering logic. Any item that results in None is excluded from the new list. For any other data type that is not a dictionary or list, the function simply returns the input unchanged.\n\nThis function is called within the extractDirectoryTree function, which reads a JSON file and loads it into a data structure. After loading the data, extractDirectoryTree calls filter_node to filter the JSON tree based on the 'id' values. The filtered data is then used to build a tree structure that contains only the relevant layers and titles. This ensures that the final output is a clean and valid JSON structure, free from any unwanted entries.\n\n**Note**: It is important to ensure that the input to filter_node is either a dictionary or a list for the function to operate correctly. Any other data types will be returned as-is without modification.\n\n**Output Example**: Given an input of the following structure:\n{\n    \"id\": \"example1\",\n    \"title\": \"Sample Title\",\n    \"children\": [\n        {\n            \"id\": \"sample2\",\n            \"title\": \"Child Title\"\n        },\n        {\n            \"id\": \"example3\",\n            \"title\": \"Another Child\"\n        }\n    ]\n}\nThe output after applying filter_node would be:\n{\n    \"id\": \"example1\",\n    \"title\": \"Sample Title\",\n    \"children\": [\n        {\n            \"id\": \"example3\",\n            \"title\": \"Another Child\"\n        }\n    ]\n}"
      ],
      "code_start_line": 4,
      "code_end_line": 24,
      "params": [
        "node"
      ],
      "have_return": true,
      "code_content": "def filter_node(node):\n    # Recursively filter node: if a dict contains an 'id' with \"s\" in it, skip it.\n    if isinstance(node, dict):\n        if 'id' in node and ('s' in node['id'].lower()):\n            return None\n        new_dict = {}\n        for key, value in node.items():\n            filtered = filter_node(value)\n            # if filtering a list or dict returns a falsey (None), we still want to include keys like title/text\n            if filtered is not None:\n                new_dict[key] = filtered\n        return new_dict\n    elif isinstance(node, list):\n        new_list = []\n        for item in node:\n            filtered_item = filter_node(item)\n            if filtered_item is not None:\n                new_list.append(filtered_item)\n        return new_list\n    else:\n        return node\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "extract_ground_truth.py/extractDirectoryTree"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "build_tree",
      "md_content": [
        "**build_tree**: The function of build_tree is to recursively construct a tree-like structure from a given input, preserving only the \"title\" of each node and its optional \"children.\"\n\n**parameters**:\n· node: The input node which can either be a dictionary, a list, or a nested structure containing nodes that are to be processed.\n\n**Code Description**:  \nThe `build_tree` function is a recursive function designed to process a hierarchical structure (usually a nested combination of dictionaries and lists) and build a simplified tree. The tree is structured to retain only the \"title\" field of each node and optionally include \"children\" if present.\n\n- If the input `node` is a dictionary, the function checks if the dictionary contains a \"title\" field. If it does, a new node is created with the \"title\" field. If the dictionary also contains a \"content\" field that is a list, the function iterates through the items in the \"content\" list, recursively calling `build_tree` on each item. If a child node returns a non-None value, it is added as a child to the current node. If there are child nodes, they are included under the \"children\" key.\n- If the input `node` is a dictionary without a \"title\" field but containing a \"content\" field, the function will recursively process the \"content\" list and return the constructed children under the \"children\" key.\n- If the input `node` is a list, the function processes each element of the list, recursively calling `build_tree` on each item. The resulting valid child trees are collected and returned as a list. If no valid child trees are found, the function returns `None`.\n- In cases where the input is neither a dictionary nor a list, the function will return `None`.\n\nThis function is mainly used to extract the hierarchical structure from more complex JSON data, ensuring that only the \"title\" and the \"children\" (if applicable) are preserved in the final output.\n\nThe `build_tree` function is called by the `extractDirectoryTree` function in the project. Specifically, `extractDirectoryTree` reads the original JSON data, filters it, and then passes the filtered data to `build_tree` to simplify the structure. After constructing the tree, it is validated to ensure the result is valid JSON before returning the final tree.\n\n**Note**: The function relies on the presence of the \"title\" and \"content\" fields in the dictionary nodes to construct the tree. It assumes that any node with a \"title\" and optionally a \"content\" list should be processed. It does not process other fields, so any additional data in the input nodes will be discarded.\n\n**Output Example**:  \nGiven an input like this:\n```json\n{\n  \"title\": \"Root\",\n  \"content\": [\n    {\n      \"title\": \"Child 1\",\n      \"content\": [\n        {\"title\": \"Subchild 1.1\"}\n      ]\n    },\n    {\n      \"title\": \"Child 2\"\n    }\n  ]\n}\n```\n\nThe output will look like:\n```json\n{\n  \"title\": \"Root\",\n  \"children\": [\n    {\n      \"title\": \"Child 1\",\n      \"children\": [\n        {\"title\": \"Subchild 1.1\"}\n      ]\n    },\n    {\n      \"title\": \"Child 2\"\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 26,
      "code_end_line": 66,
      "params": [
        "node"
      ],
      "have_return": true,
      "code_content": "def build_tree(node):\n    # Recursively build a tree with only \"title\" (and optional \"children\")\n    if isinstance(node, dict):\n        if \"title\" in node:\n            new_node = {\"title\": node[\"title\"]}\n            if \"content\" in node and isinstance(node[\"content\"], list):\n                children = []\n                for child in node[\"content\"]:\n                    child_tree = build_tree(child)\n                    if child_tree:\n                        if isinstance(child_tree, list):\n                            children.extend(child_tree)\n                        else:\n                            children.append(child_tree)\n                if children:\n                    new_node[\"children\"] = children\n            return new_node\n        else:\n            if \"content\" in node and isinstance(node[\"content\"], list):\n                children = []\n                for child in node[\"content\"]:\n                    child_tree = build_tree(child)\n                    if child_tree:\n                        if isinstance(child_tree, list):\n                            children.extend(child_tree)\n                        else:\n                            children.append(child_tree)\n                if children:\n                    return {\"children\": children}\n            return None\n    elif isinstance(node, list):\n        trees = []\n        for item in node:\n            tree = build_tree(item)\n            if tree:\n                if isinstance(tree, list):\n                    trees.extend(tree)\n                else:\n                    trees.append(tree)\n        return trees if trees else None\n    return None\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "extract_ground_truth.py/extractDirectoryTree"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "build_markdown",
      "md_content": [
        "**build_markdown**: The function of build_markdown is to recursively construct a markdown text representation from a given JSON structure, focusing on titles and sentence texts while ignoring references.\n\n**parameters**: The parameters of this Function.\n· parameter1: node - This is the JSON object or list that contains the data to be converted into markdown format. It can be a dictionary representing a node in the JSON structure or a list of such nodes.\n· parameter2: level - This is an integer that indicates the current depth level in the JSON hierarchy. It is used to determine the number of hash symbols (#) to prepend to the title for proper markdown formatting. The default value is 1.\n\n**Code Description**: The build_markdown function processes a JSON-like structure to generate a markdown string. It starts by initializing an empty string `md`. If the input `node` is a dictionary, the function checks for the presence of a \"title\" key. If found, it appends the title to the markdown string, prefixed by a number of hash symbols corresponding to the current level. Next, it looks for a \"sentences\" key, which should contain a list of sentence objects. For each sentence, if it has a \"text\" key, the text is stripped of leading and trailing whitespace and added to the markdown string. \n\nIf the node contains a \"content\" key, which is expected to be a list of child nodes, the function recursively calls itself for each child, increasing the level by one to reflect the deeper hierarchy. If the input node is a list, the function iterates through each item, calling itself with the same level to ensure consistent markdown formatting.\n\nThis function is called by the extractMarkdownContent function, which reads a JSON file and loads its content into a Python dictionary. It then invokes build_markdown with this data to convert it into markdown text, which is returned instead of being saved to a file. This relationship highlights the utility of build_markdown as a helper function that transforms structured data into a human-readable format.\n\n**Note**: When using this function, ensure that the input JSON structure adheres to the expected format, particularly the presence of \"title\" and \"sentences\" keys, to avoid unexpected results or errors.\n\n**Output Example**: Given a JSON input like the following:\n```json\n{\n    \"title\": \"Sample Title\",\n    \"sentences\": [\n        {\"text\": \"This is the first sentence.\"},\n        {\"text\": \"This is the second sentence.\"}\n    ],\n    \"content\": [\n        {\n            \"title\": \"Subsection Title\",\n            \"sentences\": [\n                {\"text\": \"This is a sentence in a subsection.\"}\n            ]\n        }\n    ]\n}\n```\nThe output of the build_markdown function would be:\n```\n# Sample Title\n\nThis is the first sentence.\n\nThis is the second sentence.\n\n## Subsection Title\n\nThis is a sentence in a subsection.\n```"
      ],
      "code_start_line": 68,
      "code_end_line": 87,
      "params": [
        "node",
        "level"
      ],
      "have_return": true,
      "code_content": "def build_markdown(node, level=1):\n    \"\"\"\n    Recursively builds a markdown text from the JSON content.\n    Only includes 'title' and text from 'sentences', ignoring references.\n    \"\"\"\n    md = \"\"\n    if isinstance(node, dict):\n        if \"title\" in node:\n            md += (\"#\" * level) + \" \" + node[\"title\"] + \"\\n\\n\"\n        if \"sentences\" in node and isinstance(node[\"sentences\"], list):\n            for sentence in node[\"sentences\"]:\n                if \"text\" in sentence:\n                    md += sentence[\"text\"].strip() + \"\\n\\n\"\n        if \"content\" in node and isinstance(node[\"content\"], list):\n            for child in node[\"content\"]:\n                md += build_markdown(child, level+1)\n    elif isinstance(node, list):\n        for item in node:\n            md += build_markdown(item, level)\n    return md\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "extract_ground_truth.py/extractMarkdownContent"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "extractDirectoryTree",
      "md_content": [
        "**extractDirectoryTree**: The function of extractDirectoryTree is to process a JSON file, filter its data based on specific criteria, construct a tree-like structure containing only relevant information, and validate its correctness.\n\n**parameters**:\n- input_file_path: The file path to the original JSON file that is to be processed.\n\n**Code Description**:\nThe `extractDirectoryTree` function is designed to process and structure data from a JSON file into a clean, hierarchical tree. The function performs the following steps:\n\n1. **Reading the Input File**: The function begins by opening and reading the provided JSON file (`input_file_path`). The contents of the file are loaded into a variable called `data` using the `json.load()` function, which converts the JSON text into a Python data structure (e.g., dictionaries, lists).\n\n2. **Filtering the Data**: The loaded `data` is passed to the `filter_node` function. This function recursively filters the input data, removing any dictionary entries that contain an 'id' field with the letter \"s\" in it. This ensures that only relevant nodes are retained, based on the 'id' values. The output of this step is stored in the `filtered_data` variable.\n\n3. **Building the Tree Structure**: The filtered data is then passed to the `build_tree` function. This function processes the data to create a tree-like structure, where each node in the tree contains only the \"title\" field and, if applicable, its \"children\". The `build_tree` function recursively constructs this simplified structure, preserving the hierarchy of nodes and ensuring that only the essential information (titles and children) is retained. The output of this step is stored in the `tree_structure` variable.\n\n4. **Validating the JSON Structure**: The constructed tree is then serialized into a JSON string using `json.dumps()`. This is followed by an attempt to deserialize it back using `json.loads()`. This validation ensures that the resulting structure is a valid JSON object. If an error occurs during this process, a `ValueError` is raised with a detailed error message indicating that the JSON structure is invalid.\n\n5. **Returning the Validated Tree**: If the tree structure is valid, it is returned as the output of the function. The return value is a clean and well-structured JSON object containing the relevant hierarchy, which is ready for further use or processing.\n\nIn the context of the project, the `extractDirectoryTree` function is called within the `__init__` method of the `ReportBenchmark` class in the `report_benchmark.py` file. The `ReportBenchmark` class utilizes `extractDirectoryTree` to extract a breadth ground truth from a JSON file, which is then used to generate a report. The result from `extractDirectoryTree` is stored in the `breadth_gt` variable and used in subsequent processing steps to create a comprehensive report.\n\n**Note**: It is important that the input JSON file is properly formatted and contains the necessary fields, such as \"id\" and \"title\", for the `filter_node` and `build_tree` functions to work as expected. Any inconsistencies in the data could lead to errors or incomplete processing.\n\n**Output Example**: \nGiven an input JSON like:\n\n```json\n{\n  \"id\": \"example1\",\n  \"title\": \"Root Title\",\n  \"content\": [\n    {\n      \"id\": \"example2\",\n      \"title\": \"Child 1 Title\",\n      \"content\": [\n        {\n          \"id\": \"example3\",\n          \"title\": \"Subchild 1 Title\"\n        }\n      ]\n    },\n    {\n      \"id\": \"example4\",\n      \"title\": \"Child 2 Title\"\n    }\n  ]\n}\n```\n\nAfter processing through `extractDirectoryTree`, the output might look like:\n\n```json\n{\n  \"title\": \"Root Title\",\n  \"children\": [\n    {\n      \"title\": \"Child 1 Title\",\n      \"children\": [\n        {\n          \"title\": \"Subchild 1 Title\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Child 2 Title\"\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 89,
      "code_end_line": 108,
      "params": [
        "input_file_path"
      ],
      "have_return": true,
      "code_content": "def extractDirectoryTree(input_file_path):\n    # Read original JSON file\n    with open(input_file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    # Filter JSON tree based on node \"id\"\n    filtered_data = filter_node(data)\n\n    # Build tree containing only the layer structure and titles\n    tree_structure = build_tree(filtered_data)\n\n    # Validate that tree_structure is valid JSON by serializing and deserializing it\n    try:\n        s = json.dumps(tree_structure)\n        valid_tree = json.loads(s)\n    except Exception as e:\n        raise ValueError(\"Invalid JSON structure: \" + str(e))\n    \n    # Return the valid JSON structure without saving to a file\n    return valid_tree\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py",
        "report_benchmark.py/ReportBenchmark/__init__"
      ],
      "reference_who": [
        "extract_ground_truth.py/filter_node",
        "extract_ground_truth.py/build_tree"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "extractMarkdownContent",
      "md_content": [
        "**extractMarkdownContent**: The function of extractMarkdownContent is to read a JSON file, convert its content into a markdown text representation, and return the result.\n\n**parameters**:\n· parameter1: input_file_path - A string representing the path to the input JSON file.\n\n**Code Description**: \nThe extractMarkdownContent function is responsible for reading the contents of a given JSON file and converting it into a markdown text format. The function operates in two key stages:\n\n1. **Reading the JSON File**: The function first opens the file specified by the `input_file_path` parameter. Using Python’s `json` module, it loads the content of the file into a dictionary. This dictionary is assumed to follow a structure that is compatible with markdown generation, particularly containing keys like \"title\", \"sentences\", and \"content\".\n\n2. **Generating the Markdown**: After loading the JSON data, the function calls the `build_markdown` helper function to generate the markdown text. This function recursively processes the JSON structure, focusing on titles and sentence texts while ignoring any references. It starts by processing the top-level data and works through nested content as needed. The resulting markdown text is returned as the output.\n\nThe `build_markdown` function, which is invoked within extractMarkdownContent, processes the JSON data to produce the markdown text. This function expects the input data to have specific keys (\"title\", \"sentences\", and \"content\") and handles them accordingly by formatting titles with appropriate markdown headers and including sentence text as paragraph content.\n\n**Note**: \n- The input JSON file must adhere to the expected structure, with keys like \"title\", \"sentences\", and \"content\" present for the function to perform correctly.\n- The output will be a markdown text representation of the data in the JSON file, not a saved file.\n\n**Output Example**:\nGiven the following JSON structure:\n```json\n{\n    \"title\": \"Sample Title\",\n    \"sentences\": [\n        {\"text\": \"This is the first sentence.\"},\n        {\"text\": \"This is the second sentence.\"}\n    ],\n    \"content\": [\n        {\n            \"title\": \"Subsection Title\",\n            \"sentences\": [\n                {\"text\": \"This is a sentence in a subsection.\"}\n            ]\n        }\n    ]\n}\n```\n\nThe resulting markdown text will be:\n```\n# Sample Title\n\nThis is the first sentence.\n\nThis is the second sentence.\n\n## Subsection Title\n\nThis is a sentence in a subsection.\n```"
      ],
      "code_start_line": 110,
      "code_end_line": 119,
      "params": [
        "input_file_path"
      ],
      "have_return": true,
      "code_content": "def extractMarkdownContent(input_file_path):\n    # Read original JSON file\n    with open(input_file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    # Build markdown text from JSON structure\n    md_text = build_markdown(data)\n    \n    # Return markdown text instead of saving to a file\n    return md_text\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py",
        "report_benchmark.py/ReportBenchmark/__init__"
      ],
      "reference_who": [
        "extract_ground_truth.py/build_markdown"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "extract_markdown_sections",
      "md_content": [
        "**extract_markdown_sections**: The function of extract_markdown_sections is to extract sections from a given markdown text based on header lines.\n\n**parameters**: The parameters of this Function.\n· md_text: A string containing the markdown text from which sections will be extracted.\n\n**Code Description**: The extract_markdown_sections function processes a string of markdown text to identify and separate sections based on header lines, which are indicated by lines starting with the \"#\" character. The function initializes an empty list called sections to hold the extracted sections and another list called current_section to accumulate lines of the current section being processed.\n\nThe function iterates through each line of the input markdown text. When it encounters a line that starts with \"#\", it checks if there are any lines accumulated in current_section. If there are, it joins those lines into a single string, strips any leading or trailing whitespace, and appends this string to the sections list. It then resets current_section to start accumulating lines for the new section.\n\nAfter processing all lines, if there are any remaining lines in current_section, it joins them into a string and appends it to the sections list. Finally, the function returns the sections list, which contains all the extracted sections as separate strings.\n\nThis function is called within the ReportBenchmark class's __init__ method in the report_benchmark.py file. Specifically, it is used to process the content of a markdown file that is extracted using the extractMarkdownContent function. The resulting sections are stored in the sections attribute of the ReportBenchmark instance, which can then be utilized for generating reports or further analysis.\n\n**Note**: It is important to ensure that the input markdown text is well-formed, with headers properly defined, to achieve accurate section extraction.\n\n**Output Example**: An example of the output from the extract_markdown_sections function might look like this when provided with a markdown text containing multiple sections:\n\n```\n[\n    \"# Section 1\\nContent of section 1.\",\n    \"# Section 2\\nContent of section 2.\",\n    \"# Section 3\\nContent of section 3.\"\n]\n```"
      ],
      "code_start_line": 121,
      "code_end_line": 137,
      "params": [
        "md_text"
      ],
      "have_return": true,
      "code_content": "def extract_markdown_sections(md_text):\n    \"\"\"\n    Extract markdown sections based on header lines.\n    遇到新的标题（以#开头）则开始新的 section，\n    返回一个包含各 section 的列表，每个 section 为一个字符串。\n    \"\"\"\n    sections = []\n    current_section = []\n    for line in md_text.splitlines():\n        if line.strip().startswith(\"#\"):\n            if current_section:\n                sections.append(\"\\n\".join(current_section).strip())\n                current_section = []\n        current_section.append(line)\n    if current_section:\n        sections.append(\"\\n\".join(current_section).strip())\n    return sections\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py",
        "report_benchmark.py/ReportBenchmark/__init__"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "report_evaluation.py": [
    {
      "type": "ClassDef",
      "name": "ReportEvaluation",
      "md_content": [
        "**ReportEvaluation**: The function of ReportEvaluation is to evaluate a student report based on various benchmarks and generate scores for specific criteria such as breadth, depth, and factual accuracy.\n\n**attributes**: \n· report_benchmark: An instance of the ReportBenchmark class used to obtain ground truth data for evaluation.\n· student_report: A string representing the student's report that will be evaluated.\n\n**Code Description**: \n\nThe `ReportEvaluation` class is responsible for evaluating a student's report using predefined benchmarks. It takes an instance of `ReportBenchmark` and a student's report as input parameters and performs multiple evaluations based on these inputs.\n\n- The `__init__` method initializes the class with two parameters: `report_benchmark` (an instance of the `ReportBenchmark` class) and `student_report` (a string containing the student’s report). It stores these inputs as instance attributes for use in the evaluation methods.\n  \n- The `examinees_outline_generation` method generates a student outline by interacting with the `ReportBenchmark`'s agent. This is achieved by loading a predefined template (`outline_generation.txt`), rendering it with relevant data (like the user query), and sending the generated prompt to the agent for processing. The response received from the agent is returned as the output.\n\n- The `evaluate_breadth` method evaluates the breadth of the student's report by first generating a student tree using the `examinees_outline_generation` method. This student tree, which is returned as a string, is then parsed into a JSON object. The method calculates a similarity score between the benchmarked ground truth (breadth_gt) and the student tree structure using the `tree_similarity` function, which is returned as the final score.\n\n- The `evaluate_factualqa` method performs an evaluation based on factual accuracy using the `student_report`. It loads a template (`factual_qa.txt`) from the `ReportBenchmark`'s agent, and renders it with necessary data (user query, breadth ground truth, and the student report). The rendered prompt is passed to the agent, and the agent's response is returned.\n\n- The `extract_student_tree_structure` method extracts the structure of the student's report in terms of its logical structure (tree format). It loads a template (`student_tree_extraction.txt`) and renders it with the `student_report` data. The agent's response is expected to return a structured JSON representation of the student's report outline.\n\n- The `evaluate_depth` method is intended to evaluate the depth of the student’s report based on factual accuracy results. However, the implementation for this logic is currently not provided in the code. The method seems to focus on extracting accuracy metrics from the factual QA results and calculating an associated score, but the actual logic is left unimplemented.\n\n**Note**: \n- The class relies heavily on the `ReportBenchmark` instance and its associated agent for template rendering and interactions. The templates used for evaluation are required to exist (e.g., `outline_generation.txt`, `factual_qa.txt`, `student_tree_extraction.txt`).\n- The `evaluate_breadth` and `evaluate_factualqa` methods assume that the agent's responses will be returned in a format that can be processed (i.e., JSON format for the student tree).\n- The `evaluate_depth` method is a placeholder and needs implementation to provide a meaningful evaluation based on factual QA results.\n\n**Output Example**:\n- The output of `examinees_outline_generation` could be a response like:\n  ```\n  {\n    \"outline\": [\n      {\"section\": \"Introduction\", \"content\": \"Introduction to the topic.\"},\n      {\"section\": \"Main Content\", \"content\": \"Detailed explanation of the topic.\"},\n      {\"section\": \"Conclusion\", \"content\": \"Summary of findings.\"}\n    ]\n  }\n  ```\n- The output of `evaluate_breadth` could be a numeric score such as:\n  ```\n  0.85\n  ```\n- The output of `evaluate_factualqa` could be a factual accuracy score or response like:\n  ```\n  \"The student report contains 80% factual accuracy based on the evaluation.\"\n  ```"
      ],
      "code_start_line": 5,
      "code_end_line": 52,
      "params": [],
      "have_return": true,
      "code_content": "class ReportEvaluation:\n    def __init__(self, report_benchmark: ReportBenchmark, student_report: str):\n        # 使用 ReportBenchmark 实例获得 ground truths\n        self.report_benchmark = report_benchmark\n        # 新增的 StudentReport 字段\n        self.student_report = student_report\n\n    def examinees_outline_generation(self):\n        # 使用 ReportBenchmark 的 BaseAgent 调用，生成学生树（此前在 ReportBenchmark 中的 run_outline_generation）\n        template_str = self.report_benchmark.agent.load_template(\"outline_generation.txt\")\n        data = {\n            \"Query\": self.report_benchmark.user_query,\n        }\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return response\n\n    def evaluate_breadth(self):\n        # 直接使用 examinees_outline_generation 生成学生树\n        student_tree_str = self.examinees_outline_generation()\n        student_tree = json.loads(student_tree_str)\n        score = tree_similarity(self.report_benchmark.breadth_gt, student_tree)\n        return score\n\n    def evaluate_factualqa(self):\n        # 基于传入的 StudentReport 执行 FactualQA 评估\n        template_str = self.report_benchmark.agent.load_template(\"factual_qa.txt\")\n        data = {\n            \"Query\": self.report_benchmark.user_query,\n            \"BreadthGT\": json.dumps(self.report_benchmark.breadth_gt),\n            \"DepthGT\": self.student_report,\n        }\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return response\n\n    def extract_student_tree_structure(self):\n        # 新增函数：从 student_report 中抽取目录树逻辑结构\n        template_str = self.report_benchmark.agent.load_template(\"student_tree_extraction.txt\")\n        data = {\"StudentReport\": self.student_report}\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return json.loads(response)\n    \n    def evaluate_depth(self):\n        # 深度评估逻辑暂不实现，基于factual QA结果评估ACC\n        # 这里实现抽取student report based answer 的acc来计算最后的分数\n        pass\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "### `__init__` Method\n\nThe `__init__` method is the constructor for the `ReportEvaluation` class. It initializes the object with the necessary attributes to perform a report evaluation by accepting two parameters: `report_benchmark` and `student_report`. This method serves the purpose of setting up the initial state of the evaluation process by assigning these parameters to class attributes.\n\n#### Parameters:\n- **`report_benchmark`** (`ReportBenchmark`): This parameter is an instance of the `ReportBenchmark` class, which provides the necessary ground truths for the report evaluation. The `ReportBenchmark` instance contains the reference for the comparison and analysis of the report's accuracy and quality.\n  \n- **`student_report`** (`str`): This parameter is a string that represents the student's report to be evaluated. It contains the content of the report submitted by the student, which will be compared against the benchmark generated by `ReportBenchmark`.\n\n#### Attributes:\n- **`self.report_benchmark`**: An instance of the `ReportBenchmark` class that is used to access the benchmark data (ground truths) required for evaluation.\n  \n- **`self.student_report`**: A string containing the student's report. This will be evaluated based on the benchmark provided by `ReportBenchmark`.\n\n#### Purpose:\nThe `__init__` method is primarily responsible for setting up the objects and data required for the report evaluation. It prepares the system by taking in the benchmark data (via `report_benchmark`) and the student's report (via `student_report`) for comparison. These attributes will be used by other methods in the class to perform detailed evaluations, such as assessing factual accuracy, report completeness, and more."
      ],
      "code_start_line": 6,
      "code_end_line": 10,
      "params": [
        "self",
        "report_benchmark",
        "student_report"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, report_benchmark: ReportBenchmark, student_report: str):\n        # 使用 ReportBenchmark 实例获得 ground truths\n        self.report_benchmark = report_benchmark\n        # 新增的 StudentReport 字段\n        self.student_report = student_report\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "report_benchmark.py/ReportBenchmark"
      ],
      "special_reference_type": [
        true
      ]
    },
    {
      "type": "FunctionDef",
      "name": "examinees_outline_generation",
      "md_content": [
        "## Function: `examinees_outline_generation`\n\n### Overview:\nThe `examinees_outline_generation` function is responsible for generating an outline related to examinees based on a predefined template. It integrates with the `ReportBenchmark` class to load a template, format it with relevant data, and then use an agent to generate a response. This response is used to provide an outline that may assist in organizing or understanding examinee-related data.\n\n### Method Signature:\n```python\ndef examinees_outline_generation(self)\n```\n\n### Parameters:\nThis method does not take any external parameters. It operates on the internal state of the object.\n\n### Returns:\n- **response** (str): The generated response from the agent after rendering the template and processing it.\n\n### Detailed Description:\nThe `examinees_outline_generation` method follows a series of steps to generate the desired outline:\n\n1. **Template Loading**: It starts by loading a template file named `\"outline_generation.txt\"` from the `ReportBenchmark` agent using the `load_template` function. This template file is expected to contain predefined structure or placeholders for the outline content.\n\n2. **Template Rendering**: The method creates a data dictionary containing the `user_query` from the `ReportBenchmark` instance. This dictionary is passed along with the template string to the `render_template` function, which processes the template by replacing placeholders with the values from the data dictionary.\n\n3. **Generating Response**: After the template is rendered, the resulting prompt is sent to the agent's `common_chat` function. This function processes the prompt and generates a response, which is then returned by the `examinees_outline_generation` method.\n\n### Example Usage:\n```python\nresponse = self.examinees_outline_generation()\n```\n\nIn this example, calling `examinees_outline_generation()` would initiate the process of generating the examinee outline and return the corresponding response.\n\n### Dependencies:\n- **`ReportBenchmark`**: The method relies on the `ReportBenchmark` class for accessing the `user_query` and interacting with the agent.\n- **`load_template`**: Used to load the template file `\"outline_generation.txt\"`.\n- **`render_template`**: Formats the template using the provided data.\n- **`common_chat`**: Used to process the formatted prompt and generate the final response.\n\nThis method is designed to provide a structured and dynamic way to generate outlines for examinee-related content based on the data available in the system."
      ],
      "code_start_line": 12,
      "code_end_line": 20,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def examinees_outline_generation(self):\n        # 使用 ReportBenchmark 的 BaseAgent 调用，生成学生树（此前在 ReportBenchmark 中的 run_outline_generation）\n        template_str = self.report_benchmark.agent.load_template(\"outline_generation.txt\")\n        data = {\n            \"Query\": self.report_benchmark.user_query,\n        }\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_evaluation.py/ReportEvaluation/evaluate_breadth"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "evaluate_breadth",
      "md_content": [
        "**evaluate_breadth**: The function of evaluate_breadth is to calculate the similarity score between a generated student tree and a benchmark tree based on their structural and semantic alignment.\n\n**parameters**: The parameters of this Function.\n· parameter1: None - This method does not take any external parameters.\n\n**Code Description**: The `evaluate_breadth` function is a method within the `ReportEvaluation` class that serves to assess the breadth of a student's understanding as represented in a tree structure. The function operates by first invoking the `examinees_outline_generation` method, which generates a string representation of a student tree based on a predefined template. This string is then parsed into a JSON object to create a structured tree format.\n\nOnce the student tree is constructed, the function proceeds to compare it against a benchmark tree, which is stored in the `breadth_gt` attribute of the `report_benchmark` object. This comparison is performed using the `tree_similarity` function, which calculates a similarity score based on the hierarchical and semantic alignment of the two trees. The final score is then returned as the output of the `evaluate_breadth` method.\n\nThe relationship with its callees is significant: `examinees_outline_generation` is responsible for generating the student tree, while `tree_similarity` is tasked with evaluating the similarity between the generated tree and the benchmark tree. This method is crucial for the overall evaluation process, as it quantifies how closely the student's representation aligns with the expected standard.\n\n**Note**: It is important to ensure that the `examinees_outline_generation` method successfully generates a valid tree structure before calling `tree_similarity`, as the accuracy of the similarity score depends on the integrity of both the student tree and the benchmark tree.\n\n**Output Example**: The function may return a similarity score such as 0.85, indicating a high degree of alignment between the student tree and the benchmark tree."
      ],
      "code_start_line": 22,
      "code_end_line": 27,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def evaluate_breadth(self):\n        # 直接使用 examinees_outline_generation 生成学生树\n        student_tree_str = self.examinees_outline_generation()\n        student_tree = json.loads(student_tree_str)\n        score = tree_similarity(self.report_benchmark.breadth_gt, student_tree)\n        return score\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "tree_comparison.py/tree_similarity"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "evaluate_factualqa",
      "md_content": [
        "## Function: `evaluate_factualqa`\n\n### Overview:\nThe `evaluate_factualqa` function is responsible for performing a factual question answering (FactualQA) evaluation based on the provided student report and associated benchmark data. It loads a predefined template, populates it with relevant data, and uses this template to generate a prompt. The prompt is then processed by a chat agent to generate a response, which is returned as the evaluation result.\n\n### Method Signature:\n```python\ndef evaluate_factualqa(self)\n```\n\n### Parameters:\nThis method does not accept any parameters directly, as it operates based on attributes of the instance it belongs to.\n\n### Returns:\n- **str**: The response generated by the chat agent, which represents the outcome of the FactualQA evaluation.\n\n### Detailed Description:\nThe `evaluate_factualqa` function follows these steps:\n1. It loads a template file (`factual_qa.txt`) from the agent's predefined template repository.\n2. It prepares a dictionary containing the following keys:\n   - **`Query`**: The user query, retrieved from `self.report_benchmark.user_query`.\n   - **`BreadthGT`**: The ground truth data related to breadth, serialized as a JSON string using `self.report_benchmark.breadth_gt`.\n   - **`DepthGT`**: The student's report, stored in `self.student_report`.\n3. The function then uses the `render_template` method to render the template with the provided data, creating a formatted prompt.\n4. This rendered prompt is sent to the chat agent through the `common_chat` method for processing.\n5. Finally, the response returned by the chat agent is returned as the result of the evaluation.\n\n### Example Usage:\n```python\nevaluation_result = self.evaluate_factualqa()\n```\n\nIn this example, the `evaluate_factualqa` method is called, and the result of the FactualQA evaluation is returned as a string, which can then be used for further analysis or output.\n\n### Dependencies:\nThis method depends on several components:\n- **`self.report_benchmark`**: Contains the `user_query`, `breadth_gt`, and an agent responsible for template handling and rendering.\n- **`self.student_report`**: The student’s report used for the Depth ground truth in the evaluation.\n- **`load_template`**: Used to load the `factual_qa.txt` template file.\n- **`render_template`**: Used to format the template with dynamic data.\n- **`common_chat`**: The method used to process the prompt and generate the final response. \n\n### Example Flow:\n1. The method loads the template `factual_qa.txt`.\n2. It prepares a data dictionary containing user query, breadth ground truth, and the student's report.\n3. The template is rendered with the provided data.\n4. The prompt is sent to the agent, which processes it and generates the evaluation response.\n5. The final response is returned to the caller."
      ],
      "code_start_line": 29,
      "code_end_line": 39,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def evaluate_factualqa(self):\n        # 基于传入的 StudentReport 执行 FactualQA 评估\n        template_str = self.report_benchmark.agent.load_template(\"factual_qa.txt\")\n        data = {\n            \"Query\": self.report_benchmark.user_query,\n            \"BreadthGT\": json.dumps(self.report_benchmark.breadth_gt),\n            \"DepthGT\": self.student_report,\n        }\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "extract_student_tree_structure",
      "md_content": [
        "**extract_student_tree_structure**: The function of extract_student_tree_structure is to extract the logical structure of a directory tree from a student report.\n\n**parameters**: The parameters of this Function.\n· None\n\n**Code Description**: The extract_student_tree_structure function is designed to facilitate the extraction of a structured representation of a student's report. It begins by loading a template file named \"student_tree_extraction.txt\" using the load_template method from the report_benchmark.agent. This template serves as a blueprint for how the data from the student report should be formatted and presented.\n\nNext, the function prepares a data dictionary containing the key \"StudentReport\" mapped to the instance variable self.student_report, which holds the actual report data. This dictionary is then passed to the render_template method, which processes the template string and replaces any placeholders with the corresponding values from the data dictionary. The rendered output is a prompt that is tailored to the specific structure of the student report.\n\nFollowing this, the function invokes the common_chat method, passing the rendered prompt as the usr_prompt parameter. This method is responsible for sending the prompt to a conversational model and receiving a response. The response is expected to be in a JSON format, which is then parsed using json.loads before being returned by the extract_student_tree_structure function.\n\nThis function is integral to the ReportEvaluation class, as it allows for the systematic extraction of information from student reports, enabling further analysis or evaluation based on the structured data obtained.\n\n**Note**: It is important to ensure that the \"student_tree_extraction.txt\" template file exists in the specified directory, as the load_template method will raise a FileNotFoundError if the file is missing. Additionally, the response from the common_chat method should be in a valid JSON format to avoid errors during parsing.\n\n**Output Example**: A possible return value from the extract_student_tree_structure function could be a structured JSON object representing the hierarchy of the student report, such as:\n{\n    \"title\": \"Student Report\",\n    \"sections\": [\n        {\n            \"title\": \"Introduction\",\n            \"content\": \"This section introduces the report.\"\n        },\n        {\n            \"title\": \"Results\",\n            \"content\": \"This section presents the results.\"\n        }\n    ]\n}"
      ],
      "code_start_line": 41,
      "code_end_line": 47,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def extract_student_tree_structure(self):\n        # 新增函数：从 student_report 中抽取目录树逻辑结构\n        template_str = self.report_benchmark.agent.load_template(\"student_tree_extraction.txt\")\n        data = {\"StudentReport\": self.student_report}\n        prompt = self.report_benchmark.agent.render_template(template_str, data)\n        response = self.report_benchmark.agent.common_chat(usr_prompt=prompt)\n        return json.loads(response)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "evaluate_depth",
      "md_content": [
        "**evaluate_depth**: The function of evaluate_depth is to perform an evaluation of the depth based on the factual QA results to calculate the final score, specifically focusing on the accuracy of student report-based answers.\n\n**parameters**: \n- None\n\n**Code Description**: \nThe `evaluate_depth` function currently does not implement any logic. It is intended to evaluate the depth based on the factual question-answering (QA) results, focusing on calculating the accuracy (ACC) of student report-based answers. However, the function body contains only a `pass` statement, which indicates that the logic for depth evaluation has not been implemented yet. \n\nThe comment inside the function suggests that once implemented, it would extract the accuracy of the answers derived from student reports and use this accuracy to compute a final score. This functionality is related to assessing the quality or correctness of the answers provided by students in reports, but the actual evaluation mechanism is absent in the code at this point.\n\n**Note**: \n- The function does not currently perform any operations or return any values due to the absence of an implementation.\n- Future implementations of this function are expected to involve extracting and evaluating accuracy metrics based on student-provided answers in reports."
      ],
      "code_start_line": 49,
      "code_end_line": 52,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def evaluate_depth(self):\n        # 深度评估逻辑暂不实现，基于factual QA结果评估ACC\n        # 这里实现抽取student report based answer 的acc来计算最后的分数\n        pass\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "tree_comparison.py": [
    {
      "type": "FunctionDef",
      "name": "parse_tree",
      "md_content": [
        "**parse_tree**: The function of parse_tree is to recursively traverse a tree structure and organize its titles by their respective depth levels.\n\n**parameters**: The parameters of this Function.\n· parameter1: node - A dictionary representing a node in the tree, which may contain a 'title' and a list of 'children'.\n· parameter2: current_depth - An integer indicating the current depth level in the tree during traversal, defaulting to 0.\n· parameter3: levels - A defaultdict that stores lists of titles indexed by their depth levels, defaulting to None.\n\n**Code Description**: The parse_tree function is designed to process a hierarchical tree structure represented as a nested dictionary. It begins by checking if the levels parameter is None, in which case it initializes it as a defaultdict of lists. The function then checks if the current node contains a 'title'; if so, it appends this title to the list corresponding to the current depth in the levels dictionary. If the node has children, the function recursively calls itself for each child, incrementing the current_depth by one. This process continues until all nodes in the tree have been processed, resulting in a structured representation of the titles organized by their depth levels.\n\nThe parse_tree function is called within the tree_similarity function, where it is used to extract and organize the titles from two different tree structures: std_tree and student_tree. By calling parse_tree on both trees, tree_similarity can compare the hierarchical structures and compute a similarity score based on the presence and arrangement of titles at various depths. This integration allows for a comprehensive analysis of how closely the student's tree resembles the standard tree, taking into account both semantic and structural differences.\n\n**Note**: It is important to ensure that the input node is structured correctly, containing 'title' and 'children' keys where applicable, to avoid unexpected behavior during traversal.\n\n**Output Example**: For a given input tree structure like:\n{\n    'title': 'Root',\n    'children': [\n        {'title': 'Child 1', 'children': []},\n        {'title': 'Child 2', 'children': [\n            {'title': 'Grandchild 1', 'children': []}\n        ]}\n    ]\n}\nThe output of parse_tree would be:\n{\n    0: ['Root'],\n    1: ['Child 1', 'Child 2'],\n    2: ['Grandchild 1']\n}"
      ],
      "code_start_line": 10,
      "code_end_line": 18,
      "params": [
        "node",
        "current_depth",
        "levels"
      ],
      "have_return": true,
      "code_content": "def parse_tree(node, current_depth=0, levels=None):\n    if levels is None:\n        levels = defaultdict(list)\n    if 'title' in node:\n        levels[current_depth].append(node['title'])\n    if 'children' in node:\n        for child in node['children']:\n            parse_tree(child, current_depth + 1, levels)\n    return levels\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "tree_comparison.py/tree_similarity"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "text_similarity",
      "md_content": [
        "**text_similarity**: The function of text_similarity is to compute the similarity score between two text inputs.\n\n**parameters**: The parameters of this Function.\n· parameter1: text1 - A string representing the first text input for comparison.\n· parameter2: text2 - A string representing the second text input for comparison.\n\n**Code Description**: The text_similarity function utilizes a natural language processing (NLP) model (referred to as `nlp`) to analyze and compare two text strings, text1 and text2. It processes each text input into a document object using the NLP model, which allows for semantic analysis. The function then calculates and returns a similarity score between the two document objects using the built-in similarity method. This score is a floating-point number that indicates how similar the two texts are, with a value closer to 1.0 indicating high similarity and a value closer to 0 indicating low similarity.\n\nThe text_similarity function is called within the level_similarity function, which is responsible for comparing two sets of nodes (nodes_A and nodes_B). In level_similarity, a similarity matrix is constructed where each element represents the similarity score between corresponding nodes from the two sets, calculated using the text_similarity function. The linear_sum_assignment function is then used to find the optimal assignment of nodes that maximizes the total similarity score. The final output of level_similarity is the average similarity score, which is derived from the total similarity of the best matches divided by the maximum possible matches.\n\n**Note**: It is important to ensure that the NLP model (`nlp`) is properly initialized and available in the scope where text_similarity is called. The quality of the similarity score is highly dependent on the capabilities of the NLP model being used.\n\n**Output Example**: For example, if text1 is \"The cat sits on the mat.\" and text2 is \"A cat is resting on a mat.\", the function might return a similarity score of approximately 0.85, indicating a high degree of similarity between the two sentences."
      ],
      "code_start_line": 20,
      "code_end_line": 23,
      "params": [
        "text1",
        "text2"
      ],
      "have_return": true,
      "code_content": "def text_similarity(text1, text2):\n    doc1 = nlp(text1)\n    doc2 = nlp(text2)\n    return doc1.similarity(doc2)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "tree_comparison.py/level_similarity"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "level_similarity",
      "md_content": [
        "**level_similarity**: The function of level_similarity is to compute a similarity score between two sets of nodes based on the text similarity of their elements.\n\n**parameters**: The parameters of this Function.\n· parameter1: nodes_A - A list of nodes representing the first set of elements for comparison.\n· parameter2: nodes_B - A list of nodes representing the second set of elements for comparison.\n\n**Code Description**: The level_similarity function is responsible for computing the similarity between two sets of nodes, `nodes_A` and `nodes_B`. It begins by handling the case where both input sets are empty, in which case it returns a similarity score of 1.0, indicating perfect similarity. If either set is non-empty, the function proceeds to create a similarity matrix, `sim_matrix`, where each element represents the similarity score between corresponding nodes from `nodes_A` and `nodes_B`. These similarity scores are computed by calling the `text_similarity` function for each pair of nodes.\n\nThe `text_similarity` function (described separately) computes the semantic similarity between two individual nodes based on natural language processing techniques. This function is called for every pair of nodes between `nodes_A` and `nodes_B`, filling the similarity matrix with the results.\n\nOnce the similarity matrix is populated, the function uses the `linear_sum_assignment` algorithm to find the optimal assignment of nodes that maximizes the total similarity. This algorithm solves the assignment problem in which the goal is to match nodes in a way that maximizes the sum of similarity scores.\n\nAfter determining the optimal assignment, the function sums up the similarity scores of the best matches and divides the total by the maximum number of nodes between `nodes_A` and `nodes_B`. This division normalizes the result, ensuring that the final similarity score is in the range [0, 1], where 1 represents perfect similarity, and 0 represents no similarity.\n\nThe `level_similarity` function is called within the `tree_similarity` function, which compares two hierarchical tree structures (a standard tree and a student's tree). The `tree_similarity` function calls `level_similarity` to evaluate the similarity between corresponding levels in the two trees. This allows for the comparison of tree structures at each level and the calculation of an overall similarity score between the two trees.\n\n**Note**: The behavior of `level_similarity` is highly dependent on the implementation of the `text_similarity` function, which must be properly initialized with a natural language processing model to accurately compute the similarity between text-based nodes.\n\n**Output Example**: If `nodes_A` is a list containing [\"apple\", \"banana\"] and `nodes_B` is a list containing [\"apple\", \"orange\"], the `text_similarity` function might return similarity scores like 1.0 for \"apple\" and \"apple\", and 0.6 for \"banana\" and \"orange\". The function would then compute the optimal assignment and return a similarity score based on these values. The final output might be a value such as 0.8, indicating a moderate similarity between the two sets."
      ],
      "code_start_line": 25,
      "code_end_line": 35,
      "params": [
        "nodes_A",
        "nodes_B"
      ],
      "have_return": true,
      "code_content": "def level_similarity(nodes_A, nodes_B):\n    if not nodes_A and not nodes_B:\n        return 1.0  # 双方无节点视为完全匹配\n    sim_matrix = np.zeros((len(nodes_A), len(nodes_B)))\n    for i, a in enumerate(nodes_A):\n        for j, b in enumerate(nodes_B):\n            sim_matrix[i][j] = text_similarity(a, b)\n    row_ind, col_ind = linear_sum_assignment(-sim_matrix)\n    total_sim = sim_matrix[row_ind, col_ind].sum()\n    max_possible = max(len(nodes_A), len(nodes_B))\n    return total_sim / max_possible if max_possible > 0 else 0\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "tree_comparison.py/tree_similarity"
      ],
      "reference_who": [
        "tree_comparison.py/text_similarity"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "tree_similarity",
      "md_content": [
        "**tree_similarity**: The function of tree_similarity is to calculate a similarity score between two tree structures based on their hierarchical and semantic alignment.\n\n**parameters**: The parameters of this Function.\n· parameter1: std_tree - A tree structure representing the standard tree to be compared against.\n· parameter2: student_tree - A tree structure representing the student's tree that is being evaluated.\n· parameter3: depth_decay (default=0.8) - A factor that controls the weight assigned to different tree levels. Deeper levels receive higher weights.\n· parameter4: alpha (default=0.3) - A factor that penalizes differences in the number of nodes between two corresponding levels.\n· parameter5: beta (default=0.02) - A penalty applied for missing layers in the student's tree compared to the standard tree.\n· parameter6: gamma (default=0.02) - A penalty applied for redundant layers in the student's tree that are not present in the standard tree.\n\n**Code Description**: The `tree_similarity` function calculates the similarity between two hierarchical tree structures (the standard tree and the student's tree). The function first parses both trees to organize them into hierarchical levels using the `parse_tree` function. This function returns dictionaries where the keys represent tree depths, and the values are lists of node titles at each depth level.\n\nThe comparison starts by determining the maximum depth across both trees. It then iterates through each possible depth level, from 0 to the maximum depth, and compares the two trees at each level. For each level, the function checks if the level exists in both trees. If a level is missing in the student's tree, a \"missing layer\" penalty is incremented. Conversely, if a level exists in the student's tree but not the standard tree, a \"redundant layer\" penalty is counted. These penalties influence the final similarity score.\n\nFor each level where both trees have corresponding nodes, the function calculates a semantic similarity score using the `level_similarity` function. The `level_similarity` function compares nodes from both trees based on their textual similarity, leveraging a text similarity algorithm. Additionally, the number of nodes at each level is compared, and a penalty is applied for any difference in node count, weighted by the `alpha` factor.\n\nThe final similarity score is a weighted average of the scores across all levels, where deeper levels have more influence due to the `depth_decay` factor. The total score is adjusted with penalties for missing or redundant layers. If no valid layers are found, the function returns a score of 0.\n\nThe function serves as a key component of the broader evaluation process, which involves comparing a student's tree to a standard tree. The `tree_similarity` function is invoked in the `evaluate_breadth` method of the `ReportEvaluation` class. This method generates a student's tree, compares it to a benchmark tree (which serves as the \"standard\"), and returns the calculated similarity score.\n\n**Note**: It is crucial that both the standard and student trees are structured consistently for accurate results. Each node should contain a 'title' and optionally a 'children' key, which will be used by the `parse_tree` function to process the hierarchical structure.\n\n**Output Example**: \nFor input trees with the following structure:\n\n- Standard Tree:\n  ```\n  {\n    'title': 'Root',\n    'children': [\n      {'title': 'Child 1', 'children': []},\n      {'title': 'Child 2', 'children': [\n        {'title': 'Grandchild 1', 'children': []}\n      ]}\n    ]\n  }\n  ```\n\n- Student Tree:\n  ```\n  {\n    'title': 'Root',\n    'children': [\n      {'title': 'Child 1', 'children': []},\n      {'title': 'Child 3', 'children': []}\n    ]\n  }\n  ```\n\nThe function would compare the trees and return a similarity score (e.g., 0.75), reflecting the degree of structural and semantic alignment between the two trees. The returned score is rounded to two decimal places."
      ],
      "code_start_line": 37,
      "code_end_line": 93,
      "params": [
        "std_tree",
        "student_tree",
        "depth_decay",
        "alpha",
        "beta",
        "gamma"
      ],
      "have_return": true,
      "code_content": "def tree_similarity(std_tree, student_tree, depth_decay=0.8, alpha=0.3, beta=0.02, gamma=0.02):\n    # 解析层级\n    std_levels = parse_tree(std_tree)\n    student_levels = parse_tree(student_tree)\n    \n    max_std_depth = max(std_levels.keys(), default=0)\n    max_student_depth = max(student_levels.keys(), default=0)\n    max_depth = max(max_std_depth, max_student_depth)\n    \n    total_score = 0.0\n    total_weight = 0.0\n    missing_layers = 0\n    redundant_layers = 0\n    \n    # 遍历每个可能的层级（从0到最大深度）\n    for depth in range(max_depth + 1):\n        in_std = depth in std_levels\n        in_student = depth in student_levels\n        weight = 1.0 / (depth_decay ** depth)  # 深层权重更高\n        \n        # 层级存在性检查\n        if in_std and not in_student:\n            missing_layers += 1\n            continue  # 学生缺失该层，跳过权重累加\n        elif not in_std and in_student:\n            redundant_layers += 1\n            continue  # 学生多出该层，跳过权重累加\n        \n        # 获取该层节点\n        nodes_std = std_levels.get(depth, [])\n        nodes_student = student_levels.get(depth, [])\n        m, n = len(nodes_std), len(nodes_student)\n        \n        # 计算语义相似度\n        semantic_score = level_similarity(nodes_std, nodes_student)\n        \n        # 节点数量差异惩罚\n        if m == 0:\n            num_penalty = 0  # 标准无节点时不惩罚\n        else:\n            num_diff = abs(m - n)\n            num_penalty = alpha * (num_diff / m)\n        structure_coeff = max(0, 1 - num_penalty)\n        \n        # 层级得分\n        layer_score = semantic_score * structure_coeff\n        total_score += layer_score * weight\n        total_weight += weight\n    \n    # 计算加权平均得分\n    weighted_avg = total_score / total_weight if total_weight > 0 else 0\n    \n    # 总结构惩罚\n    structure_penalty = beta * missing_layers + gamma * redundant_layers\n    final_score = weighted_avg * max(0, 1 - structure_penalty)\n    \n    return round(final_score, 2)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py",
        "report_evaluation.py",
        "report_evaluation.py/ReportEvaluation/evaluate_breadth"
      ],
      "reference_who": [
        "tree_comparison.py/parse_tree",
        "tree_comparison.py/level_similarity"
      ],
      "special_reference_type": [
        false,
        false
      ]
    }
  ],
  "openai_deepresearch_pipeline.py": [
    {
      "type": "FunctionDef",
      "name": "tavily_search",
      "md_content": [
        "**tavily_search**: The function of tavily_search is to perform a search query using the Tavily API.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the search query to be executed.\n· api_key: A string representing the API key for authenticating with the Tavily service. It defaults to \"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\".\n\n**Code Description**: The tavily_search function initiates a search request to the Tavily API based on the provided query. It first prints the search query to the console for logging purposes. Then, it creates an instance of the TavilyClient using the provided API key. The function calls the search method of the TavilyClient, passing the query and specifying that raw content should be included in the response. After the search request is made, the function introduces a brief pause of 0.1 seconds to manage the request rate. Finally, it returns the search results extracted from the response, specifically targeting the \"results\" key. If no results are found, it returns an empty list.\n\nThis function is called within the process_single_activity function, which processes individual activities. When an activity contains an action of type \"search\", the tavily_search function is invoked with the content of that action as the query. The results from the tavily_search function are then stored in the action dictionary under the \"result\" key. This integration allows for seamless handling of search actions within the broader activity processing workflow.\n\n**Note**: It is important to ensure that the API key used is valid and has the necessary permissions to perform searches. Additionally, the function includes a slight delay after the search request to avoid overwhelming the API with rapid successive calls.\n\n**Output Example**: A possible return value from the tavily_search function could look like this:\n```json\n{\n    \"results\": [\n        {\n            \"title\": \"Who is Leo Messi?\",\n            \"snippet\": \"Lionel Messi is an Argentine professional footballer...\"\n        },\n        {\n            \"title\": \"Lionel Messi - Wikipedia\",\n            \"snippet\": \"Lionel Messi is widely regarded as one of the greatest football players...\"\n        }\n    ]\n}\n```"
      ],
      "code_start_line": 9,
      "code_end_line": 18,
      "params": [
        "query",
        "api_key"
      ],
      "have_return": true,
      "code_content": "def tavily_search(query, api_key=\"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\"):\n    \"\"\"\n    Perform a Tavily search query\n    # Example usage: results = tavily_search(\"Who is Leo Messi?\")\n    \"\"\"\n    print(f\"Searching: {query}\")\n    tavily_client = TavilyClient(api_key=api_key)\n    response = tavily_client.search(query, include_raw_content=True)\n    time.sleep(0.1)  # 添加0.5秒延时\n    return response.get(\"results\", [])\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "openai_deepresearch_pipeline.py/process_single_activity"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "tavily_extract",
      "md_content": [
        "**tavily_extract**: The function of tavily_extract is to extract content from a specified URL using the Tavily API.\n\n**parameters**: The parameters of this Function.\n· url: A string representing the URL from which content is to be extracted.  \n· api_key: An optional string that serves as the API key for authentication with the Tavily service. The default value is \"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\".\n\n**Code Description**: The tavily_extract function is designed to retrieve content from a given URL by utilizing the Tavily API. Upon invocation, it first prints a message indicating the URL being processed. It then creates an instance of the TavilyClient, passing the provided API key for authentication. The function calls the extract method of the TavilyClient with the specified URL, which returns a response containing the extracted content.\n\nAfter a brief pause of 0.1 seconds (to potentially manage rate limits or server load), the function checks the response for results. If results are present, it retrieves the \"raw_content\" from the first result; if no results are found, it returns an empty string. This function is called within the process_single_activity function, which processes individual activities and determines the type of action to perform. Specifically, when the action type is \"browse\", the tavily_extract function is invoked with the content of the activity, allowing for the extraction of relevant information from the specified URL.\n\n**Note**: It is important to ensure that the provided URL is valid and that the API key has the necessary permissions to access the Tavily service. Additionally, users should be aware of any rate limits imposed by the Tavily API to avoid potential errors during extraction.\n\n**Output Example**: An example of the return value from the tavily_extract function could be a string containing the raw content extracted from the specified URL, such as: \"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\" If no content is found, the return value would simply be an empty string: \"\"."
      ],
      "code_start_line": 21,
      "code_end_line": 34,
      "params": [
        "url",
        "api_key"
      ],
      "have_return": true,
      "code_content": "def tavily_extract(url, api_key=\"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\"):\n    \"\"\"\n    Extract content from a URL using Tavily\n    # Example usage: content = tavily_extract(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n    \"\"\"\n    print(f\"Extracting: {url}\")\n    tavily_client = TavilyClient(api_key=api_key)\n    response = tavily_client.extract(url)\n    time.sleep(0.1)  # 添加延时\n    return (\n        response.get(\"results\", [])[0].get(\"raw_content\", \"\")\n        if response.get(\"results\")\n        else \"\"\n    )\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "openai_deepresearch_pipeline.py/process_single_activity"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "read_json_file",
      "md_content": [
        "**read_json_file**: The function of read_json_file is to read a JSON file from a given file path and return its content as a Python object.\n\n**parameters**: \n· file_path: The path to the JSON file to be read. Default is \"/Users/logic/Documents/CodeSpace/CriticSearch/Deep Research detection_0214.json\".\n\n**Code Description**:  \nThe `read_json_file` function is designed to read a JSON file from a specified location and load its content into a Python object. The function takes a single parameter `file_path`, which defines the location of the JSON file. If no path is provided, it defaults to a specific file path.\n\nThe function operates as follows:\n1. It first attempts to open the file at the provided `file_path` in read mode with UTF-8 encoding using the `open()` function.\n2. If the file is successfully opened, the function proceeds to parse the JSON content using the `json.load()` method. This method converts the JSON data into a Python dictionary or list, depending on the structure of the JSON file.\n3. If no errors occur during this process, the parsed data is returned to the caller.\n\nThe function handles errors gracefully using multiple `except` blocks:\n- If the specified file cannot be found at the provided path, a `FileNotFoundError` is caught, and a message is printed to the console indicating the missing file.\n- If the file is found but the content is not in a valid JSON format, a `json.JSONDecodeError` is raised, and an error message is displayed.\n- Any other unexpected exceptions during the process are captured by a general `Exception` handler, and an error message is printed.\n\nIn each error case, the function returns `None`, signaling that the file could not be successfully read or parsed.\n\n**Note**: \n- Ensure the file path provided is correct and the file exists at the specified location to avoid a `FileNotFoundError`.\n- The function expects the content of the file to be in valid JSON format. If the file contains malformed JSON, a `JSONDecodeError` will be raised.\n- The function does not handle cases where the file is empty or contains non-JSON data other than the expected format.\n  \n**Output Example**:\nIf the file located at `file_path` contains a valid JSON object such as:\n```json\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"city\": \"New York\"\n}\n```\nThe function will return the following Python dictionary:\n```python\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"city\": \"New York\"\n}\n```\nIf an error occurs, such as the file not being found or containing invalid JSON, the function will return `None`."
      ],
      "code_start_line": 37,
      "code_end_line": 52,
      "params": [
        "file_path"
      ],
      "have_return": true,
      "code_content": "def read_json_file(\n    file_path=\"/Users/logic/Documents/CodeSpace/CriticSearch/Deep Research detection_0214.json\",\n):\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            data = json.load(file)\n            return data\n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON format in {file_path}\")\n        return None\n    except Exception as e:\n        print(f\"Error reading file: {str(e)}\")\n        return None\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "process_activity",
      "md_content": [
        "**process_activity**: The function of process_activity is to analyze a given text for specific actions related to searching and browsing, extracting relevant information accordingly.\n\n**parameters**: The parameters of this Function.\n· text: A string input that contains the activity description, which may include search and browse actions.\n\n**Code Description**: The process_activity function utilizes regular expressions to identify and extract specific actions from the input text. It defines two patterns: one for detecting search actions that follow the phrase \"Searched for\" and another for detecting browse actions that follow \"Read\" or \"Read more from\". \n\nThe function initializes an empty list called actions to store the identified actions and a variable named thinking to hold the remaining text after processing. It then iterates through the input text to find matches for the search pattern. For each match found, it appends a dictionary containing the action type (\"search\") and the associated content to the actions list, while updating the thinking variable to exclude the processed portion of the text.\n\nSimilarly, the function searches for browse actions using the defined browse pattern. If a valid URL is found (ensuring it does not contain certain characters like brackets), it appends a corresponding dictionary to the actions list and updates the thinking variable accordingly.\n\nFinally, the function returns a dictionary containing the remaining text (thinking) and the list of actions. If no actions were found, it returns None for the action key.\n\nThis function is called by the process_single_activity function, which serves as a helper to process a single activity. The process_single_activity function takes the output of process_activity and further processes each action by performing searches or extracting information based on the action type. This relationship indicates that process_activity is a foundational component that prepares the data for more specific operations in the context of processing activities.\n\n**Note**: It is important to ensure that the input text is formatted correctly to maximize the effectiveness of the regular expressions used in this function. The function assumes that the text follows a specific structure to identify actions accurately.\n\n**Output Example**: A possible return value of the function could look like this:\n{\n    \"thinking\": \"The user was interested in the following topics.\",\n    \"action\": [\n        {\"type\": \"search\", \"content\": \"machine learning\"},\n        {\"type\": \"browse\", \"content\": \"https://example.com/resource\"}\n    ]\n}"
      ],
      "code_start_line": 56,
      "code_end_line": 76,
      "params": [
        "text"
      ],
      "have_return": true,
      "code_content": "def process_activity(text):\n    # 定义正则：匹配换行后跟\"Searched for\"和\"Read\"或\"Read more from\"\n    pattern_search = re.compile(r\"\\nSearched for\\s*(.+)\")\n    pattern_browse = re.compile(r\"\\nRead(?: more from)?\\s*(https?://[^\\s\\[\\]()]+)\")\n\n    actions = []\n    thinking = text\n\n    # 查找所有search匹配\n    for match in pattern_search.finditer(text):\n        actions.append({\"type\": \"search\", \"content\": match.group(1).strip()})\n        thinking = text[: match.start()].strip()\n\n    # 查找所有browse匹配\n    for match in pattern_browse.finditer(text):\n        url = match.group(1).strip()\n        if \"[\" not in url and \"]\" not in url and \"(\" not in url and \")\" not in url:\n            actions.append({\"type\": \"browse\", \"content\": url})\n            thinking = text[: match.start()].strip()\n\n    return {\"thinking\": thinking.strip(), \"action\": actions if actions else None}\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "openai_deepresearch_pipeline.py/process_single_activity"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "process_single_activity",
      "md_content": [
        "**process_single_activity**: The function of process_single_activity is to process a single activity by analyzing its actions and executing corresponding search or browse operations.\n\n**parameters**: The parameters of this Function.\n· activity: A dictionary representing a single activity that may contain actions to be processed.\n\n**Code Description**: The process_single_activity function serves as a helper function designed to handle individual activities by processing their associated actions. It begins by calling the process_activity function, which analyzes the input activity and extracts any actions related to searching or browsing. The output of process_activity is a dictionary that includes both the remaining text (referred to as \"thinking\") and a list of actions.\n\nOnce the actions are identified, the function iterates through each action in the list. For actions of type \"search\", it invokes the tavily_search function, passing the action's content as the search query. This function performs a search using the Tavily API and returns the results, which are then stored in the action dictionary under the \"result\" key. Similarly, for actions of type \"browse\", the tavily_extract function is called with the action's content as the URL. This function extracts content from the specified URL and also stores the result in the action dictionary.\n\nThe processed activity, now enriched with the results of the actions, is returned at the end of the function. This integration allows for a seamless workflow where individual activities can be processed to yield actionable insights based on the specified actions.\n\nThe process_single_activity function is called within the process_activities function, which handles a list of activities. It utilizes a thread pool to process each activity concurrently, thereby improving efficiency. The processed results are collected and returned as part of the overall output.\n\n**Note**: It is essential to ensure that the input activity is correctly formatted and contains valid action types. Additionally, the API key used in tavily_search and tavily_extract must be valid and have the necessary permissions to perform the respective operations.\n\n**Output Example**: A possible return value from the process_single_activity function could look like this:\n```json\n{\n    \"thinking\": \"The user was interested in the following topics.\",\n    \"action\": [\n        {\"type\": \"search\", \"content\": \"machine learning\", \"result\": [{\"title\": \"Machine Learning Overview\", \"snippet\": \"Machine learning is a subset of artificial intelligence...\"}]},\n        {\"type\": \"browse\", \"content\": \"https://example.com/resource\", \"result\": \"Content extracted from the specified URL.\"}\n    ]\n}\n```"
      ],
      "code_start_line": 79,
      "code_end_line": 88,
      "params": [
        "activity"
      ],
      "have_return": true,
      "code_content": "def process_single_activity(activity):\n    \"\"\"Helper function to process a single activity\"\"\"\n    processed = process_activity(activity)\n    if processed.get(\"action\"):\n        for action in processed[\"action\"]:\n            if action[\"type\"] == \"search\":\n                action[\"result\"] = tavily_search(action[\"content\"])\n            elif action[\"type\"] == \"browse\":\n                action[\"result\"] = tavily_extract(action[\"content\"])\n    return processed\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "openai_deepresearch_pipeline.py/process_activities"
      ],
      "reference_who": [
        "openai_deepresearch_pipeline.py/tavily_search",
        "openai_deepresearch_pipeline.py/tavily_extract",
        "openai_deepresearch_pipeline.py/process_activity"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "process_activities",
      "md_content": [
        "**process_activities**: The function of process_activities is to process a list of activities, handling both regular activities and a special \"Deep Research\" item, while utilizing concurrent processing for efficiency.\n\n**parameters**: The parameters of this Function.\n· activities: A list of activities, where each activity can be a dictionary containing either \"Activity\" or \"Deep Research\" keys.\n\n**Code Description**: The process_activities function begins by checking if the input, activities, is a list. If it is not, the function returns the input as is. This ensures that the function can handle unexpected input types gracefully.\n\nThe function initializes an empty list called final_result to store the processed activities and a variable deep_research set to None to temporarily hold any \"Deep Research\" item found during processing.\n\nThe function then iterates over each item in the activities list. If an item is a dictionary and contains the key \"Deep Research,\" it is stored in the deep_research variable, and the iteration continues to the next item without further processing of this item. This allows the function to prioritize the handling of \"Deep Research\" items.\n\nFor items that are dictionaries containing the key \"Activity,\" the function prepares to process the activities listed under this key. It creates an empty list called processed_activities to hold the results of processing each individual activity. The function employs a ThreadPoolExecutor with a maximum of 20 worker threads to process the activities concurrently. This parallel processing is achieved by mapping the process_single_activity function to each activity in the item[\"Activity\"] list. The results are collected into the processed_activities list.\n\nAfter processing, the function updates the original item by replacing its \"Activity\" key with the processed_activities list. The modified item is then appended to the final_result list.\n\nOnce all items have been processed, if a deep_research item was found, it is appended to the final_result list at the end. This ensures that the \"Deep Research\" item is included in the output while maintaining the order of the other activities.\n\nFinally, the function returns the final_result list, which contains all processed activities along with any \"Deep Research\" item.\n\nThe process_single_activity function, which is called within process_activities, is responsible for handling individual activities and their associated actions. It processes each activity to yield actionable insights based on the specified actions, thereby enhancing the overall functionality of process_activities.\n\n**Note**: It is important to ensure that the input activities are formatted correctly and contain valid keys. The function assumes that the \"Activity\" key will always contain a list of activities to be processed.\n\n**Output Example**: A possible return value from the process_activities function could look like this:\n```json\n[\n    {\n        \"Activity\": [\n            {\n                \"thinking\": \"The user was interested in machine learning.\",\n                \"action\": [\n                    {\"type\": \"search\", \"content\": \"machine learning\", \"result\": [{\"title\": \"Machine Learning Overview\", \"snippet\": \"Machine learning is a subset of artificial intelligence...\"}]}\n                ]\n            }\n        ]\n    },\n    {\n        \"Deep Research\": {\n            \"topic\": \"Advanced AI Techniques\",\n            \"details\": \"In-depth analysis of the latest AI methodologies.\"\n        }\n    }\n]\n```"
      ],
      "code_start_line": 92,
      "code_end_line": 122,
      "params": [
        "activities"
      ],
      "have_return": true,
      "code_content": "def process_activities(activities):\n    if not isinstance(activities, list):\n        return activities\n\n    final_result = []\n    deep_research = None\n\n    for item in activities:\n        # 如果是Deep Research项,先保存起来\n        if isinstance(item, dict) and \"Deep Research\" in item:\n            deep_research = item\n            continue\n\n        # 处理其他项(包括Activity)\n        if isinstance(item, dict) and \"Activity\" in item:\n            processed_activities = []\n\n            # 使用线程池并行处理activities\n            with ThreadPoolExecutor(max_workers=20) as executor:\n                processed_activities = list(\n                    executor.map(process_single_activity, item[\"Activity\"])\n                )\n\n            item[\"Activity\"] = processed_activities\n        final_result.append(item)\n\n    # 最后添加Deep Research\n    if deep_research:\n        final_result.append(deep_research)\n\n    return final_result\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "openai_deepresearch_pipeline.py/process_single_activity"
      ],
      "special_reference_type": [
        false
      ]
    }
  ],
  "tests/test_function_call_between_models.py": [
    {
      "type": "FunctionDef",
      "name": "test_function_call",
      "md_content": [
        "**test_function_call**: The function of `test_function_call` is to test the behavior of the `call_llm` function when called with different models, ensuring the correct handling of tool calls and function arguments based on model type.\n\n**parameters**: The parameters of this function are as follows:\n- model: A string representing the model name to be tested.\n\n**Code Description**: \nThe `test_function_call` function is designed to verify the behavior of the `call_llm` function when different models are used. It takes a single parameter, `model`, which represents the name of the model to be tested. \n\nThe function performs the following steps:\n1. It first calls the `call_llm` function with the `model`, `usr_prompt`, `config`, and `tools` parameters, where `usr_prompt` is assumed to be defined elsewhere in the code (likely as a list or string) and contains the input message for the model, `config` is a settings dictionary for the model, and `tools` is an optional list of tools available for the model's interaction.\n\n2. The function then proceeds to check the behavior based on the model name. If the model belongs to the \"deepseek_family\" (i.e., \"r1\" or \"reasoner\"), it asserts that no tool calls are returned by the `call_llm` function, raising an `AssertionError` if tool calls are present. This is done using the `pytest.raises(AssertionError)` construct, which ensures that the model should not generate any tool calls.\n\n3. For models other than those in the \"deepseek_family\", such as GPT-4o-mini or similar, the function checks that valid tool calls are returned. If no tool calls are returned, the function will raise an assertion failure with a specific message. Additionally, for each tool call returned, the function verifies that the tool call's function name is `\"get_weather\"` and that the function arguments contain `\"location\"`. These checks ensure that the correct function and arguments are used, validating the model's response and interaction with tools.\n\nThe test ensures the correctness of the `call_llm` function’s integration with various models, verifying both the presence of tool calls and the correctness of the function name and arguments.\n\n**Note**: \n- The test assumes that `messages`, `settings`, and `tools` are predefined elsewhere in the code.\n- The behavior of the test is dependent on the `model` parameter passed to the function, and it distinguishes between models that should not return tool calls (e.g., \"r1\", \"reasoner\") and models that should return valid tool calls.\n- The specific function name checked is `\"get_weather\"`, and it is assumed that all models generating tool calls should utilize this function for weather-related queries.\n- The use of `pytest` for exception handling ensures that expected errors are correctly raised in the event of invalid tool calls.\n\n**Output Example**:\nFor a model such as \"r1\" that belongs to the deepseek family, the expected result would be an AssertionError if any tool calls are present:\n\n```\nAssertionError: Model r1 should not return tool_calls.\n```\n\nFor a model like \"GPT-4o-mini\" that is expected to return tool calls, a correct output would look like:\n\n```\nModel GPT-4o-mini returned empty tool_calls.\nModel GPT-4o-mini returned incorrect function name.\nModel GPT-4o-mini returned incorrect function arguments.\n```\n\nIn these cases, the test would fail, highlighting the specific mismatch in the tool calls, function name, or function arguments."
      ],
      "code_start_line": 38,
      "code_end_line": 67,
      "params": [
        "model"
      ],
      "have_return": true,
      "code_content": "def test_function_call(model):\n    # 调用 call_llm 函数\n    response = call_llm(\n        model=model,\n        usr_prompt=messages,\n        config=settings,\n        tools=tools,\n    )\n\n    # Case 1: DeepSeek model should not return a function call\n    deepseek_family = [\"r1\", \"reasoner\"]\n\n    if any(sub in model.lower() for sub in deepseek_family):\n        with pytest.raises(AssertionError):\n            assert response.tool_calls, f\"Model {model} should not return tool_calls.\"\n\n    # Case 2: Other models (like GPT-4o-mini) should return valid tool calls\n    else:\n        assert response.tool_calls, f\"Model {model} returned empty tool_calls.\"\n\n        # 检查 function 的名称是否正确\n        for tool_call in response.tool_calls:\n            assert tool_call.function.name == \"get_weather\", (\n                f\"Model {model} returned incorrect function name.\"\n            )\n\n            # 检查 function 的参数是否正确\n            assert \"location\" in tool_call.function.arguments, (\n                f\"Model {model} returned incorrect function arguments.\"\n            )\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/llm_service.py/call_llm"
      ],
      "special_reference_type": [
        false
      ]
    }
  ],
  "tests/test_multiple_same_role.py": [],
  "tests/test_scrape_empty_result.py": [],
  "tests/test_tool_result_overwrite.py": [],
  "tests/test_search_empty_result.py": [],
  "src/criticsearch/llm_service.py": [
    {
      "type": "ClassDef",
      "name": "ModelManager",
      "md_content": [
        "**ModelManager**: The function of ModelManager is to manage model configurations and clients, enabling the creation of OpenAI API clients and retrieval of model-specific configurations.\n\n**attributes**:\n- config: Stores the configuration object containing model configurations and other settings.\n- clients: A dictionary that holds initialized client objects indexed by model names.\n\n**Code Description**:  \nThe `ModelManager` class is designed to handle the management of model configurations and the creation of API clients that interact with OpenAI’s services.\n\n- **`__init__(self, config)`**:  \n  The constructor initializes the `ModelManager` with the given `config` parameter, which contains the settings for the models, such as API keys, URLs, and other relevant configurations. It also initializes an empty `clients` dictionary that will store the client instances corresponding to each model.\n\n- **`get_model_config(self, model_name=None)`**:  \n  This method retrieves the configuration for a specific model. If no model name is provided, it defaults to the first model in the configuration. The function raises an error if no models are found or if the specified model name is not available in the configuration. It returns the configuration dictionary for the selected model.\n\n- **`create_client(self, model_name=None)`**:  \n  This method is responsible for creating and returning a client object. It checks if the client for the specified model already exists in the `clients` dictionary. If not, it retrieves the configuration for the model using `get_model_config`, and initializes an OpenAI client (using the `OpenAI` class, which is not shown in the provided code but is assumed to be a predefined class or function) with the relevant settings like the API key, base URL, timeout, and retry parameters. Once created, the client is stored in the `clients` dictionary for reuse.\n\nFrom a functional perspective, the `ModelManager` class is used by the `call_llm` function in the project. The `call_llm` function interacts with `ModelManager` to:\n1. Instantiate a `ModelManager` object using the provided configuration.\n2. Create a client for the specified model (or default to the first model if no model name is provided).\n3. Retrieve the configuration for the selected model.\n4. Use the configuration and client to make API calls to OpenAI’s services and process the responses.\n\nThe `ModelManager` acts as a central utility that abstracts away the complexity of managing multiple models and their configurations. By using this class, the system can easily handle different model configurations and create clients for various models dynamically.\n\n**Note**:\n- The `config` passed into the `ModelManager` should contain a \"models\" key that maps model names to their respective configurations.\n- If a model is not found in the configuration, a `ValueError` will be raised, so proper error handling should be considered when using this class.\n- The OpenAI client is created with a default timeout of 120 seconds and the possibility to customize retry settings, which are important for dealing with API reliability.\n\n**Output Example**:  \nWhen `create_client` is called with a model name like \"gpt-4\", the output will be an instance of an OpenAI client initialized with that model’s configuration, assuming that the configuration contains the appropriate API key and endpoint. The exact appearance of this client is dependent on the implementation of the OpenAI client, but it will allow making requests to OpenAI's API to process prompts and retrieve responses."
      ],
      "code_start_line": 11,
      "code_end_line": 48,
      "params": [],
      "have_return": true,
      "code_content": "class ModelManager:\n    def __init__(self, config):\n        self.config = config\n        self.clients = {}\n\n    def get_model_config(self, model_name=None):\n        models = self.config.get(\"models\", {})\n        if not models:\n            raise ValueError(\"No models found in configuration.\")\n\n        if model_name is None:\n            model_name = next(iter(models.keys()))\n\n        if model_name not in models:\n            raise ValueError(\n                f\"Model '{model_name}' not found in configuration. Available models: {list(models.keys())}\"\n            )\n\n        model_config = models.get(model_name, {})\n        return model_config\n\n    def create_client(self, model_name=None):\n        if model_name is None:\n            model_name = next(iter(self.config.models.keys()))\n\n        if model_name in self.clients:\n            return self.clients[model_name]\n\n        model_config = self.get_model_config(model_name)\n        client = OpenAI(\n            api_key=model_config.get(\"api_key\"),\n            base_url=model_config.get(\"base_url\", \"https://api.openai.com/v1\"),\n            timeout=self.config.get(\"timeout\", 120),\n            max_retries=self.config.get(\"max_retries\"),\n        )\n\n        self.clients[model_name] = client\n        return client\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/llm_service.py/call_llm"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the class with a configuration and an empty client dictionary.\n\n**parameters**: The parameters of this Function.\n· config: A configuration object or data used to initialize the instance.\n\n**Code Description**: \nThe `__init__` function is the constructor method of the class, used to initialize an object of the class when it is instantiated. \n- The `config` parameter is passed into the constructor and assigned to the instance variable `self.config`. This suggests that the configuration data will be available throughout the lifetime of the object for further use. \n- The `clients` instance variable is initialized as an empty dictionary (`{}`). This implies that the object will eventually store client-related data or mappings in this dictionary during its lifecycle.\n\n**Note**: \n- The `config` parameter should be provided when creating an instance of the class; its structure and contents will depend on the requirements of the class and the overall application.\n- The `clients` dictionary is initialized as empty, and its population will likely occur later in the class methods."
      ],
      "code_start_line": 12,
      "code_end_line": 14,
      "params": [
        "self",
        "config"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, config):\n        self.config = config\n        self.clients = {}\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "get_model_config",
      "md_content": [
        "**get_model_config**: The function of get_model_config is to retrieve the configuration settings for a specific model from the configuration file.\n\n**parameters**:\n· model_name: A string representing the name of the model. If not provided, the first model in the configuration is selected.\n\n**Code Description**:  \nThe `get_model_config` function is responsible for fetching the configuration for a specified model from the configuration dictionary stored in the `self.config` attribute. \n\n1. The function starts by retrieving the \"models\" section of the configuration using `self.config.get(\"models\", {})`. If no models are found, a `ValueError` is raised with the message \"No models found in configuration.\"\n   \n2. If the `model_name` parameter is not provided, the function selects the first available model by using `next(iter(models.keys()))`.\n\n3. The function checks if the `model_name` exists in the models configuration. If it is not found, a `ValueError` is raised indicating the model is not in the configuration, and it provides a list of available models.\n\n4. If the model is found, the function retrieves its configuration from the `models` dictionary and returns it.\n\nThe function is used by other components in the project to ensure that the correct configuration for a model is retrieved. For example, in the `create_client` method, it is used to get the configuration of a specific model when creating an OpenAI client. It is also utilized in the `call_llm` function, where it is used to get the model configuration to set up parameters for making API calls.\n\n**Note**:  \n- The function raises errors if the models section is missing or if the specified model is not found in the configuration.\n- The function defaults to the first model in the configuration if no model name is provided.\n\n**Output Example**:  \nIf the configuration for the model \"gpt-3\" contains the following settings:\n```json\n{\n  \"models\": {\n    \"gpt-3\": {\n      \"api_key\": \"your-api-key\",\n      \"base_url\": \"https://api.openai.com/v1\",\n      \"temperature\": 0.7,\n      \"max_tokens\": 150\n    }\n  }\n}\n```\nCalling `get_model_config(\"gpt-3\")` would return:\n```python\n{\n  \"api_key\": \"your-api-key\",\n  \"base_url\": \"https://api.openai.com/v1\",\n  \"temperature\": 0.7,\n  \"max_tokens\": 150\n}\n```"
      ],
      "code_start_line": 16,
      "code_end_line": 30,
      "params": [
        "self",
        "model_name"
      ],
      "have_return": true,
      "code_content": "    def get_model_config(self, model_name=None):\n        models = self.config.get(\"models\", {})\n        if not models:\n            raise ValueError(\"No models found in configuration.\")\n\n        if model_name is None:\n            model_name = next(iter(models.keys()))\n\n        if model_name not in models:\n            raise ValueError(\n                f\"Model '{model_name}' not found in configuration. Available models: {list(models.keys())}\"\n            )\n\n        model_config = models.get(model_name, {})\n        return model_config\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/llm_service.py/ModelManager/create_client",
        "src/criticsearch/llm_service.py/call_llm"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "create_client",
      "md_content": [
        "**create_client**: The function of create_client is to create and return an OpenAI client instance for a specified model.\n\n**parameters**: The parameters of this Function.\n· model_name: A string representing the name of the model for which the client is to be created. If not provided, the first model in the configuration is selected.\n\n**Code Description**: The `create_client` function is responsible for instantiating and returning an OpenAI client based on the specified model name. The function first checks if a model name has been provided; if not, it defaults to the first model available in the configuration. \n\nThe function then checks if a client for the specified model already exists in the `self.clients` dictionary. If it does, the existing client is returned, avoiding the overhead of creating a new instance. \n\nIf the client does not exist, the function retrieves the model's configuration using the `get_model_config` method. This method fetches the necessary API key, base URL, timeout, and maximum retries for the model from the configuration settings. \n\nAn instance of the OpenAI client is then created using the retrieved configuration parameters. This instance is stored in the `self.clients` dictionary for future use and is returned to the caller.\n\nThe `create_client` function is called by the `call_llm` function, which is responsible for making API calls to the OpenAI service. In `call_llm`, the `create_client` function is invoked to obtain the client needed to interact with the OpenAI API, ensuring that the correct configuration is used for the specified model. This establishes a direct relationship where `call_llm` relies on `create_client` to provide the necessary client instance for executing its operations.\n\n**Note**: It is important to ensure that the model name provided is valid and exists in the configuration. If the model name is not found, the `get_model_config` method will raise an error, which will propagate back to the caller, potentially affecting the execution of the `call_llm` function.\n\n**Output Example**: If the model name \"gpt-3\" is specified and the configuration is correctly set, the function would return an instance of the OpenAI client configured for \"gpt-3\". The returned client would be capable of making API calls to the OpenAI service with the specified parameters."
      ],
      "code_start_line": 32,
      "code_end_line": 48,
      "params": [
        "self",
        "model_name"
      ],
      "have_return": true,
      "code_content": "    def create_client(self, model_name=None):\n        if model_name is None:\n            model_name = next(iter(self.config.models.keys()))\n\n        if model_name in self.clients:\n            return self.clients[model_name]\n\n        model_config = self.get_model_config(model_name)\n        client = OpenAI(\n            api_key=model_config.get(\"api_key\"),\n            base_url=model_config.get(\"base_url\", \"https://api.openai.com/v1\"),\n            timeout=self.config.get(\"timeout\", 120),\n            max_retries=self.config.get(\"max_retries\"),\n        )\n\n        self.clients[model_name] = client\n        return client\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/llm_service.py/call_llm"
      ],
      "reference_who": [
        "src/criticsearch/llm_service.py/ModelManager/get_model_config"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "call_llm",
      "md_content": [
        "## `call_llm` Function Documentation\n\n### Purpose:\nThe `call_llm` function interacts with a language model API to generate responses based on a user-provided prompt. It handles communication with the OpenAI API or a similar service, utilizing a model configuration and client provided through the `ModelManager`.\n\n### Parameters:\n- **model** (`str`):  \n  The name of the model to be used for generating the response (e.g., `\"gpt-4\"`). It is passed to the `ModelManager` to create the appropriate client.\n  \n- **usr_prompt** (`str | Iterable[ChatCompletionMessageParam]`):  \n  The user prompt to send to the model. It can either be a single string message or an iterable of `ChatCompletionMessageParam` objects. The prompt is the basis of the model's response.\n\n- **config** (`dict`):  \n  A configuration dictionary used to initialize the `ModelManager`. It includes settings related to model configurations such as API keys, timeout settings, and retry parameters.\n\n- **tools** (`List | None`, optional):  \n  A list of tools that can be used by the model during the interaction. This is an optional parameter. If not provided, the function defaults to `None`.\n\n### Returns:\n- **ChatCompletionMessage**:  \n  The generated response message from the model. This object contains the model's output based on the provided prompt.\n\n### Functionality:\n1. **Initialize ModelManager**:  \n   A `ModelManager` instance is created using the provided configuration (`config`). This instance is responsible for managing model-specific settings and clients.\n\n2. **Create Model Client**:  \n   The `create_client` method of `ModelManager` is used to create a client for the specified model. If a client for the model does not already exist, it is initialized and stored.\n\n3. **Configure Prompt**:  \n   The `usr_prompt` is processed. If it is a string, it is converted into a message format. If it is already an iterable of `ChatCompletionMessageParam`, it is used as-is.\n\n4. **API Request**:  \n   The function sends the prompt to the OpenAI API (or a compatible service) via the client, using settings such as `temperature` and `max_tokens` from the model's configuration. If tools are provided, they are passed along with the request.\n\n5. **Handle Response**:  \n   The function extracts the response message from the API's result. If the model supports tools, it handles the response accordingly. If not, it reattempts the request without tools.\n\n6. **Error Handling**:  \n   The function raises specific exceptions in case of errors, including:\n   - `APIConnectionError`: If there is an issue connecting to the API.\n   - `ValueError`: If there is an issue with the configuration or model settings.\n   - `BadRequestError`: If the model does not support tools (in which case, a retry without tools is performed).\n\n### Example Usage:\n```python\nresponse = call_llm(\n    model=\"gpt-4\",\n    usr_prompt=\"What is the capital of France?\",\n    config=config_dict\n)\n```\n\n### Notes:\n- The `model` parameter should correspond to a valid model name as specified in the configuration.\n- The `config` dictionary must include all necessary settings for model initialization, including API keys and any model-specific options.\n- The `tools` parameter is optional, and should only be used if supported by the model. If the model does not support tools, the function will handle this by retrying without them.\n- Proper error handling should be implemented to manage exceptions such as connection failures or invalid configurations."
      ],
      "code_start_line": 51,
      "code_end_line": 93,
      "params": [
        "model",
        "usr_prompt",
        "config",
        "tools"
      ],
      "have_return": true,
      "code_content": "def call_llm(\n    model,\n    usr_prompt: str | Iterable[ChatCompletionMessageParam],\n    config,\n    tools: List | None = None,\n) -> ChatCompletionMessage:\n    model_manager = ModelManager(config)\n    client = model_manager.create_client(model)\n\n    # 从 ModelManager 获取配置\n    model_config = model_manager.get_model_config(model)\n    if isinstance(usr_prompt, str):\n        messages = [ChatCompletionUserMessageParam(content=usr_prompt, role=\"user\")]\n    else:\n        messages = usr_prompt\n\n    try:\n        response = client.chat.completions.create(\n            model=model,\n            messages=messages,\n            temperature=model_config.get(\"temperature\", None),\n            max_tokens=model_config.get(\"max_tokens\", None),\n            tools=tools,  # type: ignore\n        )\n\n        response_message = response.choices[0].message\n        return response_message\n\n    except APIConnectionError as e:\n        raise RuntimeError(f\"Failed to connect to OpenAI API: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Error in configuration or model: {e}\")\n    except BadRequestError:\n        # Some model like gemini-2.0-flash-thinking-exp may not support tools and raise BadRequestError\n        response = client.chat.completions.create(\n            model=model,\n            messages=messages,\n            temperature=model_config.get(\"temperature\", None),\n            max_tokens=model_config.get(\"max_tokens\", None),\n        )\n\n        response_message = response.choices[0].message\n        return response_message\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)",
        "tests/test_function_call_between_models.py",
        "tests/test_function_call_between_models.py/test_function_call",
        "tests/test_multiple_same_role.py"
      ],
      "reference_who": [
        "src/criticsearch/llm_service.py/ModelManager",
        "src/criticsearch/llm_service.py/ModelManager/get_model_config",
        "src/criticsearch/llm_service.py/ModelManager/create_client"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/base_agent.py": [
    {
      "type": "ClassDef",
      "name": "BaseAgent",
      "md_content": [
        "**BaseAgent**: The function of BaseAgent is to serve as a foundational class for implementing an intelligent agent that can manage conversations, perform searches, and interact with various tools.\n\n**attributes**: The attributes of this Class.\n· queryDB: A set to store unique queries made by the agent during its operation.  \n· tool_registry: An instance of ToolRegistry that manages the schemas for tools used by the agent.  \n· user_question: A string that holds the current question posed by the user.  \n· conversation_manager: An instance of ConversationManager responsible for maintaining the history of the conversation.  \n· prompts_dir: A string that specifies the directory path where template prompt files are stored.  \n· citationDB: A list of dictionaries that contains search queries and their corresponding results, specifically those praised by a critic.  \n· search_aggregator: An instance of SearchAggregator that facilitates search operations.  \n· search_aggregator_schema: A schema representation of the search aggregator tool, retrieved from the tool registry.  \n· content_scraper: An instance of ContentScraper that handles web scraping tasks.  \n· content_scraper_schema: A schema representation of the content scraper tool, retrieved from the tool registry.  \n· repeat_turns: An integer that defines the number of times the agent will repeat its search and interaction process.\n\n**Code Description**: The BaseAgent class is designed to provide a structured framework for building intelligent agents that can engage in conversations, perform searches, and utilize various tools effectively. Upon initialization, the class sets up several key components, including the conversation manager, tool registry, and search aggregator. \n\nThe conversation manager is responsible for tracking the history of interactions, while the tool registry allows the agent to manage and retrieve schemas for different tools it may use. The citationDB is specifically designed to store search results that have received positive feedback from a critic, ensuring that the agent can reference high-quality information.\n\nThe class provides several methods for loading templates, rendering them with data, and managing conversations. The `common_chat` method is overloaded to handle different types of user prompts, allowing for flexible interactions. The `update_answer` method enables the agent to refine its responses based on previous answers and feedback from critics.\n\nAdditionally, the `search_and_browse` method integrates both search and web scraping functionalities, allowing the agent to gather information from various sources and present it to the user. The `model_confident` method checks the agent's confidence in its responses, guiding its decision-making process on whether to provide an answer or seek additional information.\n\nThe BaseAgent class is utilized in various parts of the project, including the CriticAgent, which extends its functionality to generate critiques based on the agent's responses. The main function in the project initializes an instance of BaseAgent to handle user tasks, demonstrating its role as a central component in the overall architecture.\n\n**Note**: It is essential to ensure that the tool registry is populated with the necessary schemas for the tools being used, as the agent relies on these schemas for proper functionality. Additionally, the citationDB should be managed carefully to maintain the quality of information referenced by the agent.\n\n**Output Example**: A possible appearance of the code's return value when performing a search might look like this:\n```json\n{\n  \"search_results\": [\n    {\n      \"document_id\": \"12345\",\n      \"url\": \"https://example.com/article\",\n      \"title\": \"Understanding the Challenges Faced by Google in 2019\",\n      \"content\": \"In 2019, Google faced several challenges including...\"\n    }\n  ],\n  \"conversation_history\": [\n    {\"role\": \"user\", \"content\": \"What challenges did Google face in 2019?\"},\n    {\"role\": \"assistant\", \"content\": \"Google faced several challenges including...\"}\n  ]\n}\n```"
      ],
      "code_start_line": 19,
      "code_end_line": 258,
      "params": [],
      "have_return": true,
      "code_content": "class BaseAgent:\n    # Class-level attributes, shared across all instances\n    queryDB = set()  # A set to store queries\n    tool_registry = ToolRegistry()  # Registry for tools\n    user_question = \"\"\n    conversation_manager = ConversationManager()\n\n    def __init__(self):\n        base_dir = os.path.dirname(\n            os.path.abspath(__file__)\n        )  # Directory of the current script\n        self.prompts_dir = os.path.join(base_dir, \"prompts\")\n        # self.env = Environment(loader=FileSystemLoader(self.prompts_dir))\n\n        # 对于citationDB,应该是一个字典，key是query，value是内容和来源\n        # 这个列表中的每个元素都是一个字典，代表一个搜索的问题以及对应的搜索结果\n        self.citationDB = [\n            {  # citationDB中只会把受到critic表扬的搜索结果加入\n                \"why do we say google was facing challenges in 2019?\": {\n                    \"document_id\": {  # 这个document_id是一个唯一的标识符，用于标识这个文档\n                        \"url\": \"\",\n                        \"title\": \"\",\n                        \"content\": \"\",\n                    }\n                }\n            }\n        ]\n        self.search_aggregator = SearchAggregator()\n\n        self.search_aggregator_schema = (\n            BaseAgent.tool_registry.get_or_create_tool_schema(\n                self.search_aggregator.search\n            )\n        )\n\n        self.content_scraper = ContentScraper()\n\n        self.content_scraper_schema = BaseAgent.tool_registry.get_or_create_tool_schema(\n            self.content_scraper.scrape\n        )\n\n        BaseAgent.conversation_manager.available_tools = [\n            self.content_scraper_schema,\n            self.search_aggregator_schema,\n        ]\n\n        self.repeat_turns = 10\n\n    def load_template(self, filename):\n        \"\"\"\n        Loads a template file from the prompts directory.\n\n        :param filename: The name of the template file to load.\n        :return: The content of the file as a string.\n        \"\"\"\n        filepath = os.path.join(self.prompts_dir, filename)\n\n        # Ensure the file exists\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(\n                f\"Template file '{filename}' not found in {self.prompts_dir}\"\n            )\n\n        # Read and return the content of the file\n        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n            return file.read()\n\n    def render_template(self, template_str, data):\n        \"\"\"\n        Render a template using string formatting.\n\n        :param template_str: Template content as a string.\n        :param data: Dictionary of variables to replace in the template.\n        :return: Rendered string.\n        \"\"\"\n        template = Template(template_str)\n        return template.render(**data)\n\n    @overload\n    def common_chat(\n        self, usr_prompt: List, tools: None = None\n    ) -> ChatCompletionMessage: ...\n\n    @overload\n    def common_chat(self, usr_prompt: str, tools: List) -> ChatCompletionMessage: ...\n\n    @overload\n    def common_chat(self, usr_prompt: str, tools: None = None) -> str: ...\n\n    def common_chat(\n        self,\n        usr_prompt: str | List,\n        tools: Optional[List] = None,\n        role: str = \"assistant\",\n    ) -> ChatCompletionMessage | str | None:\n        llm_response = call_llm(\n            model=settings.default_model,\n            usr_prompt=usr_prompt,\n            config=settings,\n            tools=tools,\n        )\n\n        # logger.info(f\"usr_prompt:\\n{usr_prompt}\")\n        # logger.info(f\"llm_response:\\n{llm_response}\")\n\n        if tools is not None:\n            return llm_response\n\n        BaseAgent.conversation_manager.append_to_history(\n            role=role, content=llm_response.content\n        )\n\n        return llm_response.content\n\n    def update_answer(self, query, previous_answer, search_results, critic_feedback):\n        data = {\n            \"query\": query,\n            \"previous_answer\": previous_answer,\n            \"search_results\": search_results,\n            \"critic_feedback\": critic_feedback,\n        }\n\n        agent_update_answer_prompt = self.load_template(\"agent_update_answer.txt\")\n        rendered_prompt = self.render_template(agent_update_answer_prompt, data)\n\n        agent_update_answer_response = self.common_chat(usr_prompt=rendered_prompt)\n\n        return agent_update_answer_response\n\n    def model_confident(self, query):\n        \"\"\"\n        检查模型是否对当前问题有信心。\n        \"\"\"\n        data = {\"user_question\": query}\n        agent_confidence_prompt = self.load_template(\"agent_confidence.txt\")\n\n        rendered_prompt = self.render_template(agent_confidence_prompt, data)\n        agent_confidence_response = self.common_chat(usr_prompt=rendered_prompt)\n\n        return agent_confidence_response\n\n    def search_and_browse(self, rendered_prompt) -> str | None:\n        search_with_tool_response = self.common_chat(\n            usr_prompt=rendered_prompt, tools=self.search_aggregator_schema\n        )\n\n        logger.info(f\"search_with_tool_response:\\n{search_with_tool_response}\")\n\n        # If no tool calls, return the response immediately\n        if search_with_tool_response.tool_calls is None:\n            return search_with_tool_response.content\n\n        BaseAgent.conversation_manager.append_tool_call_to_history(\n            search_with_tool_response.tool_calls\n        )\n\n        final_search_results = \"\"\n\n        for tool_call in search_with_tool_response.tool_calls:\n            query = json.loads(tool_call.function.arguments).get(\"query\", \"\")\n\n            search_results = asyncio.run(self.search_aggregator.search(query=query))\n\n            time.sleep(1)\n\n            BaseAgent.conversation_manager.append_tool_call_result_to_history(\n                tool_call_id=tool_call.id,\n                name=\"search\",\n                content=search_results,\n            )\n\n            BaseAgent.queryDB.update(query)\n\n            final_search_results += f\"{search_results}\"\n\n        web_scraper_prompt = self.load_template(\"web_scraper.txt\")\n        web_scraper_rendered_prompt = self.render_template(\n            web_scraper_prompt,\n            {\n                \"user_question\": self.user_question,\n                \"initial_search_results\": final_search_results,\n            },\n        )\n\n        # Interact with the model for web scraping\n        web_scraper_response = self.common_chat(\n            usr_prompt=web_scraper_rendered_prompt,\n            tools=self.content_scraper_schema,\n        )\n\n        # If no tool calls, return the response immediately\n        if web_scraper_response.tool_calls is None:\n            return web_scraper_response.content\n\n        BaseAgent.conversation_manager.append_tool_call_to_history(\n            web_scraper_response.tool_calls\n        )\n\n        final_web_scraper_results = \"\"\n\n        for tool_call in web_scraper_response.tool_calls:\n            urls = json.loads(tool_call.function.arguments).get(\"urls\", [])\n\n            web_scraper_results = asyncio.run(self.content_scraper.scrape(urls=urls))\n\n            BaseAgent.conversation_manager.append_tool_call_result_to_history(\n                tool_call_id=tool_call.id,\n                name=\"scrape\",\n                content=web_scraper_results,  # type: ignore\n            )\n\n            final_web_scraper_results += web_scraper_results  # type: ignore\n\n        return final_web_scraper_results\n\n    def receive_task(self, task):\n        \"\"\"\n        接收原始任务。\n        \"\"\"\n        self.original_task = task\n\n    def extract_and_validate_yaml(self, model_response):\n        # 正则表达式匹配包裹在```yaml```之间的内容\n        import re\n\n        match = re.search(r\"```yaml\\n([\\s\\S]*?)\\n```\", model_response, re.DOTALL)\n\n        if not match:\n            return None  # 如果没有找到匹配的内容，返回None\n\n        model_response = match.group(1).strip()\n\n        try:\n            # 尝试解析YAML内容\n            parsed_yaml = yaml.safe_load(model_response)\n            return yaml.dump(parsed_yaml, default_flow_style=False)\n\n        except yaml.YAMLError as exc:\n            print(f\"Invalid YAML content: {exc}\")\n            return None\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py",
        "report_benchmark.py/ReportBenchmark/__init__",
        "src/criticsearch/critic_agent.py",
        "src/criticsearch/critic_agent.py/CriticAgent",
        "src/criticsearch/main.py",
        "src/criticsearch/main.py/main",
        "src/criticsearch/tasks_runner.py",
        "src/criticsearch/tasks_runner.py/run_tasks"
      ],
      "reference_who": [
        "src/criticsearch/models.py/ConversationManager",
        "src/criticsearch/tools/tool_registry.py/ToolRegistry"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the BaseAgent class, setting up necessary directories, databases, and tools for the agent's operation.\n\n**parameters**: The parameters of this Function.\n· None\n\n**Code Description**: The __init__ method is the constructor for the BaseAgent class. It is responsible for initializing various components that the agent will use during its operation. \n\n1. **Directory Setup**: The method begins by determining the base directory of the current script using `os.path.dirname(os.path.abspath(__file__))`. This directory is essential for locating resources related to the agent, specifically the prompts directory, which is constructed by joining the base directory with the string \"prompts\".\n\n2. **Citation Database Initialization**: The `citationDB` attribute is initialized as a list containing a single dictionary. This dictionary is designed to store search queries as keys and their corresponding results as values. The comment indicates that only search results praised by a critic will be included in this database. Each entry in the citationDB is structured to hold a unique document identifier along with its associated metadata, such as URL, title, and content.\n\n3. **Search Aggregator Setup**: An instance of the `SearchAggregator` class is created and assigned to the `search_aggregator` attribute. This component is responsible for managing search queries across multiple search engines.\n\n4. **Tool Schema Creation**: The method retrieves or creates schemas for the search aggregator and content scraper tools using the `get_or_create_tool_schema` method from the `tool_registry`. This method ensures that the schemas for these tools are registered and available for use in the agent's operations. The schemas are stored in `search_aggregator_schema` and `content_scraper_schema` attributes, respectively.\n\n5. **Content Scraper Initialization**: An instance of the `ContentScraper` class is created and assigned to the `content_scraper` attribute. This component is responsible for scraping content from specified URLs.\n\n6. **Updating Available Tools**: The method updates the `available_tools` attribute of the `conversation_manager` class variable in BaseAgent to include the schemas for both the content scraper and the search aggregator. This allows the agent to utilize these tools during interactions.\n\n7. **Repeat Turns Configuration**: Finally, the `repeat_turns` attribute is initialized to 10, which likely indicates the number of times the agent can repeat a search or interaction before stopping.\n\nThe __init__ method is crucial for setting up the BaseAgent instance with all necessary components and configurations, ensuring that it is ready to perform its intended functions effectively.\n\n**Note**: When using this method, it is important to ensure that the required directories and tools are correctly set up in the environment. Additionally, the proper functioning of the search aggregator and content scraper depends on the availability of their respective configurations and API keys."
      ],
      "code_start_line": 26,
      "code_end_line": 65,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self):\n        base_dir = os.path.dirname(\n            os.path.abspath(__file__)\n        )  # Directory of the current script\n        self.prompts_dir = os.path.join(base_dir, \"prompts\")\n        # self.env = Environment(loader=FileSystemLoader(self.prompts_dir))\n\n        # 对于citationDB,应该是一个字典，key是query，value是内容和来源\n        # 这个列表中的每个元素都是一个字典，代表一个搜索的问题以及对应的搜索结果\n        self.citationDB = [\n            {  # citationDB中只会把受到critic表扬的搜索结果加入\n                \"why do we say google was facing challenges in 2019?\": {\n                    \"document_id\": {  # 这个document_id是一个唯一的标识符，用于标识这个文档\n                        \"url\": \"\",\n                        \"title\": \"\",\n                        \"content\": \"\",\n                    }\n                }\n            }\n        ]\n        self.search_aggregator = SearchAggregator()\n\n        self.search_aggregator_schema = (\n            BaseAgent.tool_registry.get_or_create_tool_schema(\n                self.search_aggregator.search\n            )\n        )\n\n        self.content_scraper = ContentScraper()\n\n        self.content_scraper_schema = BaseAgent.tool_registry.get_or_create_tool_schema(\n            self.content_scraper.scrape\n        )\n\n        BaseAgent.conversation_manager.available_tools = [\n            self.content_scraper_schema,\n            self.search_aggregator_schema,\n        ]\n\n        self.repeat_turns = 10\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/tool_registry.py/ToolRegistry/get_or_create_tool_schema",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/search"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "load_template",
      "md_content": [
        "## Function: `load_template`\n\n### Overview:\nThe `load_template` function is responsible for loading a template file from a predefined directory and returning its contents as a string. This method is particularly useful for retrieving text-based templates that can be rendered or processed further in the application.\n\n### Method Signature:\n```python\ndef load_template(self, filename)\n```\n\n### Parameters:\n- **`filename`** (str): The name of the template file to be loaded. This should be a valid filename present within the specified prompts directory.\n\n### Returns:\n- **str**: The content of the template file as a string.\n\n### Raises:\n- **FileNotFoundError**: If the specified template file does not exist in the prompts directory, this error is raised with a descriptive message indicating the missing file.\n\n### Detailed Description:\nThe `load_template` function performs the following steps:\n1. It constructs the full file path by combining the predefined prompts directory (`self.prompts_dir`) with the provided `filename`.\n2. It checks if the file exists at the constructed path.\n3. If the file does not exist, it raises a `FileNotFoundError` with a detailed message about the missing file.\n4. If the file is found, it opens the file in read mode, reads its content, and returns the content as a string.\n\nThis function ensures that template files are loaded correctly, and if a template file is missing, the user is informed with a clear error message.\n\n### Example Usage:\n```python\ntemplate_content = self.load_template(\"example_template.txt\")\n```\n\nIn this example, the function loads the content of `example_template.txt` from the predefined directory and stores it in the `template_content` variable for further use."
      ],
      "code_start_line": 67,
      "code_end_line": 84,
      "params": [
        "self",
        "filename"
      ],
      "have_return": true,
      "code_content": "    def load_template(self, filename):\n        \"\"\"\n        Loads a template file from the prompts directory.\n\n        :param filename: The name of the template file to load.\n        :return: The content of the file as a string.\n        \"\"\"\n        filepath = os.path.join(self.prompts_dir, filename)\n\n        # Ensure the file exists\n        if not os.path.exists(filepath):\n            raise FileNotFoundError(\n                f\"Template file '{filename}' not found in {self.prompts_dir}\"\n            )\n\n        # Read and return the content of the file\n        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n            return file.read()\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/__init__",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "render_template",
      "md_content": [
        "**render_template**: The function of render_template is to render a template using string formatting.\n\n**parameters**: The parameters of this Function.\n· template_str: Template content as a string.  \n· data: Dictionary of variables to replace in the template.  \n\n**Code Description**: The render_template function is designed to take a string representation of a template and a dictionary of data, which contains key-value pairs that will be used to replace placeholders in the template. The function utilizes the Template class to create a template object from the provided template string. It then calls the render method on this template object, unpacking the data dictionary to replace the placeholders with the corresponding values. The result is a fully rendered string that incorporates the provided data.\n\nThis function is called by various methods within the project, specifically in the ReportBenchmark and ReportEvaluation classes. For instance, in the attempt method of the ReportBenchmark class, render_template is used to create a prompt for a chat interaction by loading a specific template and populating it with relevant data such as wiki_text and UserQuery. Similarly, in the run_factualqa method, it renders a template for FactualQA evaluation, incorporating user queries and ground truth data. The rendered output is then used to generate responses from a common chat function, which is a critical part of the application's functionality.\n\nIn the ReportEvaluation class, methods like examinees_outline_generation and evaluate_factualqa also leverage render_template to prepare prompts for generating outlines and evaluating factual questions, respectively. Each of these methods relies on the rendered output to facilitate interactions with the chat system, ensuring that the responses are contextually relevant and tailored to the specific queries being addressed.\n\n**Note**: It is important to ensure that the data dictionary passed to the render_template function contains all necessary keys that correspond to placeholders in the template string. Failure to provide the correct keys may result in rendering errors or incomplete output.\n\n**Output Example**: An example of the rendered output might look like this:\n\nIf the template_str is \"Hello, {{ UserQuery }}! Here is your information: {{ wiki_text }}.\" and the data is {\"UserQuery\": \"What is AI?\", \"wiki_text\": \"AI stands for Artificial Intelligence.\"}, the output would be:\n\n\"Hello, What is AI?! Here is your information: AI stands for Artificial Intelligence.\""
      ],
      "code_start_line": 86,
      "code_end_line": 95,
      "params": [
        "self",
        "template_str",
        "data"
      ],
      "have_return": true,
      "code_content": "    def render_template(self, template_str, data):\n        \"\"\"\n        Render a template using string formatting.\n\n        :param template_str: Template content as a string.\n        :param data: Dictionary of variables to replace in the template.\n        :return: Rendered string.\n        \"\"\"\n        template = Template(template_str)\n        return template.render(**data)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "common_chat",
      "md_content": [
        "**common_chat**: The function of common_chat is to facilitate a conversation with the model by sending user prompts and receiving responses.\n\n**parameters**: The parameters of this Function.\n· usr_prompt: A list containing the user prompt that is to be sent to the model for processing.\n· tools: An optional parameter that can be set to None, which may be used to specify any tools that the model can utilize during the conversation.\n\n**Code Description**: The common_chat function is designed to interact with a conversational model, taking a user prompt as input and returning a response in the form of a ChatCompletionMessage. This function is integral to the operation of various components within the project, as it serves as the primary means of communication with the model. It is invoked by several methods across different classes, such as attempt in ReportBenchmark, run_factualqa, examinees_outline_generation, evaluate_factualqa, and extract_student_tree_structure in the ReportEvaluation class, as well as update_answer and model_confident in the BaseAgent class.\n\nIn each of these instances, common_chat is called with a rendered prompt that is generated based on specific templates and user data. For example, in the attempt method, the function is called after loading and rendering a template for fact extraction, ensuring that the model receives a well-structured query. Similarly, in the run_factualqa method, the function is used to evaluate factual questions by passing a prompt that includes user queries and ground truth data.\n\nThe common_chat function is also utilized in the context of updating answers and checking model confidence, where it processes prompts that include previous answers and user feedback. This highlights its role in maintaining an ongoing dialogue with the model, allowing for iterative improvements based on user interactions and feedback.\n\n**Note**: It is important to ensure that the usr_prompt parameter is properly formatted and contains relevant information for the model to generate an appropriate response. Additionally, while the tools parameter is optional, its inclusion may enhance the model's capabilities depending on the context of the conversation."
      ],
      "code_start_line": 98,
      "code_end_line": 100,
      "params": [
        "self",
        "usr_prompt",
        "tools"
      ],
      "have_return": false,
      "code_content": "    def common_chat(\n        self, usr_prompt: List, tools: None = None\n    ) -> ChatCompletionMessage: ...\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "common_chat",
      "md_content": [
        "**common_chat**: The function of common_chat is to facilitate a chat interaction by processing a user prompt and potentially utilizing additional tools.\n\n**parameters**: The parameters of this Function.\n· usr_prompt: A string representing the user's prompt that initiates the chat interaction.\n· tools: A list of tools that may be used during the chat interaction.\n\n**Code Description**: The common_chat function is designed to handle chat interactions within the BaseAgent class. It takes a user prompt (usr_prompt) as input, which is a string that contains the user's query or message. Additionally, it accepts a list of tools that can be employed during the chat process. The function is expected to return a ChatCompletionMessage, which encapsulates the response generated from the chat interaction.\n\nThis function plays a crucial role in various methods across the project, serving as a core component for generating responses based on user queries. For instance, in the ReportBenchmark class, the common_chat function is invoked in methods such as run_fact_extraction and run_factualqa. In these contexts, it processes prompts that are dynamically created from templates and user data, ensuring that the responses are contextually relevant and accurate.\n\nMoreover, the common_chat function is also utilized in the ReportEvaluation class, specifically in methods like examinees_outline_generation and evaluate_factualqa. Here, it aids in generating outlines and evaluations based on student reports and user queries, demonstrating its versatility in handling different types of interactions.\n\nIn the context of the BaseAgent class, the common_chat function is called by other methods such as update_answer and model_confident. These methods leverage common_chat to obtain responses that are then used to update previous answers or assess the model's confidence in its responses.\n\nOverall, the common_chat function serves as a foundational element in the communication framework of the project, enabling seamless interactions between users and the system while ensuring that the responses are generated based on the provided prompts and tools.\n\n**Note**: It is important to ensure that the usr_prompt is well-formed and relevant to the context of the conversation to receive meaningful responses. Additionally, the tools parameter should be populated with appropriate tools that can enhance the chat interaction if needed."
      ],
      "code_start_line": 103,
      "code_end_line": 103,
      "params": [
        "self",
        "usr_prompt",
        "tools"
      ],
      "have_return": false,
      "code_content": "    def common_chat(self, usr_prompt: str, tools: List) -> ChatCompletionMessage: ...\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "common_chat",
      "md_content": [
        "**common_chat**: The function of common_chat is to facilitate a conversation with the user by processing a given prompt and returning a response.\n\n**parameters**: The parameters of this Function.\n· usr_prompt: A string that contains the user's prompt or query that needs to be processed.\n· tools: An optional parameter that can be set to None, which may be used to specify additional tools for processing the prompt.\n\n**Code Description**: The common_chat function is designed to handle user interactions by taking a user prompt as input and generating a response. It is a core component of the BaseAgent class, which serves as a foundational element for various agents in the project. The function is invoked in multiple contexts throughout the project, primarily within methods that require interaction with the user or the processing of user queries.\n\nFor instance, in the ReportBenchmark class, the common_chat function is called within the run_fact_extraction and run_factualqa methods. In these cases, it processes a rendered template prompt that includes user queries and relevant data, returning a response that is expected to be in a specific format (e.g., JSON). If the response is not in the expected format or is empty, exceptions are raised to handle these scenarios appropriately.\n\nSimilarly, in the ReportEvaluation class, methods such as examinees_outline_generation and evaluate_factualqa also utilize common_chat to generate responses based on user queries. The responses from common_chat are critical for further processing and evaluation, as they often serve as input for subsequent logic or decision-making steps.\n\nThe function is also utilized in the update_answer and model_confident methods of the BaseAgent class, where it processes prompts related to updating answers based on user feedback and checking the model's confidence in its responses.\n\nOverall, common_chat acts as a communication bridge between the user and the agent, ensuring that user queries are effectively processed and that the agents can respond appropriately based on the context provided.\n\n**Note**: When using the common_chat function, it is essential to ensure that the usr_prompt is well-formed and that any expected tools are correctly specified if applicable. Proper error handling should be implemented to manage cases where the response does not meet the expected criteria."
      ],
      "code_start_line": 106,
      "code_end_line": 106,
      "params": [
        "self",
        "usr_prompt",
        "tools"
      ],
      "have_return": false,
      "code_content": "    def common_chat(self, usr_prompt: str, tools: None = None) -> str: ...\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "common_chat",
      "md_content": [
        "**common_chat**: The function of common_chat is to facilitate interaction with a language model by sending user prompts and managing the conversation history.\n\n**parameters**: The parameters of this Function.\n· usr_prompt: A string or list representing the user's prompt to the language model.\n· tools: An optional list of tools that can be utilized during the interaction.\n· role: A string indicating the role of the entity sending the message, defaulting to \"assistant\".\n\n**Code Description**: The common_chat function is designed to interact with a language model by sending a user-defined prompt and processing the response. It first calls the call_llm function, which handles the communication with the language model API. This function takes the model specified in the settings, the user prompt, and any tools that may be needed for the interaction.\n\nIf tools are provided, the function returns the model's response directly without appending it to the conversation history. However, if no tools are specified, the response content is appended to the conversation history managed by the BaseAgent's conversation_manager, using the specified role (defaulting to \"assistant\"). The function ultimately returns the content of the model's response.\n\nThe common_chat function is called by various methods throughout the project, including:\n- In the attempt method of the ReportBenchmark class, where it generates a prompt based on a template and user query, then retrieves a response from the language model.\n- In the run_factualqa method, where it similarly generates a prompt for factual question answering and retrieves the model's response.\n- In the examinees_outline_generation and evaluate_factualqa methods, where it generates prompts for outline generation and factual question evaluation, respectively.\n- In the update_answer and model_confident methods, where it is used to update answers based on user queries and to check the model's confidence in its responses.\n- In the search_and_browse method, where it interacts with tools for searching and browsing based on the rendered prompt.\n\nThis function plays a critical role in maintaining the flow of conversation and ensuring that responses from the language model are appropriately handled and recorded.\n\n**Note**: It is important to ensure that the usr_prompt is well-formed and that the tools, if used, are compatible with the language model being called. The function's behavior may vary based on whether tools are provided or not, affecting how the response is processed and stored.\n\n**Output Example**: A possible return value from the common_chat function could be a string such as \"The capital of France is Paris.\" or a structured response from the language model, depending on the prompt and context provided."
      ],
      "code_start_line": 108,
      "code_end_line": 131,
      "params": [
        "self",
        "usr_prompt",
        "tools",
        "role"
      ],
      "have_return": true,
      "code_content": "    def common_chat(\n        self,\n        usr_prompt: str | List,\n        tools: Optional[List] = None,\n        role: str = \"assistant\",\n    ) -> ChatCompletionMessage | str | None:\n        llm_response = call_llm(\n            model=settings.default_model,\n            usr_prompt=usr_prompt,\n            config=settings,\n            tools=tools,\n        )\n\n        # logger.info(f\"usr_prompt:\\n{usr_prompt}\")\n        # logger.info(f\"llm_response:\\n{llm_response}\")\n\n        if tools is not None:\n            return llm_response\n\n        BaseAgent.conversation_manager.append_to_history(\n            role=role, content=llm_response.content\n        )\n\n        return llm_response.content\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "report_benchmark.py/ReportBenchmark/run_fact_extraction/process_section/attempt",
        "report_benchmark.py/ReportBenchmark/run_factualqa",
        "report_evaluation.py/ReportEvaluation/examinees_outline_generation",
        "report_evaluation.py/ReportEvaluation/evaluate_factualqa",
        "report_evaluation.py/ReportEvaluation/extract_student_tree_structure",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/llm_service.py/call_llm",
        "src/criticsearch/models.py/ConversationManager/append_to_history"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "update_answer",
      "md_content": [
        "**update_answer**: The function of update_answer is to update the agent's response based on a new query, previous answer, search results, and feedback from a critic.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the new question or query that the agent needs to address.  \n· previous_answer: A string containing the previous answer provided by the agent to the query.  \n· search_results: A string or data structure that holds the results obtained from a search operation related to the query.  \n· critic_feedback: A string containing feedback from a critic that may influence the update of the answer.\n\n**Code Description**: The update_answer function is designed to refine the agent's response to a user query by incorporating new information and feedback. The function begins by organizing the input parameters into a dictionary named `data`, which includes the current query, the previous answer, the search results, and the critic's feedback. \n\nNext, the function calls the load_template method to retrieve a specific template file named \"agent_update_answer.txt\". This template is expected to contain a structured format for generating a prompt that will be sent to the conversational model. The retrieved template is then rendered using the render_template method, which replaces placeholders in the template with the actual values from the `data` dictionary. This step ensures that the prompt is contextually relevant and tailored to the current interaction.\n\nAfter rendering the prompt, the function invokes the common_chat method, passing the rendered prompt as an argument. This method facilitates communication with the language model, sending the prompt and receiving a response. The response generated by the common_chat method is then returned as the output of the update_answer function.\n\nThe update_answer function is called within the main function of the project, specifically during the iterative process of refining answers based on user queries and feedback from a critic agent. In the main function, after the initial answer is generated, the update_answer function is invoked to incorporate the latest search results and feedback from the critic. This iterative approach allows the agent to improve its responses over multiple iterations, ensuring that the final answer is well-informed and aligned with user expectations.\n\n**Note**: It is essential to ensure that the parameters passed to the update_answer function are valid and appropriately formatted. The function relies on the successful loading of the template and the proper functioning of the common_chat method to generate an accurate response.\n\n**Output Example**: A possible return value from the update_answer function could be a string such as \"Based on the latest search results and feedback, the updated answer is: [new answer].\" This output reflects the agent's refined response after considering the provided inputs."
      ],
      "code_start_line": 133,
      "code_end_line": 146,
      "params": [
        "self",
        "query",
        "previous_answer",
        "search_results",
        "critic_feedback"
      ],
      "have_return": true,
      "code_content": "    def update_answer(self, query, previous_answer, search_results, critic_feedback):\n        data = {\n            \"query\": query,\n            \"previous_answer\": previous_answer,\n            \"search_results\": search_results,\n            \"critic_feedback\": critic_feedback,\n        }\n\n        agent_update_answer_prompt = self.load_template(\"agent_update_answer.txt\")\n        rendered_prompt = self.render_template(agent_update_answer_prompt, data)\n\n        agent_update_answer_response = self.common_chat(usr_prompt=rendered_prompt)\n\n        return agent_update_answer_response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "model_confident",
      "md_content": [
        "**model_confident**: The function of model_confident is to check whether the model is confident in its response to the current user query.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the user's question that needs to be evaluated for model confidence.\n\n**Code Description**: The model_confident function is designed to assess the confidence level of the model regarding a specific user query. It begins by constructing a data dictionary that includes the user's question under the key \"user_question\". The function then loads a confidence assessment template from a file named \"agent_confidence.txt\" using the load_template method. This template serves as a structured prompt for the model to evaluate its confidence.\n\nNext, the function renders the loaded template by passing the data dictionary to the render_template method, which replaces any placeholders in the template with the corresponding values from the dictionary. The rendered prompt is then sent to the model through the common_chat method, which facilitates the interaction with the model and retrieves the response.\n\nThe response obtained from common_chat is returned as the output of the model_confident function. This output indicates the model's confidence level regarding the provided query.\n\nThe model_confident function is called within the main function of the project, specifically during the first iteration of a loop that manages multiple interactions with the model. In this context, it is used to determine whether the model is confident enough to provide an answer directly or if further actions, such as searching for additional information, are necessary. If the model is deemed confident, the common_chat function is invoked to obtain the answer. Conversely, if the model lacks confidence, the process involves generating a search prompt and retrieving supplementary data before answering the user.\n\n**Note**: It is essential to ensure that the query parameter passed to the model_confident function is well-formed and relevant to the context of the conversation to receive an accurate confidence assessment.\n\n**Output Example**: A possible return value from the model_confident function could be a string indicating the model's confidence level, such as \"true\" or \"false\", depending on the evaluation of the user query."
      ],
      "code_start_line": 148,
      "code_end_line": 158,
      "params": [
        "self",
        "query"
      ],
      "have_return": true,
      "code_content": "    def model_confident(self, query):\n        \"\"\"\n        检查模型是否对当前问题有信心。\n        \"\"\"\n        data = {\"user_question\": query}\n        agent_confidence_prompt = self.load_template(\"agent_confidence.txt\")\n\n        rendered_prompt = self.render_template(agent_confidence_prompt, data)\n        agent_confidence_response = self.common_chat(usr_prompt=rendered_prompt)\n\n        return agent_confidence_response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "search_and_browse",
      "md_content": [
        "**search_and_browse**: The function of search_and_browse is to perform a search and web scraping operation based on a rendered prompt, returning the final results as a string.\n\n**parameters**: The parameters of this Function.\n· rendered_prompt: A string that contains the prompt to be processed for searching and browsing.\n\n**Code Description**: The search_and_browse function is a method within the BaseAgent class that orchestrates a two-step process: searching for information using a search aggregator and then scraping content from the web based on the search results. \n\n1. The function begins by invoking the common_chat method with the provided rendered_prompt and the search_aggregator_schema. This interaction initiates a search operation, and the response is logged for debugging purposes.\n\n2. If the search_with_tool_response indicates that no tool calls were made, the function immediately returns the content of the response. This allows for quick exit when no further action is necessary.\n\n3. If tool calls are present, the function appends these calls to the conversation history using the append_tool_call_to_history method. This ensures that all interactions with tools are recorded for future reference.\n\n4. The function then initializes an empty string to accumulate the final search results. It iterates over each tool call, extracting the query from the tool call's arguments. For each query, it calls the search method of the search_aggregator to perform the search asynchronously.\n\n5. After a brief pause to manage rate limits, the results from each search are appended to the conversation history using append_tool_call_result_to_history, and the query is updated in the query database.\n\n6. Once all search results are collected, the function loads a web scraper template and renders it with the user's question and the initial search results. This rendered prompt is then sent to the common_chat method to interact with the content scraper.\n\n7. Similar to the search step, if the web_scraper_response contains no tool calls, the function returns the content directly. If tool calls are present, they are appended to the conversation history.\n\n8. The function then processes each tool call related to web scraping, extracting URLs from the arguments and calling the scrape method of the content scraper to gather content from these URLs.\n\n9. The results from the scraping operation are also logged into the conversation history, and the final results are concatenated into a single string, which is returned at the end of the function.\n\nThe search_and_browse function is called within the main function of the project, specifically when the agent is not confident in its initial answer and needs to gather additional information through searching and scraping. This highlights its role in enhancing the agent's ability to provide accurate and relevant responses based on real-time data.\n\n**Note**: It is essential to ensure that the rendered_prompt is well-formed and contains relevant queries for both the search and scraping processes to function effectively. Additionally, proper error handling should be implemented to manage cases where the search or scraping operations do not yield results.\n\n**Output Example**: A possible return value of the search_and_browse function could be a string formatted as follows:\n```\n\"Here are the results from your search: 1. Title: Example Article, URL: http://example.com/article1, Content: This is a summary of the article. 2. Title: Another Example, URL: http://example.com/article2, Content: This is another summary.\"\n```"
      ],
      "code_start_line": 160,
      "code_end_line": 232,
      "params": [
        "self",
        "rendered_prompt"
      ],
      "have_return": true,
      "code_content": "    def search_and_browse(self, rendered_prompt) -> str | None:\n        search_with_tool_response = self.common_chat(\n            usr_prompt=rendered_prompt, tools=self.search_aggregator_schema\n        )\n\n        logger.info(f\"search_with_tool_response:\\n{search_with_tool_response}\")\n\n        # If no tool calls, return the response immediately\n        if search_with_tool_response.tool_calls is None:\n            return search_with_tool_response.content\n\n        BaseAgent.conversation_manager.append_tool_call_to_history(\n            search_with_tool_response.tool_calls\n        )\n\n        final_search_results = \"\"\n\n        for tool_call in search_with_tool_response.tool_calls:\n            query = json.loads(tool_call.function.arguments).get(\"query\", \"\")\n\n            search_results = asyncio.run(self.search_aggregator.search(query=query))\n\n            time.sleep(1)\n\n            BaseAgent.conversation_manager.append_tool_call_result_to_history(\n                tool_call_id=tool_call.id,\n                name=\"search\",\n                content=search_results,\n            )\n\n            BaseAgent.queryDB.update(query)\n\n            final_search_results += f\"{search_results}\"\n\n        web_scraper_prompt = self.load_template(\"web_scraper.txt\")\n        web_scraper_rendered_prompt = self.render_template(\n            web_scraper_prompt,\n            {\n                \"user_question\": self.user_question,\n                \"initial_search_results\": final_search_results,\n            },\n        )\n\n        # Interact with the model for web scraping\n        web_scraper_response = self.common_chat(\n            usr_prompt=web_scraper_rendered_prompt,\n            tools=self.content_scraper_schema,\n        )\n\n        # If no tool calls, return the response immediately\n        if web_scraper_response.tool_calls is None:\n            return web_scraper_response.content\n\n        BaseAgent.conversation_manager.append_tool_call_to_history(\n            web_scraper_response.tool_calls\n        )\n\n        final_web_scraper_results = \"\"\n\n        for tool_call in web_scraper_response.tool_calls:\n            urls = json.loads(tool_call.function.arguments).get(\"urls\", [])\n\n            web_scraper_results = asyncio.run(self.content_scraper.scrape(urls=urls))\n\n            BaseAgent.conversation_manager.append_tool_call_result_to_history(\n                tool_call_id=tool_call.id,\n                name=\"scrape\",\n                content=web_scraper_results,  # type: ignore\n            )\n\n            final_web_scraper_results += web_scraper_results  # type: ignore\n\n        return final_web_scraper_results\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)",
        "src/criticsearch/models.py/ConversationManager/append_tool_call_to_history",
        "src/criticsearch/models.py/ConversationManager/append_tool_call_result_to_history",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/search"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "receive_task",
      "md_content": [
        "**receive_task**: The function of receive_task is to accept and store the original task provided to the agent.\n\n**parameters**: The parameters of this Function.\n· task: The original task that needs to be received and stored by the agent.\n\n**Code Description**: The receive_task function is a method of the BaseAgent class, designed to receive a task as input and store it in the instance variable original_task. This function is crucial for the operation of the agent, as it allows the agent to keep track of the task it is currently handling. When the function is called, it takes the task parameter and assigns it to the instance variable self.original_task, effectively saving the task for future reference or processing.\n\nIn the context of the project, the receive_task function is invoked by the CriticAgent within the main function of the application. Specifically, after the common agent generates an answer to the user's question, the CriticAgent receives the original task (TASK) using the receive_task method. This step is essential for the CriticAgent to evaluate the performance of the common agent based on the task it was given. By storing the original task, the CriticAgent can provide feedback and suggestions for improvement, thereby enhancing the overall interaction and effectiveness of the agents involved in the task processing.\n\n**Note**: It is important to ensure that the task passed to the receive_task function is well-defined and relevant to the agent's capabilities, as this will directly influence the quality of the agent's performance and the feedback provided by the CriticAgent."
      ],
      "code_start_line": 234,
      "code_end_line": 238,
      "params": [
        "self",
        "task"
      ],
      "have_return": false,
      "code_content": "    def receive_task(self, task):\n        \"\"\"\n        接收原始任务。\n        \"\"\"\n        self.original_task = task\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "extract_and_validate_yaml",
      "md_content": [
        "**extract_and_validate_yaml**: The function of extract_and_validate_yaml is to extract YAML content from a string and validate it.\n\n**parameters**: The parameters of this Function.\n· model_response: A string containing the response from a model which may include YAML content wrapped in code block markers.\n\n**Code Description**: \nThe function `extract_and_validate_yaml` is designed to extract YAML data from a given string, `model_response`, and return it in a structured format if valid. It performs the following steps:\n\n1. **Regular Expression Matching**: The function begins by using a regular expression to search for content between triple backticks ` ```yaml ` and ` ``` `, which is expected to be YAML content. The regular expression `r\"```yaml\\n([\\s\\S]*?)\\n```\"` is used to identify the YAML content enclosed within the code block. If no match is found, it returns `None`.\n\n2. **YAML Parsing**: Once the YAML content is extracted, the function attempts to parse it using `yaml.safe_load`. This function safely loads the YAML content into a Python dictionary or data structure. If the content is not valid YAML, a `yaml.YAMLError` is caught and the error message is printed, returning `None`.\n\n3. **Formatting and Returning**: If the YAML content is successfully parsed, it is re-serialized into a YAML formatted string using `yaml.dump`, and the result is returned. This output is presented in a human-readable YAML format, with the default flow style set to `False`.\n\nIn the context of the broader project, this function is typically used in situations where model responses or other content need to be processed for YAML data. For example, in the `critic` method of the `CriticAgent` class, this function is called to extract and validate YAML content from a model response. Similarly, in the `main` function, it is used to process agent confidence data in YAML format.\n\n**Note**: It is important to ensure that the model response contains valid YAML content, as invalid or improperly formatted YAML will cause the function to return `None` and may trigger error handling in the calling code.\n\n**Output Example**: \nGiven a valid `model_response` such as:\n\n```\n```yaml\nconfidence: true\n```\n```\n\nThe function would return:\n\n```\nconfidence: true\n```"
      ],
      "code_start_line": 240,
      "code_end_line": 258,
      "params": [
        "self",
        "model_response"
      ],
      "have_return": true,
      "code_content": "    def extract_and_validate_yaml(self, model_response):\n        # 正则表达式匹配包裹在```yaml```之间的内容\n        import re\n\n        match = re.search(r\"```yaml\\n([\\s\\S]*?)\\n```\", model_response, re.DOTALL)\n\n        if not match:\n            return None  # 如果没有找到匹配的内容，返回None\n\n        model_response = match.group(1).strip()\n\n        try:\n            # 尝试解析YAML内容\n            parsed_yaml = yaml.safe_load(model_response)\n            return yaml.dump(parsed_yaml, default_flow_style=False)\n\n        except yaml.YAMLError as exc:\n            print(f\"Invalid YAML content: {exc}\")\n            return None\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/__init__.py": [],
  "src/criticsearch/log.py": [
    {
      "type": "ClassDef",
      "name": "InterceptHandler",
      "md_content": [
        "**InterceptHandler**: The function of InterceptHandler is to redirect standard logging messages to the Loguru logging system, allowing for consistent log handling across the application.\n\n**attributes**: The attributes of this Class.\n· record: logging.LogRecord - This parameter represents the log record containing all the information pertinent to the event being logged.\n\n**Code Description**: The InterceptHandler class extends the logging.Handler class to facilitate the integration of Python's standard logging module with the Loguru logging system. The primary function of this class is to override the emit method, which is responsible for processing log records. \n\nWhen a log record is emitted, the emit method first attempts to map the standard logging level (record.levelname) to the corresponding Loguru level using the logger.level method. If the level cannot be found, it defaults to using the numeric level (record.levelno). \n\nNext, the method identifies the caller of the log message by traversing the call stack using inspect.currentframe(). This is done to determine the depth of the call, which helps in providing context for the log message. The depth is incremented until it reaches a frame that is not part of the logging module itself.\n\nFinally, the log message is logged using Loguru's logger.opt method, which allows for additional options such as depth and exception information to be included. This ensures that the log message is formatted and handled according to Loguru's capabilities, providing a more powerful logging experience.\n\nThe InterceptHandler is utilized within the set_logger_level_from_config function, which configures the Loguru logger based on the specified log level. This function removes any existing Loguru handlers, sets up new handlers for different log levels, and ultimately redirects standard logging output to the Loguru system using the InterceptHandler. This integration allows all logging, whether from standard logging or Loguru, to be managed uniformly, enhancing the application's logging consistency and effectiveness.\n\n**Note**: It is important to ensure that the InterceptHandler is properly instantiated and passed to the logging.basicConfig function to effectively redirect standard logging output to Loguru. Additionally, users should be aware of the log levels being set and how they correspond to Loguru's logging levels to avoid any confusion in log output."
      ],
      "code_start_line": 14,
      "code_end_line": 31,
      "params": [],
      "have_return": false,
      "code_content": "class InterceptHandler(logging.Handler):\n    def emit(self, record: logging.LogRecord) -> None:\n        # Get corresponding Loguru level if it exists.\n        level: str | int\n        try:\n            level = logger.level(record.levelname).name\n        except ValueError:\n            level = record.levelno\n\n        # Find caller from where originated the logged message.\n        frame, depth = inspect.currentframe(), 0\n        while frame and (depth == 0 or frame.f_code.co_filename == logging.__file__):\n            frame = frame.f_back\n            depth += 1\n\n        logger.opt(depth=depth, exception=record.exc_info).log(\n            level, record.getMessage()\n        )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/log.py/set_logger_level_from_config"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "emit",
      "md_content": [
        "**emit**: The function of emit is to process and log a message using the Loguru logger while capturing the log level and caller information.\n\n**parameters**: \n- record: logging.LogRecord - This parameter holds the log record containing information about the event being logged, such as the log level, message, and associated exception information.\n\n**Code Description**: \nThe `emit` function processes the incoming log record and logs the message using the Loguru logger. The function first attempts to map the standard Python logging log level to a corresponding Loguru log level. If the log level is not recognized, it falls back to using the numeric level value.\n\nThe code then inspects the call stack to determine the caller information that originated the log message. This is achieved by traversing the call stack with the help of the `inspect.currentframe()` method. The function skips frames that belong to the `logging` module, focusing on the caller that generated the log message.\n\nFinally, the function uses Loguru’s `opt()` method to adjust the depth (indicating the call stack level) and exception information before logging the message with the appropriate level. The log message is retrieved from the `record` object using `record.getMessage()`.\n\n**Note**: \n- The `logger.level(record.levelname).name` method is used to map the standard logging levels (such as 'INFO', 'ERROR') to the corresponding Loguru levels. If a matching level cannot be found, the function uses the `record.levelno` numeric value to log the message.\n- The `inspect.currentframe()` method is used to inspect the current stack trace. The `depth` parameter ensures the correct caller's frame is identified, avoiding frames related to the logging module itself.\n- The `logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())` is responsible for sending the log message to Loguru with additional contextual information like depth and exception details."
      ],
      "code_start_line": 15,
      "code_end_line": 31,
      "params": [
        "self",
        "record"
      ],
      "have_return": false,
      "code_content": "    def emit(self, record: logging.LogRecord) -> None:\n        # Get corresponding Loguru level if it exists.\n        level: str | int\n        try:\n            level = logger.level(record.levelname).name\n        except ValueError:\n            level = record.levelno\n\n        # Find caller from where originated the logged message.\n        frame, depth = inspect.currentframe(), 0\n        while frame and (depth == 0 or frame.f_code.co_filename == logging.__file__):\n            frame = frame.f_back\n            depth += 1\n\n        logger.opt(depth=depth, exception=record.exc_info).log(\n            level, record.getMessage()\n        )\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "set_logger_level_from_config",
      "md_content": [
        "## Function: `set_logger_level_from_config`\n\n### Description:\nThe `set_logger_level_from_config` function configures the logging behavior for the application by setting up the **Loguru** logger with the specified log level. It also integrates **Loguru** with Python's standard logging module to ensure consistent logging across the application.\n\n### Arguments:\n- `log_level` (str): A string representing the desired log level for **Loguru** (e.g., `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`). The function will configure the logger to output logs at this level.\n\n### Functionality:\n- **Loguru Logger Configuration**: \n  - The function first removes any existing handlers from **Loguru** to ensure that the logger starts with a clean configuration.\n  - It then adds a new handler that directs log output to **stderr** and configures the log level based on the provided `log_level`.\n  - Additional parameters:\n    - `enqueue=True`: Ensures that logs are handled in a thread-safe manner using a queue.\n    - `backtrace=False`: Disables detailed tracebacks to prevent excessively verbose logs.\n    - `diagnose=False`: Suppresses extra diagnostic information from **Loguru** to keep the logs concise.\n    - `filter=lambda record: record[\"level\"].name != \"SUCCESS\"`: Filters out logs with the `\"SUCCESS\"` level from this handler.\n\n- **Success Log Format**: \n  - A specific format for `\"SUCCESS\"` level logs is defined, which includes:\n    - A timestamp (`YYYY-MM-DD HH:mm:ss.SSS`),\n    - Log level,\n    - Module, function, and line number from where the log was generated,\n    - The log message itself.\n\n- **Handling `\"SUCCESS\"` Logs**: \n  - A separate handler is added for **Loguru** to handle logs at the `\"SUCCESS\"` level, ensuring that they follow the defined success log format.\n\n- **File-based Logging**:\n  - A file handler is added that writes logs to a file (`output.txt`) with the specified `log_level`.\n  - This file logging does not split logs into multiple files (i.e., no rotation) and does not retain old logs.\n\n- **Standard Logging Integration**:\n  - The function uses the `InterceptHandler` class to intercept logs from Python's standard logging module and redirect them to **Loguru**. This ensures that both **Loguru** and standard logging are handled consistently.\n\n- **Log Message**: \n  - Once the logger is configured, a success message is logged using the `\"SUCCESS\"` level, indicating the log level that has been set.\n\n### Example Usage:\n```python\nset_logger_level_from_config(log_level=\"INFO\")\n```\n\nThis would configure **Loguru** to output logs at the `\"INFO\"` level and redirect standard logging messages to **Loguru** as well."
      ],
      "code_start_line": 34,
      "code_end_line": 92,
      "params": [
        "log_level"
      ],
      "have_return": false,
      "code_content": "def set_logger_level_from_config(log_level):\n    \"\"\"\n    Configures the loguru logger with specified log level and integrates it with the standard logging module.\n\n    Args:\n        log_level (str): The log level to set for loguru (e.g., \"DEBUG\", \"INFO\", \"WARNING\").\n\n    This function:\n    - Removes any existing loguru handlers to ensure a clean slate.\n    - Adds a new handler to loguru, directing output to stderr with the specified level.\n      - `enqueue=True` ensures thread-safe logging by using a queue, helpful in multi-threaded contexts.\n      - `backtrace=False` minimizes detailed traceback to prevent overly verbose output.\n      - `diagnose=False` suppresses additional loguru diagnostic information for more concise logs.\n    - Redirects the standard logging output to loguru using the InterceptHandler, allowing loguru to handle\n      all logs consistently across the application.\n    \"\"\"\n    logger.remove()\n    logger.add(\n        sys.stderr,\n        level=log_level,\n        enqueue=True,\n        backtrace=False,\n        diagnose=False,\n        filter=lambda record: record[\"level\"].name != \"SUCCESS\",\n    )\n    success_format = (\n        \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"  # 时间格式\n        \"<level>{level: <8}</level> | \"  # 日志级别\n        \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - \"  # 模块、函数、行号\n        \"<bold>{message}</bold>\"  # 日志消息\n    )\n\n    # SUCCESS 特定格式输出\n    logger.add(\n        sink=sys.stderr,\n        level=\"SUCCESS\",  # 针对 SUCCESS 日志\n        format=success_format,\n        filter=lambda record: record[\"level\"].name == \"SUCCESS\",  # 仅过滤 SUCCESS 日志\n        enqueue=True,\n        backtrace=False,\n        diagnose=False,\n    )\n\n    logger.add(\n        \"output.txt\",\n        level=log_level,\n        enqueue=True,\n        backtrace=False,\n        diagnose=False,\n        rotation=None,  # 不进行文件分割\n        retention=None,  # 不保留旧日志\n        format=\"{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}\",\n        mode=\"w\",  # 每次覆盖文件\n    )\n\n    # Intercept standard logging\n    logging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)\n\n    logger.success(f\"Log level set to {log_level}!\")\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/log.py/InterceptHandler"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "colorize_message",
      "md_content": [
        "**colorize_message**: The function of colorize_message is to format and log messages with specified colors and styles for better visibility in the output.\n\n**parameters**: The parameters of this Function.\n· message_title: An optional string that serves as the title of the message to be logged. Default is an empty string.\n· color: A literal string that specifies the color of the message. It can be one of the following values: \"black\", \"blue\", \"cyan\", \"green\", \"magenta\", \"red\", \"white\", or \"yellow\". Default is \"black\".\n· style: A literal string that defines the style of the message. It can be \"bold\", \"dim\", \"normal\", \"italic\", or \"underline\". Default is \"normal\".\n· message_content: An optional parameter that can either be a string or a dictionary. It contains the content of the message to be logged. Default is an empty string.\n\n**Code Description**: The colorize_message function is designed to enhance the logging experience by allowing developers to specify both the color and style of the messages being logged. The function begins by determining the appropriate opening tags for the specified color and style. If both are provided, it generates a closing tag accordingly. \n\nThe function then constructs a styled title using the provided message_title, surrounded by equal signs for visual emphasis. If message_content is a dictionary, it formats it as a JSON string for better readability; otherwise, it converts it to a string. Finally, the function logs the formatted message using the logger's success method, ensuring that the title and content are displayed clearly.\n\nThis function is called multiple times within the main function of the project, specifically during the iterative process of handling tasks. It is used to log significant events such as the start of iterations, the common agent's answers, and the responses from the critic agent. By utilizing colorize_message, the output becomes more organized and visually distinct, aiding developers in tracking the flow of information and the status of various processes throughout the execution of the program.\n\n**Note**: It is important to ensure that the color and style parameters are chosen appropriately to maintain readability in the output. Additionally, the message_content should be formatted correctly to avoid any logging errors."
      ],
      "code_start_line": 95,
      "code_end_line": 134,
      "params": [
        "message_title",
        "color",
        "style",
        "message_content"
      ],
      "have_return": false,
      "code_content": "def colorize_message(\n    message_title: Optional[str] = \"\",\n    color: Literal[\n        \"black\", \"blue\", \"cyan\", \"green\", \"magenta\", \"red\", \"white\", \"yellow\"\n    ] = \"black\",\n    style: Literal[\"bold\", \"dim\", \"normal\", \"italic\", \"underline\"] = \"normal\",\n    message_content: Optional[str] | Dict = \"\",\n):\n    # Open and close tags for color and style\n    color_tag = f\"<{color}>\" if color else \"\"\n    style_tag = f\"<{style}>\" if style != \"normal\" else \"\"\n\n    # Generate the closing tag properly\n    close_tag = \"\"\n    if color_tag and style_tag:\n        close_tag = \"</></>\"\n    elif color_tag:\n        close_tag = \"</>\"\n    elif style_tag:\n        close_tag = \"</>\"\n\n    # Styled title\n    styled_title = (\n        f\"{style_tag}{color_tag}{'=' * 20} {message_title} {'=' * 20}{close_tag}\"\n        if message_title\n        else \"\"\n    )\n\n    # Format content\n    if isinstance(message_content, Dict):\n        formatted_content = json.dumps(message_content, ensure_ascii=True, indent=2)\n    else:\n        formatted_content = str(message_content) if message_content else \"\"\n\n    # Log the message\n    logger.success(\n        f\"\\n{styled_title}\\n{formatted_content}\\n\"\n        if formatted_content\n        else f\"\\n{styled_title}\\n\"\n    )\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/config.py": [],
  "src/criticsearch/models.py": [
    {
      "type": "ClassDef",
      "name": "HistoryItem",
      "md_content": [
        "**HistoryItem**: The function of HistoryItem is to represent an individual entry in a conversation history.\n\n**attributes**: The attributes of this Class.\n· role: Literal[\"user\", \"assistant\", \"tool\", \"critic\"]  \n   This attribute defines the role of the entity in the conversation, such as \"user\", \"assistant\", \"tool\", or \"critic\". The role helps categorize the message within the conversation history.  \n· content: Optional[str]  \n   This attribute holds the actual content of the message. It is optional and may be `None` if not provided.  \n· tool_calls: Optional[List[ChatCompletionMessageToolCall]]  \n   This attribute stores a list of tool calls associated with the message. It is optional and only used when the message involves invoking tools.  \n· tool_call_id: Optional[str]  \n   This attribute holds a unique identifier for a tool call. It is optional and is used to track the specific tool call in case the message involves a tool.  \n· name: Optional[str]  \n   This attribute is used to store the name associated with the history item. It is optional and can be used to provide additional context about the message.\n\n**Code Description**:  \nThe `HistoryItem` class is a data model that encapsulates a single entry within a conversation. It has a `role` attribute that defines who or what is contributing to the conversation, such as the user, assistant, tool, or critic. The `content` attribute contains the message's text, and it can be optional if no message content is provided. The `tool_calls` attribute, also optional, is used when a message involves calling a tool or a function, storing details about the tool calls made. Similarly, the `tool_call_id` serves as a unique identifier for each tool call, providing a way to trace or reference specific tool interactions. Finally, the `name` attribute can store a custom name for the entry, providing further context if required.\n\nThis class plays a vital role in managing conversation history, particularly in the context of applications where various entities interact through a series of messages. It integrates directly with the `ConversationManager` class, which manages the overall conversation history and tools used within it. Specifically, the `HistoryItem` class is used when appending new entries to the conversation history, either through regular messages or tool calls, ensuring that each entry is well-defined with relevant context (such as role, content, tool calls, etc.).\n\nIn the `ConversationManager` class, the `HistoryItem` is instantiated and appended to the `history` attribute whenever a new message is added to the conversation. For instance, the `append_to_history` method in `ConversationManager` creates a new `HistoryItem` with the given role and content, and then adds it to the history list. The `serialize_history` method, which handles the serialization of the conversation history, processes these `HistoryItem` instances to ensure that the history is accurately saved, potentially excluding any `None` values during serialization.\n\nFurthermore, in specific cases where tool calls are involved, the `HistoryItem` can hold a list of `tool_calls` and a `tool_call_id`, providing a way to capture the specific details of any tools or functions invoked during the conversation.\n\n**Note**:  \n- The `content` attribute can be omitted for certain roles, such as \"tool\" or \"critic\", where the primary focus is on the interaction rather than the message content.  \n- The use of `tool_calls` and `tool_call_id` is essential when the conversation involves automated tools or functions, ensuring that these interactions are tracked and referenced correctly.  \n- The optional nature of many attributes (like `content`, `tool_calls`, `tool_call_id`, and `name`) allows for flexibility, enabling this class to accommodate various types of messages and interactions in a conversation history."
      ],
      "code_start_line": 20,
      "code_end_line": 25,
      "params": [],
      "have_return": false,
      "code_content": "class HistoryItem(BaseModel):\n    role: Literal[\"user\", \"assistant\", \"tool\", \"critic\"]\n    content: Optional[str] = None\n    tool_calls: Optional[List[ChatCompletionMessageToolCall]] = None\n    tool_call_id: Optional[str] = None\n    name: Optional[str] = None\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/models.py/ConversationManager",
        "src/criticsearch/models.py/ConversationManager/serialize_history",
        "src/criticsearch/models.py/ConversationManager/append_to_history"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "ConversationManager",
      "md_content": [
        "**ConversationManager**: The function of ConversationManager is to manage and maintain the conversation history, including the ability to serialize this history, append new messages, and handle tool calls within the conversation.\n\n**attributes**: The attributes of this Class.\n· history: List[HistoryItem]  \n   This attribute stores the conversation history as a list of HistoryItem instances, which represent individual entries in the conversation.\n\n· max_history_length: int  \n   This attribute defines the maximum number of entries to retain in the conversation history, limiting the size of the history to the most recent entries.\n\n· available_tools: List  \n   This attribute holds a list of tools that can be utilized during the conversation, allowing for integration of various functionalities.\n\n· save_path: Path  \n   This attribute specifies the file path where the conversation history will be saved in JSON Lines format.\n\n· delete_on_init: bool  \n   This attribute is a flag that indicates whether to delete the existing conversation history file upon initialization of the ConversationManager.\n\n**Code Description**: The ConversationManager class is designed to facilitate the management of conversation history in applications that involve interactions between users and automated systems. It extends from BaseModel, allowing it to leverage data modeling capabilities. Upon initialization, the class checks if the specified save_path exists and deletes it if the delete_on_init flag is set to True. This ensures that any previous conversation history is cleared when a new instance is created.\n\nThe class provides methods to append messages to the history, including the append_to_history method, which allows adding new entries with specified roles (user, assistant, tool, or critic) and optional content. It also includes specialized methods for handling tool calls, such as append_tool_call_to_history and append_tool_call_result_to_history, which ensure that interactions with tools are accurately recorded in the history.\n\nSerialization of the conversation history is handled through the serialize_history method, which prepares the history for saving by excluding any None values and limiting the output to the most recent entries based on max_history_length. Additionally, the custom_serialize method allows for context-specific serialization, particularly for formats like ShareGPT, transforming the history into a structured format suitable for sharing.\n\nThe write method is responsible for saving the conversation history to the specified file, handling both the creation of the file and the appending of new data to existing content. The _auto_save method ensures that the most recent entry in the history is automatically saved after each update.\n\nThe ConversationManager is utilized within the BaseAgent class, where it serves as a central component for managing conversation interactions. The BaseAgent class creates an instance of ConversationManager, allowing it to append messages and tool calls to the history as part of its operations. This integration ensures that all interactions, whether user prompts or tool responses, are systematically recorded, providing a comprehensive log of the conversation flow.\n\n**Note**: It is important to ensure that the max_history_length is set appropriately to avoid excessive memory usage, especially in long-running applications. The delete_on_init flag should be used with caution, as it will permanently remove any existing conversation history upon initialization.\n\n**Output Example**: A possible appearance of the code's return value when serializing the conversation history might look like this:\n```json\n{\n  \"conversations\": [\n    {\"from\": \"human\", \"value\": \"Hello, how can I help you?\"},\n    {\"from\": \"function_call\", \"value\": \"{\\\"name\\\": \\\"search\\\", \\\"arguments\\\": {\\\"query\\\": \\\"latest news\\\"}}\"},\n    {\"from\": \"observation\", \"value\": \"{\\\"result\\\": \\\"Here are the latest news articles...\\\"}\"}\n  ],\n  \"tools\": \"[{\\\"name\\\": \\\"search\\\", \\\"description\\\": \\\"Search for information\\\"}]\"\n}\n```"
      ],
      "code_start_line": 29,
      "code_end_line": 191,
      "params": [],
      "have_return": true,
      "code_content": "class ConversationManager(BaseModel):\n    history: List[HistoryItem] = []\n    max_history_length: int = 10  # Limit for conversation history\n    available_tools: List = []\n    save_path: Path = Path(\"conversation_history.jsonl\")\n    delete_on_init: bool = True  # Flag to delete file on initialization\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        if self.delete_on_init and self.save_path.exists():\n            try:\n                self.save_path.unlink()  # Delete the file if it exists\n                logger.info(f\"Deleted existing file: {self.save_path}\")\n            except Exception as e:\n                logger.error(f\"Failed to delete file {self.save_path}: {e}\")\n                raise\n        # Set the flag to False to avoid further deletions\n        self.delete_on_init = False\n\n    @field_serializer(\"history\")\n    def serialize_history(self, history: List[HistoryItem]):\n        serialized_history = []\n        for item in history[-self.max_history_length :]:\n            serialized_history.append(item.model_dump(exclude_none=True))\n        return serialized_history\n\n    @model_serializer(mode=\"wrap\")\n    def custom_serialize(\n        self, handler: SerializerFunctionWrapHandler, info: SerializationInfo\n    ):\n        \"\"\"\n        Custom serialization logic that handles different contexts, such as 'sharegpt'.\n        \"\"\"\n        # Perform default serialization\n        result = handler(self)\n\n        result = result[\"history\"]\n\n        if info.context and info.context.get(\"sharegpt\"):\n            # Transform history into ShareGPT format\n            # TODO: human 和 observation 必须出现在奇数位置，gpt 和 function 必须出现在偶数位置\n            conversations = []\n            for item in self.history:\n                role_mapping = {\n                    \"user\": \"human\",\n                    \"assistant\": \"function_call\",\n                    \"tool\": \"observation\",\n                    \"critic\": \"critic\",\n                }\n\n                role = role_mapping.get(item.role, item.role)\n                value = item.content if item.content else None\n\n                # For tool calls, include the tool_call_id or arguments\n                if role == \"function_call\":\n                    if item.tool_calls:\n                        for tool_call in item.tool_calls:\n                            value = json.dumps(\n                                {\n                                    \"name\": tool_call.function.name,\n                                    \"arguments\": tool_call.function.arguments,\n                                },\n                                ensure_ascii=True,\n                            )\n\n                            conversations.append({\"from\": role, \"value\": value})\n                    else:\n                        conversations.append({\"from\": \"gpt\", \"value\": value})\n\n                elif role == \"observation\":\n                    conversations.append(\n                        {\"from\": role, \"value\": json.dumps(value, ensure_ascii=True)}\n                    )\n\n                else:\n                    conversations.append({\"from\": role, \"value\": value})\n\n            # Build final output structure\n            result = {\n                \"conversations\": conversations,\n                \"tools\": json.dumps(self.available_tools, ensure_ascii=True),\n            }\n\n        return result\n\n    def write(self, data: dict, path: Path | str):\n        if isinstance(path, str):\n            path = Path(path)\n\n        try:\n            # Create parent directories if they do not exist\n            path.parent.mkdir(parents=True, exist_ok=True)\n\n            # Check if the file exists and read existing data\n            if path.exists():\n                with path.open(\"r\", encoding=\"utf-8\") as f:\n                    try:\n                        # Try to parse the existing JSON data (expecting a list at the top level)\n                        existing_data = json.load(f)\n                        if not isinstance(existing_data, list):\n                            existing_data = []  # Ensure it's a list\n                    except json.JSONDecodeError:\n                        # If the file is empty or corrupt, start with an empty list\n                        existing_data = []\n            else:\n                existing_data = []\n\n            # Append the new data to the existing array\n            existing_data.append(data)\n\n            # Write the updated array back to the file\n            with path.open(\"w\", encoding=\"utf-8\") as f:\n                json.dump(existing_data, f, ensure_ascii=True, indent=2)\n\n        except Exception as e:\n            logger.error(f\"Failed to write to {path}: {e}\")\n            raise\n\n    def _auto_save(self):\n        \"\"\"Auto save after each update if save_path is set\"\"\"\n        self.write(\n            path=self.save_path, data=self.history[-1].model_dump(exclude_none=True)\n        )\n\n    def append_to_history(\n        self,\n        role: Literal[\"user\", \"assistant\", \"tool\", \"critic\"],\n        content: Optional[str] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Add a new message to the conversation history.\n        \"\"\"\n        self.history.append(HistoryItem(role=role, content=content, **kwargs))\n        self._auto_save()\n\n        # logger.info(f\"Current history:\\n{self.model_dump()}\")\n\n    def append_tool_call_to_history(\n        self,\n        tool_calls: List[ChatCompletionMessageToolCall],\n        content: Optional[str] = None,\n    ):\n        \"\"\"\n        Add a tool call entry to the conversation history.\n        \"\"\"\n        self.append_to_history(role=\"assistant\", tool_calls=tool_calls, content=content)\n\n    def append_tool_call_result_to_history(\n        self, tool_call_id: str, name: str, content: str\n    ):\n        \"\"\"\n        Add a tool call result to the conversation history.\n        \"\"\"\n        self.append_to_history(\n            role=\"tool\", tool_call_id=tool_call_id, name=name, content=content\n        )\n\n    def clear_history(self):\n        \"\"\"\n        Clear the entire conversation history.\n        \"\"\"\n        self.history.clear()\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py",
        "src/criticsearch/base_agent.py/BaseAgent"
      ],
      "reference_who": [
        "src/criticsearch/models.py/HistoryItem"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the object and manage file deletion if certain conditions are met.\n\n**parameters**: \n· data: This parameter is passed as keyword arguments (**kwargs**) to initialize the base class.\n\n**Code Description**: \nThe `__init__` function in this case is a constructor that serves to initialize an object. It first calls the constructor of the superclass using `super().__init__(**data)` to ensure that any initialization defined in the parent class is executed. The keyword arguments passed to this constructor are forwarded to the parent class.\n\nThe function then checks the condition `if self.delete_on_init and self.save_path.exists()`. If the `delete_on_init` flag is set to `True` and a file at the path specified by `self.save_path` exists, the function attempts to delete the file using `self.save_path.unlink()`. If the file is successfully deleted, a log message is created with the information that the file was deleted. If the deletion operation fails (e.g., due to insufficient permissions or other issues), the function catches the exception and logs an error message containing the exception details.\n\nAfter attempting the deletion, the function sets `self.delete_on_init = False` to ensure that no further deletion attempts are made in subsequent invocations of the object. This is done to prevent repeated deletions of the same file unless explicitly required elsewhere in the class.\n\n**Note**: \n- The method assumes that `self.save_path` is a valid file path object that supports `.exists()` and `.unlink()` methods.\n- It is important that the `delete_on_init` flag is properly managed to avoid unintended file deletion during object initialization.\n- The use of `logger` for logging information and errors is crucial for debugging and understanding the state of the file deletion process."
      ],
      "code_start_line": 36,
      "code_end_line": 46,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, **data):\n        super().__init__(**data)\n        if self.delete_on_init and self.save_path.exists():\n            try:\n                self.save_path.unlink()  # Delete the file if it exists\n                logger.info(f\"Deleted existing file: {self.save_path}\")\n            except Exception as e:\n                logger.error(f\"Failed to delete file {self.save_path}: {e}\")\n                raise\n        # Set the flag to False to avoid further deletions\n        self.delete_on_init = False\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "serialize_history",
      "md_content": [
        "**serialize_history**: The function of serialize_history is to convert a list of conversation history items into a serialized format, excluding any attributes that are set to None.\n\n**parameters**: The parameters of this Function.\n· history: List[HistoryItem]  \n   This parameter represents a list of `HistoryItem` objects that encapsulate individual entries in a conversation history.\n\n**Code Description**: The `serialize_history` method is designed to process a list of `HistoryItem` instances, which represent entries in a conversation. The method takes a single parameter, `history`, which is expected to be a list of `HistoryItem` objects. The function first initializes an empty list called `serialized_history` to hold the serialized representations of the history items.\n\nThe method then iterates over the last `max_history_length` number of items from the `history` list. This is achieved by slicing the list with `history[-self.max_history_length :]`, which ensures that only the most recent entries are considered for serialization. For each `HistoryItem` in this sliced list, the method calls the `model_dump` method on the item, passing `exclude_none=True` as an argument. This call to `model_dump` is responsible for converting the `HistoryItem` into a dictionary format while omitting any attributes that have a value of None.\n\nFinally, the method returns the `serialized_history` list, which contains the serialized representations of the selected `HistoryItem` instances. This serialized data can be useful for saving conversation history in a structured format, such as for storage in a database or for transmission over a network.\n\nThe `serialize_history` method is closely related to the `HistoryItem` class, which defines the structure of each entry in the conversation history. By utilizing the `model_dump` method from the `HistoryItem`, this function ensures that the serialization process respects the attributes defined in the `HistoryItem` class, providing a consistent and accurate representation of the conversation history.\n\n**Note**: It is important to ensure that the `max_history_length` attribute is defined within the class that contains the `serialize_history` method, as it dictates how many of the most recent history items will be serialized. The method is particularly useful in scenarios where only a limited portion of the conversation history is needed, such as when displaying recent interactions to a user or when preparing data for logging purposes.\n\n**Output Example**: A possible appearance of the code's return value could be as follows:\n```json\n[\n    {\n        \"role\": \"user\",\n        \"content\": \"What is the weather like today?\",\n        \"tool_calls\": null,\n        \"tool_call_id\": null,\n        \"name\": null\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"The weather is sunny with a high of 75°F.\",\n        \"tool_calls\": null,\n        \"tool_call_id\": null,\n        \"name\": null\n    }\n]\n```"
      ],
      "code_start_line": 49,
      "code_end_line": 53,
      "params": [
        "self",
        "history"
      ],
      "have_return": true,
      "code_content": "    def serialize_history(self, history: List[HistoryItem]):\n        serialized_history = []\n        for item in history[-self.max_history_length :]:\n            serialized_history.append(item.model_dump(exclude_none=True))\n        return serialized_history\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/models.py/HistoryItem"
      ],
      "special_reference_type": [
        true
      ]
    },
    {
      "type": "FunctionDef",
      "name": "custom_serialize",
      "md_content": [
        "**custom_serialize**: The function of custom_serialize is to apply custom serialization logic to handle different contexts, particularly focusing on transforming the history into a ShareGPT format when specified.\n\n**parameters**:\n· handler: A SerializerFunctionWrapHandler responsible for performing default serialization of the object.\n· info: A SerializationInfo object containing the context information, which can determine whether the ShareGPT format should be applied.\n\n**Code Description**:  \nThe `custom_serialize` function begins by invoking the `handler` to perform default serialization on the object. This results in the `result` variable, which contains the serialized data, including the `history` attribute.\n\nIf the `info` parameter contains a context with a key \"sharegpt\", the function processes the history attribute further to format it for the ShareGPT use case. The logic involves iterating over each item in the `history` and remapping the roles using a predefined `role_mapping` dictionary. The roles are mapped from:\n- `\"user\"` to `\"human\"`\n- `\"assistant\"` to `\"function_call\"`\n- `\"tool\"` to `\"observation\"`\n- `\"critic\"` to `\"critic\"`\n\nFor each item, the corresponding value (either content or tool call data) is extracted. If the role is `\"function_call\"`, the function checks if tool calls are associated with the item and formats them as JSON, including the function name and its arguments. If no tool calls are present, the value is directly assigned with the content associated with the \"gpt\" role.\n\nFor `\"observation\"` roles, the content is serialized as a JSON string.\n\nAfter processing all items in the history, the `conversations` list is populated with the formatted role-value pairs. Finally, the `result` object is updated to include the conversations and a serialized version of the `available_tools` attribute. This final output is then returned.\n\n**Note**:  \n- The `result[\"history\"]` is assumed to be a list that contains historical interactions with objects that have `role` and `content` attributes.\n- The handling of tool calls in the `\"function_call\"` role relies on the presence of a `tool_calls` attribute, which is expected to be a list of tool call objects.\n- The format of the final output is specifically structured to accommodate ShareGPT's data format, which includes the key `\"conversations\"` and `\"tools\"`.\n\n**Output Example**:  \nHere is a mock-up of what the final output might look like when the `sharegpt` context is provided:\n\n```json\n{\n  \"conversations\": [\n    {\n      \"from\": \"human\",\n      \"value\": \"Hello, how are you?\"\n    },\n    {\n      \"from\": \"gpt\",\n      \"value\": \"I'm doing well, thank you for asking!\"\n    },\n    {\n      \"from\": \"function_call\",\n      \"value\": \"{\\\"name\\\": \\\"weatherApi.getForecast\\\", \\\"arguments\\\": {\\\"location\\\": \\\"New York\\\"}}\"\n    },\n    {\n      \"from\": \"observation\",\n      \"value\": \"{\\\"temperature\\\": 72, \\\"condition\\\": \\\"Sunny\\\"}\"\n    }\n  ],\n  \"tools\": \"{\\\"weatherApi\\\": {\\\"name\\\": \\\"weatherApi\\\", \\\"description\\\": \\\"Provides weather data\\\"}}\"\n}\n```"
      ],
      "code_start_line": 56,
      "code_end_line": 112,
      "params": [
        "self",
        "handler",
        "info"
      ],
      "have_return": true,
      "code_content": "    def custom_serialize(\n        self, handler: SerializerFunctionWrapHandler, info: SerializationInfo\n    ):\n        \"\"\"\n        Custom serialization logic that handles different contexts, such as 'sharegpt'.\n        \"\"\"\n        # Perform default serialization\n        result = handler(self)\n\n        result = result[\"history\"]\n\n        if info.context and info.context.get(\"sharegpt\"):\n            # Transform history into ShareGPT format\n            # TODO: human 和 observation 必须出现在奇数位置，gpt 和 function 必须出现在偶数位置\n            conversations = []\n            for item in self.history:\n                role_mapping = {\n                    \"user\": \"human\",\n                    \"assistant\": \"function_call\",\n                    \"tool\": \"observation\",\n                    \"critic\": \"critic\",\n                }\n\n                role = role_mapping.get(item.role, item.role)\n                value = item.content if item.content else None\n\n                # For tool calls, include the tool_call_id or arguments\n                if role == \"function_call\":\n                    if item.tool_calls:\n                        for tool_call in item.tool_calls:\n                            value = json.dumps(\n                                {\n                                    \"name\": tool_call.function.name,\n                                    \"arguments\": tool_call.function.arguments,\n                                },\n                                ensure_ascii=True,\n                            )\n\n                            conversations.append({\"from\": role, \"value\": value})\n                    else:\n                        conversations.append({\"from\": \"gpt\", \"value\": value})\n\n                elif role == \"observation\":\n                    conversations.append(\n                        {\"from\": role, \"value\": json.dumps(value, ensure_ascii=True)}\n                    )\n\n                else:\n                    conversations.append({\"from\": role, \"value\": value})\n\n            # Build final output structure\n            result = {\n                \"conversations\": conversations,\n                \"tools\": json.dumps(self.available_tools, ensure_ascii=True),\n            }\n\n        return result\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "write",
      "md_content": [
        "**write**: The function of write is to append data to a JSON file, creating the necessary directories and handling potential issues with existing file data.\n\n**parameters**: The parameters of this Function.\n· data: dict - A dictionary containing the data to be written to the file.\n· path: Path | str - The path (as a string or Path object) to the file where the data will be saved.\n\n**Code Description**: The `write` function is responsible for managing the process of appending data to a specified JSON file. The function first ensures that the provided file path is a `Path` object, converting it from a string if necessary. It then verifies that the parent directories of the file exist, creating them if needed. If the file already exists, it attempts to read the existing data and ensures that it is a list (or initializes it as an empty list if the data is invalid or absent). The new data is then appended to this list, and the updated list is written back to the file in a JSON format, ensuring that the data is properly formatted (with indentation for readability).\n\nThe function handles potential errors that might occur during these operations, such as issues with file access or invalid data formats. In such cases, it logs the error message and raises the exception.\n\nFrom a project perspective, the `write` function is utilized by other parts of the code to persist conversation history or similar data. For instance, it is called by the `_auto_save` method in the `ConversationManager` class, where it is used to save the most recent conversation history to a file, if the `save_path` attribute is set. Additionally, the `write` function is called in the `run_tasks` function, which processes a list of tasks and logs conversation data after each task is completed.\n\n**Note**: When using this function, ensure that the path provided is correct, and be aware that it appends data to the file. This means that the file will grow in size over time as more data is added. Also, if the file contains corrupt or non-JSON data, the function will start with an empty list, potentially overwriting previous content."
      ],
      "code_start_line": 114,
      "code_end_line": 145,
      "params": [
        "self",
        "data",
        "path"
      ],
      "have_return": false,
      "code_content": "    def write(self, data: dict, path: Path | str):\n        if isinstance(path, str):\n            path = Path(path)\n\n        try:\n            # Create parent directories if they do not exist\n            path.parent.mkdir(parents=True, exist_ok=True)\n\n            # Check if the file exists and read existing data\n            if path.exists():\n                with path.open(\"r\", encoding=\"utf-8\") as f:\n                    try:\n                        # Try to parse the existing JSON data (expecting a list at the top level)\n                        existing_data = json.load(f)\n                        if not isinstance(existing_data, list):\n                            existing_data = []  # Ensure it's a list\n                    except json.JSONDecodeError:\n                        # If the file is empty or corrupt, start with an empty list\n                        existing_data = []\n            else:\n                existing_data = []\n\n            # Append the new data to the existing array\n            existing_data.append(data)\n\n            # Write the updated array back to the file\n            with path.open(\"w\", encoding=\"utf-8\") as f:\n                json.dump(existing_data, f, ensure_ascii=True, indent=2)\n\n        except Exception as e:\n            logger.error(f\"Failed to write to {path}: {e}\")\n            raise\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/models.py/ConversationManager/_auto_save",
        "src/criticsearch/tasks_runner.py/run_tasks"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "_auto_save",
      "md_content": [
        "**_auto_save**: The function of _auto_save is to automatically save the most recent entry in the conversation history to a specified file path, provided the save path is set.\n\n**parameters**:  \n- None\n\n**Code Description**: The `_auto_save` method is a function within the `ConversationManager` class that is responsible for saving the most recent conversation history to a file, specifically the last entry in the `history` list. The method checks whether the `save_path` attribute is defined, and if it is, it uses the `write` method to persist the most recent entry in the conversation history. This entry is accessed using `self.history[-1]`, which fetches the last item in the `history` list, and then the `model_dump(exclude_none=True)` method is invoked on this entry to prepare it for saving. This method ensures that no `None` values are included in the saved data. The resulting data is then passed to the `write` method, which handles the task of appending this data to a file at the location specified by the `save_path`.\n\nThe `_auto_save` function is called automatically whenever a new message is added to the conversation history. Specifically, it is invoked by the `append_to_history` method, which adds new conversation entries to the `history` list. Once a new message is appended to the history, `_auto_save` is triggered to ensure that the updated history is saved immediately. This process facilitates the continuous preservation of the conversation data without requiring manual intervention from the user.\n\nThe `write` method, which is invoked by `_auto_save`, is responsible for appending data to a JSON file. It manages the creation of necessary directories, reads any existing data from the file, and ensures that the data is in the correct format before appending new content. This integration ensures that the conversation history is consistently updated and saved to disk.\n\n**Note**: It is important to ensure that the `save_path` attribute is set correctly in order for the `_auto_save` function to work as expected. If the `save_path` is not provided or is invalid, no data will be saved. Additionally, the data being saved is the most recent entry in the `history` list, meaning only the latest message or event is preserved during each save operation."
      ],
      "code_start_line": 147,
      "code_end_line": 151,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def _auto_save(self):\n        \"\"\"Auto save after each update if save_path is set\"\"\"\n        self.write(\n            path=self.save_path, data=self.history[-1].model_dump(exclude_none=True)\n        )\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/models.py/ConversationManager/append_to_history"
      ],
      "reference_who": [
        "src/criticsearch/models.py/ConversationManager/write"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "append_to_history",
      "md_content": [
        "### Function: `append_to_history`\n\n**Purpose**:  \nThe `append_to_history` function is designed to add a new message to the conversation history in a `ConversationManager` instance.\n\n**Parameters**:\n- `role` (Literal[\"user\", \"assistant\", \"tool\", \"critic\"]):  \n  Specifies the role of the entity contributing to the conversation. The value can be one of the following:\n  - `\"user\"`: Represents the user initiating the message.\n  - `\"assistant\"`: Represents the assistant responding to the user.\n  - `\"tool\"`: Represents an automated tool interacting within the conversation.\n  - `\"critic\"`: Represents a critic providing feedback or evaluation.\n\n- `content` (Optional[str]):  \n  The actual content of the message. This is an optional parameter and can be set to `None` if no content is provided.\n\n- `**kwargs`:  \n  Additional optional keyword arguments that can be passed to the `HistoryItem` constructor. These arguments can be used for providing extra context, such as tool calls or identifiers.\n\n**Functionality**:  \nThis method creates a new entry in the conversation history by instantiating a `HistoryItem` object with the provided `role`, `content`, and any additional keyword arguments. The newly created `HistoryItem` is appended to the `history` attribute, which is a list that stores the conversation history. After adding the new history item, the method triggers the `_auto_save` function to automatically save the updated conversation history.\n\n**Usage**:  \nThis function is used to maintain and update the flow of a conversation by systematically adding new messages from different participants (user, assistant, tool, or critic) and ensuring that the history is saved for future reference. It plays a crucial role in tracking the progression of conversations over time.\n\n**Example**:  \n```python\nconversation_manager.append_to_history(role=\"user\", content=\"Hello, how can I assist you today?\")\n```\n\nIn this example, a new message from the user is added to the conversation history. The content of the message is \"Hello, how can I assist you today?\" and the role is set as `\"user\"`.\n\n**Related Methods**:  \n- `_auto_save`: Automatically saves the most recent conversation entry to a file after the message is added to history."
      ],
      "code_start_line": 153,
      "code_end_line": 163,
      "params": [
        "self",
        "role",
        "content"
      ],
      "have_return": false,
      "code_content": "    def append_to_history(\n        self,\n        role: Literal[\"user\", \"assistant\", \"tool\", \"critic\"],\n        content: Optional[str] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Add a new message to the conversation history.\n        \"\"\"\n        self.history.append(HistoryItem(role=role, content=content, **kwargs))\n        self._auto_save()\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)",
        "src/criticsearch/main.py/main",
        "src/criticsearch/models.py/ConversationManager/append_tool_call_to_history",
        "src/criticsearch/models.py/ConversationManager/append_tool_call_result_to_history"
      ],
      "reference_who": [
        "src/criticsearch/models.py/HistoryItem",
        "src/criticsearch/models.py/ConversationManager/_auto_save"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "append_tool_call_to_history",
      "md_content": [
        "**append_tool_call_to_history**: The function of append_tool_call_to_history is to add a tool call entry to the conversation history.\n\n**parameters**: The parameters of this Function.\n· tool_calls: List[ChatCompletionMessageToolCall] - A list of tool call entries that are to be added to the conversation history.\n· content: Optional[str] - An optional string that represents additional content related to the tool calls. If not provided, it defaults to None.\n\n**Code Description**: The append_tool_call_to_history function is a method within the ConversationManager class that is responsible for appending tool call entries to the conversation history. It takes two parameters: a list of tool calls and an optional content string. The primary purpose of this function is to maintain a record of interactions that involve automated tools within the conversation flow.\n\nWhen invoked, the function calls another method, append_to_history, passing along the role of \"assistant\", the list of tool calls, and any additional content. The append_to_history method is responsible for creating a new entry in the conversation history, which is stored as a list of HistoryItem objects. This ensures that every interaction involving tools is documented, allowing for a comprehensive view of the conversation's progression.\n\nThe append_tool_call_to_history function is called within the search_and_browse method of the BaseAgent class. In this context, it is used to log the tool calls generated during a search operation. If the search_with_tool_response contains tool calls, the function is invoked to append these calls to the conversation history. This is crucial for tracking the actions taken by the assistant and the tools it interacts with, ensuring that the conversation history remains accurate and up-to-date.\n\nIn summary, append_tool_call_to_history plays a vital role in maintaining the integrity of the conversation history by systematically recording tool interactions, which can be referenced later for analysis or debugging.\n\n**Note**: It is important to ensure that the tool_calls parameter is always provided as a list of ChatCompletionMessageToolCall objects to avoid errors during the history appending process. Additionally, the content parameter is optional and can be omitted if there is no additional information to record."
      ],
      "code_start_line": 167,
      "code_end_line": 175,
      "params": [
        "self",
        "tool_calls",
        "content"
      ],
      "have_return": false,
      "code_content": "    def append_tool_call_to_history(\n        self,\n        tool_calls: List[ChatCompletionMessageToolCall],\n        content: Optional[str] = None,\n    ):\n        \"\"\"\n        Add a tool call entry to the conversation history.\n        \"\"\"\n        self.append_to_history(role=\"assistant\", tool_calls=tool_calls, content=content)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse"
      ],
      "reference_who": [
        "src/criticsearch/models.py/ConversationManager/append_to_history"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "append_tool_call_result_to_history",
      "md_content": [
        "**append_tool_call_result_to_history**: The function of `append_tool_call_result_to_history` is to add the result of a tool call to the conversation history.\n\n**parameters**: The parameters of this function are:\n- `tool_call_id`: A string representing the unique identifier of the tool call.\n- `name`: A string representing the name of the tool involved in the call.\n- `content`: A string representing the result or content generated from the tool call.\n\n**Code Description**: \nThe `append_tool_call_result_to_history` function is designed to add the result of a tool call to the conversation history in a structured manner. This is achieved by calling the `append_to_history` method, which is responsible for adding an entry to the conversation history. The `role` parameter in `append_to_history` is set to `\"tool\"`, signifying that the message is coming from an automated tool. Along with this, the `tool_call_id`, `name`, and `content` are passed as keyword arguments to ensure that the specific details of the tool call are included in the history entry.\n\nThis function is called within the `search_and_browse` method of the `BaseAgent` class, which handles the interaction between the agent and external tools. Specifically, after making a tool call to search or scrape data, the results are passed to `append_tool_call_result_to_history` to be logged into the conversation history. This is crucial for maintaining a structured log of tool activities in the ongoing conversation.\n\nWhen tool calls occur during the search and web scraping processes, `append_tool_call_result_to_history` ensures that the relevant tool call results are captured and saved in the conversation history. This allows for easy tracking of the results generated by tools like search aggregators and content scrapers.\n\nIn summary, this function is used to log the results of tool calls in the conversation history, providing a complete and organized record of the interactions involving automated tools.\n\n**Note**: The content parameter passed to this function should contain the result of the tool's operation (such as search results or web scraping data) and should be a string that accurately reflects the output generated by the tool."
      ],
      "code_start_line": 177,
      "code_end_line": 185,
      "params": [
        "self",
        "tool_call_id",
        "name",
        "content"
      ],
      "have_return": false,
      "code_content": "    def append_tool_call_result_to_history(\n        self, tool_call_id: str, name: str, content: str\n    ):\n        \"\"\"\n        Add a tool call result to the conversation history.\n        \"\"\"\n        self.append_to_history(\n            role=\"tool\", tool_call_id=tool_call_id, name=name, content=content\n        )\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse"
      ],
      "reference_who": [
        "src/criticsearch/models.py/ConversationManager/append_to_history"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "clear_history",
      "md_content": [
        "**clear_history**: The function of clear_history is to remove all entries from the conversation history.\n\n**parameters**: The clear_history function does not take any parameters.\n\n**Code Description**: The clear_history function is a method that belongs to a class, presumably related to managing conversations. When invoked, this method performs a single action: it clears the entire conversation history stored in the object's history attribute. The history attribute is expected to be a data structure that supports the clear operation, such as a list or a similar collection. By calling self.history.clear(), the method effectively empties this collection, ensuring that no previous conversation data remains accessible. This functionality is particularly useful in scenarios where a fresh start is required, such as resetting a chat interface or preparing for a new session without any prior context.\n\n**Note**: It is important to be aware that once the clear_history method is executed, all conversation data will be permanently deleted and cannot be recovered. Therefore, it is advisable to use this method with caution, especially in applications where conversation history may be needed for reference or analysis."
      ],
      "code_start_line": 187,
      "code_end_line": 191,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def clear_history(self):\n        \"\"\"\n        Clear the entire conversation history.\n        \"\"\"\n        self.history.clear()\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/main.py": [
    {
      "type": "FunctionDef",
      "name": "main",
      "md_content": [
        "**main**: The function of main is to manage the iterative process of handling a user-defined task, utilizing an intelligent agent to generate responses and critiques based on user input.\n\n**parameters**: The parameters of this Function.\n· TASK: A string representing the task or question posed by the user that the agent will address.\n· MAX_ITERATION: An integer specifying the maximum number of iterations the agent will perform to refine its answer.\n\n**Code Description**: The main function serves as the central orchestrator for processing a user-defined task within an intelligent agent framework. It begins by initializing an instance of the BaseAgent class, which is responsible for managing conversations, performing searches, and interacting with various tools. The user question is assigned to the agent's `user_question` attribute, and the logging level is set based on the configuration.\n\nThe function logs the initiation of the conversation with the specified task and appends the task to the conversation history. It then enters a loop that iterates up to the specified maximum number of iterations. During each iteration, the function performs the following steps:\n\n1. It logs the current iteration number with a colorized message for visibility.\n2. In the first iteration, it checks the agent's confidence in its response to the task. If the agent is confident, it directly retrieves an answer using the `common_chat` method. If not, it constructs a search prompt, performs a search using the `search_and_browse` method, and then generates an answer based on the search results.\n3. In subsequent iterations, the function updates the answer based on feedback from a CriticAgent, which evaluates the previous answer and provides suggestions for improvement. The `update_answer` method is called to refine the response based on the critic's feedback.\n4. After each answer is generated, it logs the response and the critic's evaluation, checking if the critique indicates that the process should stop. If so, it logs the total iterations and the final answer before returning it.\n5. If the maximum number of iterations is reached without a stopping condition, it logs the total iterations and the final answer, returning the result.\n\nThe main function is called by the `run_tasks` function in the `tasks_runner.py` module, which iterates over a list of tasks, invoking the main function for each task and logging the conversation history after each execution. This establishes a clear flow of task processing and response generation, ensuring that the agent can iteratively improve its answers based on user input and critiques.\n\n**Note**: It is essential to ensure that the TASK parameter is well-defined and relevant to the capabilities of the agent. The MAX_ITERATION parameter should be set appropriately to balance the need for thoroughness in response generation with the efficiency of processing.\n\n**Output Example**: A possible appearance of the code's return value when performing a search might look like this:\n```json\n{\n  \"final_answer\": \"Based on the information gathered, the challenges faced by Google in 2019 included...\",\n  \"conversation_history\": [\n    {\"role\": \"user\", \"content\": \"What challenges did Google face in 2019?\"},\n    {\"role\": \"assistant\", \"content\": \"The challenges included...\"},\n    {\"role\": \"critic\", \"content\": \"The answer is good but lacks specific examples.\"}\n  ]\n}\n```"
      ],
      "code_start_line": 11,
      "code_end_line": 185,
      "params": [
        "TASK",
        "MAX_ITERATION"
      ],
      "have_return": true,
      "code_content": "def main(TASK, MAX_ITERATION):\n    # Initialize agents\n    common_agent = BaseAgent()\n\n    # initialize the task\n    common_agent.user_question = TASK\n\n    set_logger_level_from_config(log_level=settings.log_level.upper())\n\n    logger.success(f\"Starting the conversation with task: {TASK}\")\n\n    BaseAgent.conversation_manager.append_to_history(role=\"user\", content=TASK)\n\n    for iteration in range(MAX_ITERATION):\n        colorize_message(\n            message_title=f\"ITERATION {iteration + 1}\", color=\"cyan\", style=\"bold\"\n        )\n\n        if iteration == 0:\n            # Initialize search_results as None\n            search_results = None\n\n            # Model confidence check - yellow\n            agent_confident = common_agent.model_confident(TASK)\n            agent_confident_yaml = common_agent.extract_and_validate_yaml(\n                agent_confident\n            )\n\n            if agent_confident_yaml is None:\n                logger.warning(\n                    \"Failed to extract valid YAML content. Defaulting to 'false'.\"\n                )\n                agent_confident = False\n            else:\n                agent_confident_dict = yaml.safe_load(agent_confident_yaml)\n                agent_confident = (\n                    agent_confident_dict.get(\"confidence\", \"true\").lower() == \"true\"\n                )\n\n            if agent_confident:\n                # When confident, only get the answer\n                common_agent_answer = common_agent.common_chat(usr_prompt=TASK)\n            else:\n                # When not confident, get both answer and search results\n                data = {\n                    \"user_question\": TASK,\n                }\n                initial_search_prompt = common_agent.load_template(\n                    \"planner_agent_initial_search_plan.txt\"\n                )\n                initial_search_rendered_prompt = common_agent.render_template(\n                    initial_search_prompt, data\n                )\n                logger.info(\n                    f\"initial_search_rendered_prompt: {initial_search_rendered_prompt}\"\n                )\n\n                initial_web_result_markdown_text = common_agent.search_and_browse(\n                    initial_search_rendered_prompt\n                )\n                logger.info(f\"Initial web result: {initial_web_result_markdown_text}\")\n\n                rag_based_answer_prompt = common_agent.render_template(\n                    common_agent.load_template(\"rag_based_answer.txt\"),\n                    {\n                        \"user_question\": common_agent.user_question,\n                        \"web_result_markdown_text\": initial_web_result_markdown_text,\n                    },\n                )\n\n                common_agent_answer = common_agent.common_chat(\n                    usr_prompt=rag_based_answer_prompt,\n                )\n\n        else:\n            # 前面根据critc的返回得到了新的网页搜索结果web_result_markdown_text\n            common_agent_answer = common_agent.update_answer(\n                query=TASK,\n                previous_answer=common_agent_answer,\n                search_results=web_result_markdown_text,\n                critic_feedback=critic_agent_response,\n            )\n            time.sleep(0.5)  # hitting rate limits for gpt mini\n\n        colorize_message(\n            message_title=\"COMMON AGENT ANSWER\",\n            color=\"magenta\",\n            message_content=common_agent_answer,\n        )\n\n        # Critic evaluation - blue\n        critic_agent = CriticAgent()\n        critic_agent.receive_task(TASK)\n        critic_agent.receive_agent_answer(common_agent_answer)\n        critic_agent_response = critic_agent.critic()\n\n        colorize_message(\n            message_title=\"CRITIC_AGENT_RESPONSE\",\n            color=\"blue\",\n            message_content=critic_agent_response,\n        )\n\n        if yaml.safe_load(critic_agent_response).get(\"Stop\", {}).lower() == \"true\":\n            colorize_message(\n                message_title=f\"TOTAL ITERATIONS: {iteration + 1}\", color=\"red\"\n            )\n\n            colorize_message(\n                message_title=\"ALL SEARCH QUERIES\",\n                color=\"black\",\n                message_content=\", \".join(map(str, common_agent.queryDB)),\n            )\n            colorize_message(\n                message_title=\"FINAL ANSWER\",\n                color=\"red\",\n                message_content=common_agent_answer,\n            )\n\n            return f\"\\n{common_agent_answer}\\n\"\n\n        # 根据critic的建议再执行一次搜索和爬虫操作\n        # 先构建rendered_prompt\n        reflection_data = {\n            \"user_question\": TASK,\n            \"previous_answer\": common_agent_answer,\n            \"user_feedback\": critic_agent_response,\n            \"search_history\": common_agent.queryDB,\n        }\n        search_again_prompt = common_agent.render_template(\n            common_agent.load_template(\"planner_agent_with_reflection.txt\"),\n            reflection_data,\n        )\n        try:\n            web_result_markdown_text = common_agent.search_and_browse(\n                search_again_prompt\n            )\n        except:\n            colorize_message(\n                message_title=f\"TOTAL ITERATIONS: {iteration + 1}\", color=\"red\"\n            )\n\n            colorize_message(\n                message_title=\"ALL SEARCH QUERIES\",\n                color=\"black\",\n                message_content=\", \".join(map(str, common_agent.queryDB)),\n            )\n\n            colorize_message(\n                message_title=\"FINAL ANSWER\",\n                color=\"red\",\n                message_content=common_agent_answer,\n            )\n\n            # we run out of searches for now, so we force the agent to give a final answer:\n            return f\"\\n{common_agent_answer}\\n\"\n\n        # Check if reached max iterations\n        if iteration == MAX_ITERATION - 1:\n            colorize_message(\n                message_title=f\"TOTAL ITERATIONS: {iteration + 1}\", color=\"red\"\n            )\n\n            colorize_message(\n                message_title=\"ALL SEARCH QUERIES\",\n                color=\"black\",\n                message_content=\", \".join(map(str, common_agent.queryDB)),\n            )\n\n            colorize_message(\n                message_title=\"FINAL ANSWER\",\n                color=\"red\",\n                message_content=common_agent_answer,\n            )\n\n            return f\"\\n{common_agent_answer}\\n\"\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tasks_runner.py",
        "src/criticsearch/tasks_runner.py/run_tasks"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent",
        "src/criticsearch/base_agent.py/BaseAgent/load_template",
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/update_answer",
        "src/criticsearch/base_agent.py/BaseAgent/model_confident",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/base_agent.py/BaseAgent/receive_task",
        "src/criticsearch/base_agent.py/BaseAgent/extract_and_validate_yaml",
        "src/criticsearch/log.py/set_logger_level_from_config",
        "src/criticsearch/log.py/colorize_message",
        "src/criticsearch/models.py/ConversationManager/append_to_history",
        "src/criticsearch/critic_agent.py/CriticAgent",
        "src/criticsearch/critic_agent.py/CriticAgent/critic",
        "src/criticsearch/critic_agent.py/CriticAgent/receive_agent_answer"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tasks_runner.py": [
    {
      "type": "FunctionDef",
      "name": "run_tasks",
      "md_content": [
        "**run_tasks**: The function of run_tasks is to handle multiple tasks, run them iteratively, and log conversation history.\n\n**parameters**: The parameters of this Function.\n· tasks: list - A list of task strings (questions) to process.\n· max_iterations: int - Maximum number of iterations for each task (default is 10).\n· output_file: Path | str - Path to save the conversation history in sharegpt format (default is \"conversation_history_sharegpt.jsonl\").\n\n**Code Description**: The run_tasks function is designed to manage the execution of a series of tasks, iterating through each task and performing operations to generate responses while logging the conversation history. The function accepts a list of tasks, a maximum number of iterations for processing each task, and a file path for saving the conversation history.\n\nFor each task in the provided list, the function invokes the main function, which is responsible for processing the task and generating responses. The main function is called with the current task and the specified maximum number of iterations. This function is integral to the overall architecture, as it utilizes the BaseAgent class to manage conversations and interactions.\n\nAfter executing the main function for a task, the run_tasks function retrieves the conversation data from the BaseAgent's conversation manager. It then writes this data to the specified output file using the write method of the conversation manager. This ensures that the conversation history is preserved in a structured format, allowing for future reference or analysis.\n\nThe run_tasks function is called by other components in the project, such as the main execution flow in the src/criticsearch/__main__.py file and potentially other scripts that require batch processing of tasks. This establishes a clear pathway for task management and response generation within the intelligent agent framework.\n\n**Note**: When using this function, ensure that the tasks provided are well-defined and relevant to the capabilities of the underlying agent. Additionally, be mindful of the output file path, as the function appends data to the file, which may grow in size over time. If the file contains corrupt or non-JSON data, the function may start with an empty list, potentially overwriting previous content."
      ],
      "code_start_line": 7,
      "code_end_line": 32,
      "params": [
        "tasks",
        "max_iterations",
        "output_file"
      ],
      "have_return": false,
      "code_content": "def run_tasks(\n    tasks: list,\n    max_iterations: int = 10,\n    output_file: Path | str = \"conversation_history_sharegpt.jsonl\",\n):\n    \"\"\"\n    Function to handle multiple tasks, run them iteratively, and log conversation history.\n\n    Parameters:\n    - tasks (list): List of task strings (questions) to process.\n    - max_iterations (int): Maximum number of iterations for each task.\n    - output_file (Path | str): Path to save the conversation history in sharegpt format.\n    \"\"\"\n\n    for task in tasks:\n        # Run the main function for each task\n        main(task, max_iterations)\n\n        # Log conversation history after each task\n        conversation_data = BaseAgent.conversation_manager.model_dump(\n            context={\"sharegpt\": True}\n        )\n        BaseAgent.conversation_manager.write(\n            data=conversation_data,\n            path=output_file,\n        )\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "eval.py",
        "src/criticsearch/__main__.py"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent",
        "src/criticsearch/models.py/ConversationManager/write",
        "src/criticsearch/main.py/main"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/__main__.py": [],
  "src/criticsearch/critic_agent.py": [
    {
      "type": "ClassDef",
      "name": "CriticAgent",
      "md_content": [
        "**CriticAgent**: The function of CriticAgent is to generate critiques based on the responses provided by an intelligent agent.\n\n**attributes**: The attributes of this Class.\n· original_task: A string that holds the original task or question received from the user.  \n· critic_prompt: A string that contains the template for generating critiques, loaded from a specified template file.\n\n**Code Description**: The CriticAgent class extends the BaseAgent class, inheriting its foundational capabilities while specializing in the evaluation of responses generated by other agents. Upon initialization, the CriticAgent sets up its original task as an empty string and loads a critique template from a file named \"critic_agent.txt\". \n\nThe primary method of the CriticAgent is `critic`, which is responsible for generating critiques. This method first gathers the necessary data for critique generation by calling `get_data_for_critic`, which compiles the original task and the agent's answer into a dictionary. The `critic` method then renders the critique prompt using this data and interacts with a common chat interface to obtain a response from the model. \n\nThe response is expected to be in YAML format, which is validated and extracted using the `extract_and_validate_yaml` method. If the response contains invalid YAML, an error message is printed, and the method returns None. \n\nAdditionally, the CriticAgent has a method called `receive_agent_answer`, which allows it to store the answer provided by the agent for later critique. The `get_data_for_critic` method is a helper function that prepares the data needed for the critique by returning a dictionary containing the original task and the agent's answer.\n\nThe CriticAgent is utilized within the main function of the project, where it receives the task and the agent's answer, generates a critique, and evaluates whether to continue the interaction based on the critique's content. This interaction is part of a loop that allows for iterative refinement of the agent's responses based on feedback from the CriticAgent.\n\n**Note**: It is important to ensure that the template file \"critic_agent.txt\" is correctly formatted and accessible, as the CriticAgent relies on this template to generate critiques. Additionally, proper handling of YAML responses is crucial to avoid runtime errors during critique validation.\n\n**Output Example**: A possible appearance of the code's return value when generating a critique might look like this:\n```yaml\nCritique:\n  feedback: \"The answer provided lacks depth and does not address the user's question adequately.\"\n  suggestions:\n    - \"Include more detailed examples.\"\n    - \"Clarify the main points.\"\n  Stop: false\n```"
      ],
      "code_start_line": 6,
      "code_end_line": 33,
      "params": [],
      "have_return": true,
      "code_content": "class CriticAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        self.original_task = \"\"\n        self.critic_prompt = self.load_template(\"critic_agent.txt\")\n\n    def critic(self):\n        \"\"\"\n        生成评论。\n        \"\"\"\n        data = self.get_data_for_critic()\n\n        rendered_prompt = self.render_template(self.critic_prompt, data)\n        model_response = self.common_chat(usr_prompt=rendered_prompt, role=\"critic\")\n\n        try:\n            formatted_yaml = self.extract_and_validate_yaml(model_response)\n            return formatted_yaml\n\n        except yaml.YAMLError as exc:\n            print(f\"Invalid YAML content: {exc}\")\n            return None\n\n    def receive_agent_answer(self, agent_answer):\n        self.agent_answer = agent_answer\n\n    def get_data_for_critic(self):\n        return {\"user_question\": self.original_task, \"agent_answer\": self.agent_answer}\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py",
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the `CriticAgent` class by calling the parent class's constructor and setting up the initial values for the object's attributes.\n\n**parameters**: The __init__ method does not take any additional parameters besides `self`, which refers to the instance of the class being created.\n\n**Code Description**: \nThe `__init__` method is the constructor for the `CriticAgent` class. It first invokes the constructor of its parent class, `BaseAgent`, using the `super().__init__()` call. This ensures that any initialization logic defined in the parent class is executed, allowing the `CriticAgent` class to inherit and initialize any attributes or methods defined in `BaseAgent`.\n\nAfter calling the parent constructor, the method initializes two attributes specific to the `CriticAgent` class:\n1. `self.original_task`: This attribute is set to an empty string. It is likely intended to hold information about the original task associated with the `CriticAgent`, although its exact usage is not defined within this method.\n   \n2. `self.critic_prompt`: This attribute is set by calling the `load_template` method with the argument `\"critic_agent.txt\"`. The `load_template` method, which is inherited from the `BaseAgent` class, loads the content of a template file named \"critic_agent.txt\" from a specified directory (likely defined in the parent class). This template content is then assigned to the `critic_prompt` attribute, which would presumably be used later in the `CriticAgent` for processing tasks related to the critic agent's functionality.\n\nThe `__init__` method ensures that when an instance of `CriticAgent` is created, the necessary setup for its attributes is completed, and the class is ready for further operations.\n\n**Note**: The `load_template` method is responsible for handling the file reading operation. If the file `critic_agent.txt` is missing or cannot be found in the specified prompts directory, it will raise a `FileNotFoundError`, ensuring that users are informed of any missing template files."
      ],
      "code_start_line": 7,
      "code_end_line": 10,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self):\n        super().__init__()\n        self.original_task = \"\"\n        self.critic_prompt = self.load_template(\"critic_agent.txt\")\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/load_template"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "critic",
      "md_content": [
        "**critic**: The function of critic is to generate a review based on user input and agent responses.\n\n**parameters**: The parameters of this Function.\n· None\n\n**Code Description**: The critic function is a method within the CriticAgent class that is responsible for generating a review or critique based on the data it retrieves and processes. The function operates as follows:\n\n1. **Data Retrieval**: It begins by calling the `get_data_for_critic` method, which returns a dictionary containing the user's question and the agent's answer. This data is essential for generating a contextually relevant critique.\n\n2. **Template Rendering**: The function then utilizes the `render_template` method to create a prompt for the model. This method takes the `critic_prompt` (a predefined template) and the data retrieved in the previous step, formatting it into a string that can be understood by the model.\n\n3. **Model Interaction**: The rendered prompt is sent to the `common_chat` method, which facilitates a conversation with the model. This method processes the user prompt and returns a response from the model, which is expected to contain the critique or review.\n\n4. **YAML Extraction and Validation**: After receiving the model's response, the function attempts to extract and validate any YAML content using the `extract_and_validate_yaml` method. This method checks for valid YAML formatting and returns the parsed content if successful.\n\n5. **Error Handling**: If the YAML extraction fails (for instance, if the content is not valid YAML), the function catches the `yaml.YAMLError` exception, prints an error message indicating the issue, and returns `None`.\n\nThe critic function is invoked within the `main` function of the project, specifically after the common agent has provided an answer to the user's question. The response from the critic function is then used to evaluate the agent's answer, potentially influencing subsequent iterations of the conversation. This highlights the function's role in providing feedback and improving the overall interaction quality between the user and the agent.\n\n**Note**: It is crucial to ensure that the `critic_prompt` is properly defined and that the data returned by `get_data_for_critic` is valid. If the model response does not contain valid YAML, the function will return `None`, which may affect the flow of the application.\n\n**Output Example**: A possible return value from the critic function could be a YAML formatted string such as:\n\n```yaml\nfeedback: \"The agent's answer is comprehensive but lacks specific examples.\"\nsuggestions:\n  - \"Include more detailed explanations.\"\n  - \"Provide references to support claims.\"\n```"
      ],
      "code_start_line": 12,
      "code_end_line": 27,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def critic(self):\n        \"\"\"\n        生成评论。\n        \"\"\"\n        data = self.get_data_for_critic()\n\n        rendered_prompt = self.render_template(self.critic_prompt, data)\n        model_response = self.common_chat(usr_prompt=rendered_prompt, role=\"critic\")\n\n        try:\n            formatted_yaml = self.extract_and_validate_yaml(model_response)\n            return formatted_yaml\n\n        except yaml.YAMLError as exc:\n            print(f\"Invalid YAML content: {exc}\")\n            return None\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [
        "src/criticsearch/base_agent.py/BaseAgent/render_template",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_0(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_1(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/common_chat_2(name_duplicate_version)",
        "src/criticsearch/base_agent.py/BaseAgent/extract_and_validate_yaml",
        "src/criticsearch/critic_agent.py/CriticAgent/get_data_for_critic"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "receive_agent_answer",
      "md_content": [
        "**receive_agent_answer**: The function of receive_agent_answer is to store the answer provided by an agent for further processing.\n\n**parameters**: The parameters of this Function.\n· agent_answer: This parameter represents the answer received from the agent, which will be stored in the instance variable.\n\n**Code Description**: The receive_agent_answer function is a method of the CriticAgent class. Its primary role is to accept an answer from an agent and assign it to the instance variable self.agent_answer. This function is crucial in the context of the CriticAgent's operations, as it allows the agent to receive and retain feedback or responses from other agents involved in the conversation or task execution.\n\nIn the broader context of the project, this function is called within the main function located in src/criticsearch/main.py. During the execution of the main function, after the common agent generates an answer to a user question, the CriticAgent is instantiated. The receive_agent_answer method is then invoked with the common agent's answer as an argument. This step is essential for the CriticAgent to evaluate the quality of the answer provided by the common agent. The stored answer can later be used for further analysis or feedback generation, which is part of the CriticAgent's role in the overall system.\n\n**Note**: It is important to ensure that the agent_answer parameter passed to this function is valid and represents a meaningful response from the agent to avoid any issues in subsequent evaluations or processing."
      ],
      "code_start_line": 29,
      "code_end_line": 30,
      "params": [
        "self",
        "agent_answer"
      ],
      "have_return": false,
      "code_content": "    def receive_agent_answer(self, agent_answer):\n        self.agent_answer = agent_answer\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/main.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "get_data_for_critic",
      "md_content": [
        "**get_data_for_critic**: The function of get_data_for_critic is to return a dictionary containing the user's question and the agent's answer.\n\n**parameters**: This function does not accept any parameters.\n\n**Code Description**:  \nThe `get_data_for_critic` function is a method of a class, which retrieves specific data related to the user's original task and the agent's response. It returns a dictionary with two key-value pairs: the first key is `\"user_question\"`, which corresponds to the `original_task` attribute of the class, and the second key is `\"agent_answer\"`, which corresponds to the `agent_answer` attribute of the class. This method is designed to package these two pieces of information into a format suitable for further processing or analysis.\n\nThis function is invoked by the `critic` method within the same class. The `critic` method uses the data returned by `get_data_for_critic` to render a prompt for a model, which is then used to generate a response. The data returned by `get_data_for_critic` is passed to a template-rendering function (`render_template`), where it is incorporated into a template prompt. The rendered prompt is subsequently sent to a model via the `common_chat` method, and the result is further processed. The `get_data_for_critic` function thus plays a key role in providing necessary input data for the comment generation process within the `critic` method.\n\n**Note**: This method relies on the class having attributes `original_task` and `agent_answer` set properly, as these are used to populate the returned dictionary. If either of these attributes is not initialized or is set to `None`, the function will return a dictionary with missing or invalid values.\n\n**Output Example**:  \nAn example output from `get_data_for_critic` could look as follows:\n\n```json\n{\n  \"user_question\": \"What are the benefits of using AI in healthcare?\",\n  \"agent_answer\": \"AI in healthcare can help with diagnostics, treatment plans, and personalized medicine.\"\n}\n```"
      ],
      "code_start_line": 32,
      "code_end_line": 33,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def get_data_for_critic(self):\n        return {\"user_question\": self.original_task, \"agent_answer\": self.agent_answer}\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/critic_agent.py/CriticAgent/critic"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/image_analyzer.py": [
    {
      "type": "ClassDef",
      "name": "ImageAnalyzer",
      "md_content": [
        "**ImageAnalyzer**: The function of ImageAnalyzer is to analyze an image using a specified vision model.\n\n**attributes**:\n· model: Specifies the vision model used for image analysis, defaulting to \"gpt-4o-mini\".\n\n**Code Description**:  \nThe `ImageAnalyzer` class is designed to facilitate image analysis by processing image data through a specified model. The class contains the following key components:\n\n1. **`__init__(self, model=\"gpt-4o-mini\")`**: This is the initializer method for the `ImageAnalyzer` class. It accepts one optional parameter `model`, which determines the vision model used for image analysis. The default value for this parameter is set to \"gpt-4o-mini\". This attribute is stored within the class as `self.model`.\n\n2. **`analyze_image(self, image_data: str) -> Dict`**: This is the main method responsible for analyzing an image. It accepts `image_data`, which can either be a URL, a file path, or base64-encoded image data. The method follows these steps:\n    - If `image_data` is a string:\n        - If it starts with \"http\", the method assumes the string represents a URL. A request is sent to the URL to retrieve the image, which is then processed by opening it using the `PIL.Image.open()` method after the image content is fetched.\n        - If the string is not a URL, it is treated as a file path and the image is opened directly from the specified location.\n    - The image is then converted to base64 format using the `base64` module, enabling the image to be handled as a string representation. This is done by saving the image into a `BytesIO` buffer, which is then base64-encoded.\n    - If `image_data` is already base64-encoded, the method directly assigns it to `image_base64`.\n    - A dictionary is returned containing a description of the analysis, the model used, and the format of the image data (which is \"base64\").\n\n3. The `analyze_image` method handles exceptions that might occur during the image processing. If an error occurs at any stage, the method returns a dictionary with the error message.\n\n**Note**: \n- The method expects the input image data to either be a file path, URL, or base64-encoded string. It does not handle non-image data or invalid formats.\n- The image analysis itself is not fully implemented in the code; the return statement provides a placeholder response indicating that the analysis was completed.\n- The choice of model for image analysis is configurable but defaults to \"gpt-4o-mini\". However, the analysis logic based on the specified model is not included in this snippet.\n\n**Output Example**:  \nA possible return value from the `analyze_image` method might look like this:\n\n```json\n{\n  \"description\": \"Image analysis completed\",\n  \"model_used\": \"gpt-4o-mini\",\n  \"image_format\": \"base64\"\n}\n```"
      ],
      "code_start_line": 9,
      "code_end_line": 37,
      "params": [],
      "have_return": true,
      "code_content": "class ImageAnalyzer:\n    def __init__(self, model=\"gpt-4o-mini\"):\n        self.model = model\n\n    def analyze_image(self, image_data: str) -> Dict:\n        \"\"\"Analyze an image using the specified vision model.\"\"\"\n        try:\n            # Convert image data to base64 if it's a URL or file path\n            if isinstance(image_data, str):\n                if image_data.startswith(\"http\"):\n                    response = requests.get(image_data)\n                    image = Image.open(BytesIO(response.content))\n                else:\n                    image = Image.open(image_data)\n\n                buffered = BytesIO()\n                image.save(buffered, format=\"PNG\")\n                image_base64 = base64.b64encode(buffered.getvalue()).decode()\n            else:\n                image_base64 = image_data\n\n            # TODO this is a stand in for later use\n            return {\n                \"description\": \"Image analysis completed\",\n                \"model_used\": self.model,\n                \"image_format\": \"base64\",\n            }\n        except Exception as e:\n            return {\"error\": str(e)}\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the object with a specific model configuration.\n\n**parameters**:\n· model: The model to be used, which is set to a default value of \"gpt-4o-mini\".\n\n**Code Description**: \nThe `__init__` method is a constructor that initializes an object of the class. It takes a single parameter, `model`, which defines the model to be used by the object. If no argument is provided during the object creation, it defaults to \"gpt-4o-mini\". The value passed for `model` is then stored in the instance variable `self.model`, which will allow the object to refer to this model later in its usage.\n\nThis method ensures that each object of the class starts with a specific configuration, defined by the `model` parameter. The default value \"gpt-4o-mini\" can be overridden when creating an object if a different model is needed.\n\n**Note**: The `__init__` method does not perform any complex operations or return any value. It only sets up the initial state of the object by assigning the provided `model` value to the instance."
      ],
      "code_start_line": 10,
      "code_end_line": 11,
      "params": [
        "self",
        "model"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, model=\"gpt-4o-mini\"):\n        self.model = model\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "analyze_image",
      "md_content": [
        "**analyze_image**: The function of analyze_image is to analyze an image using the specified vision model.\n\n**parameters**: The parameters of this Function.\n· image_data: A string representing the image data, which can be a URL or a file path to an image.\n\n**Code Description**: The analyze_image function is designed to process an image for analysis. It accepts a single parameter, image_data, which can either be a URL pointing to an image or a local file path. The function first checks if the provided image_data is a string. If it is a URL (indicated by the string starting with \"http\"), the function makes an HTTP GET request to retrieve the image. The image is then opened using the PIL library's Image module. If the image_data is a local file path, the function directly opens the image from that path.\n\nOnce the image is successfully opened, the function converts the image into a PNG format and encodes it into a base64 string. This base64 representation is useful for transmitting image data over the web or embedding it in JSON responses. If the image_data is already in base64 format, it is used directly without further processing.\n\nThe function is currently set up to return a dictionary containing a description of the analysis completion, the model used for analysis (which is an attribute of the class), and the format of the image (base64). In the event of an error during the image processing, the function captures the exception and returns a dictionary with an error message.\n\n**Note**: It is important to ensure that the image_data provided is either a valid URL or a correct file path. The function does not perform extensive validation on the input and assumes that the provided data is in the correct format. Additionally, the actual image analysis logic is not implemented yet, as indicated by the placeholder comment in the code.\n\n**Output Example**: \n{\n    \"description\": \"Image analysis completed\",\n    \"model_used\": \"VisionModelXYZ\",\n    \"image_format\": \"base64\"\n}"
      ],
      "code_start_line": 13,
      "code_end_line": 37,
      "params": [
        "self",
        "image_data"
      ],
      "have_return": true,
      "code_content": "    def analyze_image(self, image_data: str) -> Dict:\n        \"\"\"Analyze an image using the specified vision model.\"\"\"\n        try:\n            # Convert image data to base64 if it's a URL or file path\n            if isinstance(image_data, str):\n                if image_data.startswith(\"http\"):\n                    response = requests.get(image_data)\n                    image = Image.open(BytesIO(response.content))\n                else:\n                    image = Image.open(image_data)\n\n                buffered = BytesIO()\n                image.save(buffered, format=\"PNG\")\n                image_base64 = base64.b64encode(buffered.getvalue()).decode()\n            else:\n                image_base64 = image_data\n\n            # TODO this is a stand in for later use\n            return {\n                \"description\": \"Image analysis completed\",\n                \"model_used\": self.model,\n                \"image_format\": \"base64\",\n            }\n        except Exception as e:\n            return {\"error\": str(e)}\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/__init__.py": [],
  "src/criticsearch/tools/models.py": [
    {
      "type": "FunctionDef",
      "name": "get_list_type_annotation",
      "md_content": [
        "**get_list_type_annotation**: The function of get_list_type_annotation is to determine the type of elements in a list for constructing the \"items\" field in a JSON Schema.\n\n**parameters**: The parameters of this Function.\n· param_type: A type annotation representing the parameter to inspect. It should typically be a generic list type like `List[str]` or `List[int]`.\n\n**Code Description**: The `get_list_type_annotation` function is designed to extract the type of elements contained within a list. It is primarily used to help generate JSON Schema definitions, specifically for the \"items\" field, which describes the type of elements within an array. \n\nThe function first checks if the provided `param_type` is a list (using the `get_origin` function to check for a generic list type). If `param_type` is indeed a list, the function proceeds to extract the type of the elements within that list by calling `get_args(param_type)`. The first argument returned by `get_args` represents the element type, and if it is a type (i.e., `isinstance(args[0], type)`), the function returns a dictionary with the element's type name (e.g., `\"string\"` or `\"int\"`) for use in a JSON Schema definition.\n\nIf the `param_type` is not a list or the element type cannot be determined, the function defaults to returning a dictionary with the value `\"type\": \"string\"`, signifying that the list elements are assumed to be of string type.\n\nThis function is called in the `create_schema_from_function` method to help construct the schema of function parameters when the function contains a parameter of list type. Specifically, within `create_schema_from_function`, when a parameter is detected to be a list, the `get_list_type_annotation` function is invoked to determine the type of the items in that list, which is then added to the parameter schema as the `\"items\"` field.\n\n**Note**: It is important that the parameter passed to `get_list_type_annotation` be a valid generic list type (such as `List[str]` or `List[int]`). If the type is not a list or cannot be determined, the function will return a default type of `\"string\"`.\n\n**Output Example**: \nFor a `param_type` of `List[str]`, the function would return:\n```json\n{\n  \"type\": \"str\"\n}\n```\n\nFor a `param_type` of `List[int]`, the function would return:\n```json\n{\n  \"type\": \"int\"\n}\n```\n\nFor a `param_type` of an unsupported or non-list type, the function would return:\n```json\n{\n  \"type\": \"string\"\n}\n```"
      ],
      "code_start_line": 8,
      "code_end_line": 20,
      "params": [
        "param_type"
      ],
      "have_return": true,
      "code_content": "def get_list_type_annotation(param_type):\n    \"\"\"\n    获取列表中元素的类型，用于构造 JSON Schema 的 items 字段。\n    支持 List[str]、List[int] 等类型。\n    \"\"\"\n    # 检查是否为泛型 List 类型\n    if get_origin(param_type) is list or get_origin(param_type) is list:\n        # 获取列表的元素类型\n        args = get_args(param_type)\n        if args and isinstance(args[0], type):\n            return {\"type\": args[0].__name__}\n    # 默认返回字符串类型（未明确指定类型时）\n    return {\"type\": \"string\"}\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/models.py/Tool/create_schema_from_function"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "serialize_type",
      "md_content": [
        "**serialize_type**: The function of serialize_type is to map a given string representing a data type to its corresponding serialized name.\n\n**parameters**: The parameters of this Function.\n· value: str - A string representing a data type to be serialized.\n\n**Code Description**:  \nThe `serialize_type` function takes in a string value representing a data type (e.g., \"str\", \"int\", etc.). The function performs the following steps:\n1. A dictionary named `type_mapping` is defined. This dictionary contains key-value pairs where the key is a string representing a Python data type, and the value is the corresponding serialized name in a more generalized format.\n   - `\"str\"` maps to `\"string\"`\n   - `\"int\"` maps to `\"integer\"`\n   - `\"float\"` maps to `\"number\"`\n   - `\"bool\"` maps to `\"boolean\"`\n   - `\"list\"` maps to `\"array\"`\n   - `\"dict\"` maps to `\"object\"`\n   - `\"None\"` maps to `\"null\"`\n   \n2. The input value is converted to lowercase to ensure that the function is case-insensitive.\n\n3. The function attempts to find the serialized name by checking if the lowercase version of the `value` exists in the `type_mapping` dictionary.\n\n4. If a match is found, the corresponding serialized value is returned.\n\n5. If no match is found, the function defaults to returning `\"null\"`, which is the fallback value defined in the dictionary.\n\n**Note**: \n- The function is case-insensitive due to the use of the `lower()` method on the input string.\n- It assumes that the input is a valid Python type name. If the input string does not match any of the predefined keys, it returns `\"null\"`.\n- The function can be used for serializing Python data types to a format suitable for data serialization or communication in various systems.\n\n**Output Example**:\n- For an input value of `\"str\"`, the function will return `\"string\"`.\n- For an input value of `\"int\"`, the function will return `\"integer\"`.\n- For an input value of `\"boolean\"`, the function will return `\"null\"` since the value does not match any of the keys in the `type_mapping` dictionary."
      ],
      "code_start_line": 23,
      "code_end_line": 33,
      "params": [
        "value"
      ],
      "have_return": true,
      "code_content": "def serialize_type(value: str) -> str:\n    type_mapping = {\n        \"str\": \"string\",\n        \"int\": \"integer\",\n        \"float\": \"number\",\n        \"bool\": \"boolean\",\n        \"list\": \"array\",\n        \"dict\": \"object\",\n        \"None\": \"null\",\n    }\n    return type_mapping.get(value.lower(), \"null\")\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "Item",
      "md_content": [
        "**Item**: The function of Item is to represent a list item with a specific type.\n\n**attributes**: The attributes of this Class.\n· type: str - The type of the list item, which is a required field.\n\n**Code Description**: The Item class is a subclass of BaseModel, which indicates that it is likely part of a data modeling framework that includes validation and serialization capabilities. The primary attribute of this class is `type`, which is a string that specifies the type of the list item. This attribute is defined using the Field function, which enforces that it is a required field (denoted by the ellipsis `...`). \n\nThe class also includes a method called `serialize_type`, which is decorated with `@field_serializer`. This method is responsible for customizing the serialization of the `type` attribute. When the `type` attribute is serialized, this method is invoked, allowing for any specific transformations or formatting to be applied to the value before it is returned. The actual transformation is handled by the `serialize_type` function, which is assumed to be defined elsewhere in the project.\n\nThe Item class is utilized within the ParameterProperty class, where it is defined as an optional attribute named `items`. This indicates that a ParameterProperty can have a list of items, each of which is represented by an instance of the Item class. The relationship between Item and ParameterProperty is significant, as it allows for the encapsulation of item types within the broader context of parameter properties, enhancing the structure and organization of the data model.\n\n**Note**: When using the Item class, ensure that the `type` attribute is always provided, as it is a required field. Additionally, be aware that the serialization behavior of the `type` attribute can be customized through the `serialize_type` method.\n\n**Output Example**: An instance of the Item class might return a serialized representation like this:\n```json\n{\n  \"type\": \"string\"\n}\n``` \nThis output indicates that the type of the list item is a string, demonstrating how the class encapsulates and manages item type information."
      ],
      "code_start_line": 36,
      "code_end_line": 41,
      "params": [],
      "have_return": true,
      "code_content": "class Item(BaseModel):\n    type: str = Field(..., description=\"The type of the list item\")\n\n    @field_serializer(\"type\")\n    def serialize_type(self, value: str, _info) -> str:\n        return serialize_type(value)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/models.py/ParameterProperty"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "serialize_type",
      "md_content": [
        "**serialize_type**: The function of serialize_type is to convert a given string value into a serialized format.\n\n**parameters**: The parameters of this Function.\n· parameter1: value (str) - The string input that needs to be serialized.\n· parameter2: _info - An additional parameter that may contain contextual information, though it is not utilized within the function.\n\n**Code Description**: The serialize_type function takes a string input, referred to as 'value', and passes it to another function named serialize_type. This indicates that the function is likely designed to handle serialization tasks, converting the input string into a specific serialized format. The second parameter, _info, is included in the function signature but is not used within the function body, suggesting that it may be intended for future use or for compatibility with a broader interface. The function returns the result of the serialization process, which is expected to be a string.\n\n**Note**: It is important to ensure that the input 'value' is a valid string that can be serialized. The behavior of the function will depend on the implementation of the serialize_type function that it calls. Additionally, since the _info parameter is not utilized, developers should be aware that it may not affect the serialization process.\n\n**Output Example**: If the input value is \"example\", the function might return a serialized representation such as \"serialized_example\"."
      ],
      "code_start_line": 40,
      "code_end_line": 41,
      "params": [
        "self",
        "value",
        "_info"
      ],
      "have_return": true,
      "code_content": "    def serialize_type(self, value: str, _info) -> str:\n        return serialize_type(value)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "ParameterProperty",
      "md_content": [
        "**ParameterProperty**: The function of ParameterProperty is to define the properties of a parameter, including its data type, description, and optional items.\n\n**attributes**: The attributes of this Class.\n· type: str - The data type of the parameter, which is a required field.  \n· description: Optional[str] - A description of the parameter, which is an optional field.  \n· items: Optional[Item] - An optional attribute that represents a list of items associated with the parameter.\n\n**Code Description**: The ParameterProperty class is a subclass of BaseModel, indicating that it is part of a data modeling framework that provides validation and serialization capabilities. The primary attribute of this class is `type`, which is a string that specifies the data type of the parameter. This attribute is defined using the Field function, which enforces that it is a required field (denoted by the ellipsis `...`). \n\nThe `description` attribute is an optional string that provides additional information about the parameter, enhancing the understanding of its purpose and usage. The `items` attribute is also optional and is defined as an instance of the Item class, which allows for the encapsulation of item types within the context of parameter properties. This relationship is significant as it enables ParameterProperty to manage a collection of items, each represented by the Item class, thereby enhancing the structure and organization of the data model.\n\nThe ParameterProperty class is utilized within the Parameters class, where it is defined as a value in a dictionary that maps parameter names to their respective properties. This indicates that each parameter in the Parameters class can have its own set of properties defined by the ParameterProperty class. The Parameters class also includes attributes such as `required`, which specifies a list of required parameter names, and `additionalProperties`, which indicates whether additional properties are allowed.\n\nThe integration of ParameterProperty within the Parameters class allows for a comprehensive representation of parameters, including their types, descriptions, and associated items. This structured approach facilitates the management of complex parameter configurations in applications.\n\n**Note**: When using the ParameterProperty class, ensure that the `type` attribute is always provided, as it is a required field. The `description` and `items` attributes can be included as needed to provide further context and detail about the parameter.\n\n**Output Example**: An instance of the ParameterProperty class might return a serialized representation like this:\n```json\n{\n  \"type\": \"string\",\n  \"description\": \"A parameter that accepts string values.\",\n  \"items\": {\n    \"type\": \"string\"\n  }\n}\n```\nThis output indicates that the parameter is of type string, includes a description, and has associated items, demonstrating how the class encapsulates and manages parameter property information."
      ],
      "code_start_line": 44,
      "code_end_line": 53,
      "params": [],
      "have_return": true,
      "code_content": "class ParameterProperty(BaseModel):\n    type: str = Field(..., description=\"The data type of the parameter.\")\n    description: Optional[str] = Field(\n        None, description=\"A description of the parameter.\"\n    )\n    items: Optional[Item] = None\n\n    @field_serializer(\"type\")\n    def serialize_type(self, value: str, _info) -> str:\n        return serialize_type(value)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/models.py/Parameters"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/Item"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "serialize_type",
      "md_content": [
        "**serialize_type**: The function of serialize_type is to convert a given string value into a serialized format.\n\n**parameters**: The parameters of this Function.\n· parameter1: value (str) - The string input that needs to be serialized.\n· parameter2: _info - Additional information that may be used during serialization, though it is not utilized in the current implementation.\n\n**Code Description**: The serialize_type function is designed to take a string input, referred to as 'value', and pass it to another function named serialize_type for processing. The function does not perform any operations on the input itself; instead, it directly calls the serialize_type function, which is presumably defined elsewhere in the codebase. The purpose of this function is to ensure that the input string is transformed into a serialized format, which is often necessary for data storage or transmission. The second parameter, _info, is included in the function signature but is not used within the function body, indicating that it may be intended for future use or for compatibility with a specific interface.\n\n**Note**: It is important to ensure that the input string is valid and that the serialize_type function being called is properly defined and accessible within the scope of this function. Additionally, the behavior of the function may depend on the implementation of the serialize_type function it calls.\n\n**Output Example**: If the input value is \"example\", and the serialize_type function processes it to return a serialized version, the output might look like \"serialized_example\"."
      ],
      "code_start_line": 52,
      "code_end_line": 53,
      "params": [
        "self",
        "value",
        "_info"
      ],
      "have_return": true,
      "code_content": "    def serialize_type(self, value: str, _info) -> str:\n        return serialize_type(value)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "Parameters",
      "md_content": [
        "**Parameters**: The function of Parameters is to define a schema for function parameters, including their properties and requirements.\n\n**attributes**: The attributes of this Class.\n· type: str - The type of the parameter object, which defaults to \"object\".  \n· properties: Dict[str, ParameterProperty] - A dictionary where keys are parameter names and values are their properties, which is a required field.  \n· required: List[str] - A list of required parameter names, which is also a required field.  \n· additionalProperties: bool - A boolean indicating whether additional properties are allowed, defaulting to False.\n\n**Code Description**: The Parameters class is a subclass of BaseModel, which indicates that it is part of a data modeling framework that provides validation and serialization capabilities. This class is designed to encapsulate the structure and requirements of parameters used in functions.\n\nThe `type` attribute specifies the nature of the parameter object and is set to \"object\" by default. This attribute is essential as it establishes the context for the parameters being defined.\n\nThe `properties` attribute is a dictionary that maps parameter names (as strings) to their respective properties, which are defined by the ParameterProperty class. This relationship allows for a detailed specification of each parameter's characteristics, such as its data type and description.\n\nThe `required` attribute is a list that enumerates the names of parameters that must be provided when the function is called. This ensures that any function utilizing this schema adheres to its defined requirements, promoting robustness and reducing the likelihood of errors.\n\nThe `additionalProperties` attribute indicates whether parameters not explicitly defined in the `properties` dictionary are permitted. By default, this is set to False, enforcing a strict schema that only allows the specified parameters.\n\nThe Parameters class is utilized within the Function class, where it is defined as the `parameters` attribute. This integration signifies that every function can have a well-defined set of parameters, enhancing the clarity and maintainability of the code. Additionally, the Parameters class is referenced in the `create_schema_from_function` method, which constructs a Tool schema from a target function. This method extracts function metadata, including parameter information, and organizes it into the Parameters structure, thereby facilitating the creation of a comprehensive schema for the function.\n\n**Note**: When using the Parameters class, ensure that the `properties` and `required` attributes are always provided, as they are essential for defining the parameter schema. The `additionalProperties` attribute can be adjusted based on the desired flexibility of the parameter definitions."
      ],
      "code_start_line": 56,
      "code_end_line": 65,
      "params": [],
      "have_return": false,
      "code_content": "class Parameters(BaseModel):\n    type: str = Field(\"object\", description=\"The type of the parameter object.\")\n    properties: Dict[str, ParameterProperty] = Field(\n        ...,\n        description=\"A dictionary where keys are parameter names and values are their properties.\",\n    )\n    required: List[str] = Field(..., description=\"A list of required parameter names.\")\n    additionalProperties: bool = Field(\n        False, description=\"Whether additional properties are allowed.\"\n    )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/models.py/Function",
        "src/criticsearch/tools/models.py/Tool/create_schema_from_function"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/ParameterProperty"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "ClassDef",
      "name": "Function",
      "md_content": [
        "**Function**: The function of Function is to define a structured representation of a function, including its name, description, and parameters.\n\n**attributes**: The attributes of this Class.\n· name: str - The name of the function, which is a required field.  \n· description: str - A description of what the function does, which is also a required field.  \n· parameters: Parameters - An instance of the Parameters class that defines the schema for the function's parameters, which is a required field.  \n\n**Code Description**: The Function class is a subclass of BaseModel, indicating its role within a data modeling framework that provides validation and serialization capabilities. This class is designed to encapsulate the essential details of a function, including its name, description, and a structured schema for its parameters.\n\nThe `name` attribute is a string that holds the name of the function. This is crucial for identifying the function within the broader context of the application or system.\n\nThe `description` attribute is a string that provides a detailed explanation of the function's purpose and behavior. This attribute is important for documentation and clarity, allowing developers to understand the function's role without needing to inspect its implementation.\n\nThe `parameters` attribute is an instance of the Parameters class, which defines the schema for the function's parameters. This integration ensures that every function represented by the Function class has a well-defined set of parameters, promoting clarity and maintainability in the code. The Parameters class specifies the types, requirements, and additional properties of the parameters, thereby enforcing a structured approach to function definitions.\n\nThe Function class is utilized within the Tool class, where it is defined as the `function` attribute. This relationship signifies that each Tool instance can encapsulate a function definition, allowing for the creation of tools that are based on specific functions. The Tool class also includes a class method, `create_schema_from_function`, which constructs a Tool schema from a target function. This method extracts metadata from the target function, including its name, description, and parameters, and organizes this information into the Function and Parameters structures. This process enhances the clarity and usability of the function definitions within the application.\n\n**Note**: When using the Function class, ensure that all attributes (name, description, and parameters) are provided, as they are essential for defining a complete function representation. The integration with the Parameters class is critical for maintaining a structured approach to function parameter definitions."
      ],
      "code_start_line": 68,
      "code_end_line": 75,
      "params": [],
      "have_return": false,
      "code_content": "class Function(BaseModel):\n    name: str = Field(..., description=\"The name of the function.\")\n    description: str = Field(\n        ..., description=\"A description of what the function does.\"\n    )\n    parameters: Parameters = Field(\n        ..., description=\"The parameters schema for the function.\"\n    )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/models.py/Tool",
        "src/criticsearch/tools/models.py/Tool/create_schema_from_function"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/Parameters"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "ClassDef",
      "name": "Tool",
      "md_content": [
        "**Tool**: The function of Tool is to create a structured representation of a function, encapsulating its metadata and schema.\n\n**attributes**: The attributes of this Class.\n· type: str - The type of the tool, typically set to 'function'.  \n· function: Function - An instance of the Function class that defines the function's name, description, and parameters.\n\n**Code Description**: The Tool class is a subclass of BaseModel, designed to encapsulate the details of a function within a structured schema. It includes two primary attributes: `type`, which indicates the nature of the tool (defaulting to 'function'), and `function`, which is an instance of the Function class. The Function class itself represents a structured definition of a function, including its name, description, and a schema for its parameters.\n\nA key feature of the Tool class is the class method `create_schema_from_function`. This method takes a target function as an argument and extracts essential metadata, such as the function's name and documentation string. It parses the documentation to generate sections that include a description and a list of parameters. The method utilizes the inspect module to retrieve the function's signature, allowing it to identify required parameters and their types.\n\nThe extracted information is then organized into a Function instance, which is returned as part of the Tool instance. This process facilitates the creation of a comprehensive schema that can be used to represent the function in a structured manner.\n\nThe Tool class is utilized within the ToolRegistry's `get_or_create_tool_schema` method. This method retrieves or creates tool schemas for specified functions. If a function's schema is not already registered, it invokes `Tool.create_schema_from_function` to generate the schema and add it to the registry. This integration ensures that function definitions are consistently represented and easily accessible within the application.\n\n**Note**: When using the Tool class, ensure that the `function` attribute is properly defined as an instance of the Function class, as this is critical for maintaining a structured representation of the function's metadata.\n\nA possible appearance of the code's return value when invoking `Tool.create_schema_from_function` might look like this:\n```json\n{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"example_function\",\n        \"description\": \"This function serves as an example.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"param1\": {\n                    \"type\": \"int\",\n                    \"description\": \"The first parameter.\"\n                },\n                \"param2\": {\n                    \"type\": \"str\",\n                    \"description\": \"The second parameter.\"\n                }\n            },\n            \"required\": [\"param1\"],\n            \"additionalProperties\": false\n        }\n    }\n}\n```"
      ],
      "code_start_line": 78,
      "code_end_line": 147,
      "params": [],
      "have_return": true,
      "code_content": "class Tool(BaseModel):\n    type: str = Field(\n        \"function\", description=\"The type of the tool, typically 'function'.\"\n    )\n    function: Function = Field(..., description=\"The function definition for the tool.\")\n\n    @classmethod\n    def create_schema_from_function(cls, target_function):\n        \"\"\"Create a Tool schema from a target function.\"\"\"\n\n        # 提取函数名称和文档字符串\n        func_name = target_function.__name__\n        func_doc = inspect.getdoc(target_function) or \"No description provided.\"\n\n        # 解析文档字符串，生成 sections\n        docstring = Docstring(func_doc)\n        # NOTE: Only support  Google-style right now.\n        sections = docstring.parse(\"google\")\n\n        # 提取描述信息\n        description = \"\"\n        parameters = []\n\n        for section in sections:\n            if section.kind == DocstringSectionKind.text:\n                description = section.value.strip()\n            elif section.kind == DocstringSectionKind.parameters:\n                parameters = section.value\n\n        # 提取参数信息\n        signature = inspect.signature(target_function)\n        required = []\n        properties = {}\n\n        for param_name, param in signature.parameters.items():\n            param_type = param.annotation if param.annotation != inspect._empty else Any\n            param_default = param.default if param.default != inspect._empty else ...\n\n            # 从解析的参数部分提取描述\n            param_description = None\n            for param_info in parameters:\n                if param_info.name == param_name:  # 使用属性访问\n                    param_description = param_info.description\n                    break\n\n            if param_default is ...:\n                required.append(param_name)\n\n            properties[param_name] = {\n                \"type\": param_type.__name__,\n                \"description\": param_description or f\"The {param_name} parameter.\",\n            }\n\n            if get_origin(param_type) is list:\n                properties[param_name][\"items\"] = get_list_type_annotation(param_type)\n\n        # Build the final Function and Tool schema\n        function_schema = Function(\n            name=func_name,\n            description=description,\n            parameters=Parameters(\n                type=\"object\",\n                properties=properties,\n                required=required,\n                additionalProperties=False,\n            ),\n        )\n        return cls(type=\"function\", function=function_schema).model_dump(\n            exclude_none=True\n        )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/tool_registry.py",
        "src/criticsearch/tools/tool_registry.py/ToolRegistry/get_or_create_tool_schema"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/Function"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "create_schema_from_function",
      "md_content": [
        "### `create_schema_from_function`\n\n#### Overview\n\nThe `create_schema_from_function` method is a class method designed to generate a schema for a tool based on a target function. This schema includes the function's name, description, and parameters, providing a structured format for the tool. The method processes the function's docstring to extract relevant information and constructs a JSON-like schema, which can be used for further automation or documentation purposes.\n\n#### Parameters\n- **cls** (`type`): The class that is calling the method. This is implicitly passed when the method is invoked.\n- **target_function** (`function`): The function from which the schema will be created. The method inspects the function's name, docstring, and parameters to build the schema.\n\n#### Method Description\n\n1. **Extracting Function Metadata**: \n   - The method starts by extracting the function's name and docstring using the `__name__` attribute and `inspect.getdoc()`, respectively.\n   - If the docstring is empty, a default message of \"No description provided.\" is used.\n\n2. **Parsing the Docstring**: \n   - The docstring is parsed using the `Docstring` class, which is assumed to support Google-style docstrings.\n   - Sections of the docstring are identified and classified into text and parameters sections.\n\n3. **Processing the Parameters**: \n   - The method iterates through the parsed sections to extract the description of the function and its parameters.\n   - It then inspects the function's signature using the `inspect.signature()` method to identify the types, default values, and required status of each parameter.\n   - Parameters are classified into required and optional based on whether they have default values or not.\n\n4. **Building the Schema**: \n   - A `Function` schema is constructed using the extracted information. The function's parameters are detailed in the schema with their types and descriptions. If any parameter is of list type, the `get_list_type_annotation` function is used to determine the type of elements in the list.\n   - The `Parameters` class is utilized to define the structure of the parameters, including their types, descriptions, required status, and whether additional properties are allowed.\n\n5. **Returning the Schema**: \n   - Finally, the schema is returned as a serialized model, excluding any `None` values.\n\n#### Return Value\nThe method returns a serialized model of the function schema, including:\n- **name**: The name of the function.\n- **description**: The description extracted from the function's docstring.\n- **parameters**: A structured schema of the function's parameters, which includes their names, types, descriptions, and required status.\n\n#### Example\n\nAssume a function `example_function` with the following signature:\n\n```python\ndef example_function(arg1: int, arg2: List[str] = []):\n    \"\"\"\n    Example function to demonstrate schema creation.\n\n    Args:\n        arg1 (int): The first argument.\n        arg2 (List[str], optional): The second argument, which is a list of strings.\n    \"\"\"\n    pass\n```\n\nThe `create_schema_from_function` method would generate a schema with the following structure:\n\n```json\n{\n  \"type\": \"function\",\n  \"function\": {\n    \"name\": \"example_function\",\n    \"description\": \"Example function to demonstrate schema creation.\",\n    \"parameters\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"arg1\": {\n          \"type\": \"int\",\n          \"description\": \"The first argument.\"\n        },\n        \"arg2\": {\n          \"type\": \"list\",\n          \"items\": {\n            \"type\": \"str\"\n          },\n          \"description\": \"The second argument, which is a list of strings.\"\n        }\n      },\n      \"required\": [\"arg1\"],\n      \"additionalProperties\": false\n    }\n  }\n}\n```\n\n#### Notes\n- The method currently supports Google-style docstrings and expects parameters to be described in a specific format within the docstring.\n- It relies on the `get_list_type_annotation` function to determine the type of elements in list-type parameters.\n- The `Parameters` class is used to define the structure of the parameters, ensuring a consistent schema for function input validation."
      ],
      "code_start_line": 85,
      "code_end_line": 147,
      "params": [
        "cls",
        "target_function"
      ],
      "have_return": true,
      "code_content": "    def create_schema_from_function(cls, target_function):\n        \"\"\"Create a Tool schema from a target function.\"\"\"\n\n        # 提取函数名称和文档字符串\n        func_name = target_function.__name__\n        func_doc = inspect.getdoc(target_function) or \"No description provided.\"\n\n        # 解析文档字符串，生成 sections\n        docstring = Docstring(func_doc)\n        # NOTE: Only support  Google-style right now.\n        sections = docstring.parse(\"google\")\n\n        # 提取描述信息\n        description = \"\"\n        parameters = []\n\n        for section in sections:\n            if section.kind == DocstringSectionKind.text:\n                description = section.value.strip()\n            elif section.kind == DocstringSectionKind.parameters:\n                parameters = section.value\n\n        # 提取参数信息\n        signature = inspect.signature(target_function)\n        required = []\n        properties = {}\n\n        for param_name, param in signature.parameters.items():\n            param_type = param.annotation if param.annotation != inspect._empty else Any\n            param_default = param.default if param.default != inspect._empty else ...\n\n            # 从解析的参数部分提取描述\n            param_description = None\n            for param_info in parameters:\n                if param_info.name == param_name:  # 使用属性访问\n                    param_description = param_info.description\n                    break\n\n            if param_default is ...:\n                required.append(param_name)\n\n            properties[param_name] = {\n                \"type\": param_type.__name__,\n                \"description\": param_description or f\"The {param_name} parameter.\",\n            }\n\n            if get_origin(param_type) is list:\n                properties[param_name][\"items\"] = get_list_type_annotation(param_type)\n\n        # Build the final Function and Tool schema\n        function_schema = Function(\n            name=func_name,\n            description=description,\n            parameters=Parameters(\n                type=\"object\",\n                properties=properties,\n                required=required,\n                additionalProperties=False,\n            ),\n        )\n        return cls(type=\"function\", function=function_schema).model_dump(\n            exclude_none=True\n        )\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/tool_registry.py/ToolRegistry/get_or_create_tool_schema"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/get_list_type_annotation",
        "src/criticsearch/tools/models.py/Parameters",
        "src/criticsearch/tools/models.py/Function"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "get_delivery_date",
      "md_content": [
        "**get_delivery_date**: The function of get_delivery_date is to retrieve the delivery date for a customer's order based on the provided order ID and delivery type.\n\n**parameters**: The parameters of this function:\n· order_id (str): A string representing the unique ID of the order for which the delivery date is being requested.\n· delivery_type (str): A string specifying the type of delivery (e.g., \"standard\" or \"express\"). The default value is \"standard\".\n\n**Code Description**: \nThe `get_delivery_date` function is designed to fetch the delivery date associated with a given customer order. It accepts two parameters:\n1. `order_id` (str): This is a required parameter, which uniquely identifies the order whose delivery date is to be determined. \n2. `delivery_type` (str): This is an optional parameter that defines the delivery method for the order. The default value is \"standard\", but other types such as \"express\" could also be provided. The specific functionality regarding how the delivery type impacts the retrieval of the delivery date is not yet implemented, as the function currently has no logic inside it.\n\nAs the function is currently not implemented (indicated by the `pass` statement), no actions are taken within it, and it does not return any values at the moment.\n\n**Note**: \n- This function currently does not contain any operational logic or return values, meaning it needs to be implemented with appropriate business logic to fetch the delivery date based on the order ID and delivery type.\n- The function signature suggests that it will likely interact with a system (e.g., a database or API) to determine the delivery date based on the provided inputs, but this functionality is not present in the current state."
      ],
      "code_start_line": 152,
      "code_end_line": 160,
      "params": [
        "order_id",
        "delivery_type"
      ],
      "have_return": false,
      "code_content": "    def get_delivery_date(order_id: str, delivery_type: str = \"standard\"):\n        \"\"\"\n        Get the delivery date for a customer's order.\n\n        Parameters:\n            order_id (str): The unique ID of the order.\n            delivery_type (str): The type of delivery (e.g., standard or express).\n        \"\"\"\n        pass\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/tool_registry.py": [
    {
      "type": "ClassDef",
      "name": "ToolRegistry",
      "md_content": [
        "**ToolRegistry**: The function of ToolRegistry is to manage tools by using their function names as keys, allowing easy retrieval and creation of schemas for those tools.\n\n**Attributes**:\n- **_tools**: A dictionary that maps function names (as strings) to their respective tool schemas. It is initialized as an empty dictionary and is used to store the schemas of tools for quick access and reuse.\n\n**Code Description**:  \nThe `ToolRegistry` class is designed to manage the registration and retrieval of tool schemas based on function names. It allows the creation of new schemas for tools if they are not already registered. The primary use case of this class is within systems that work with a variety of tools, where each tool is associated with a function, and its schema needs to be retrieved or generated.\n\n- **`__init__`**: This method initializes an empty registry (`_tools`) for storing tool schemas. The registry is a dictionary where keys are the names of functions (as strings) and values are the schemas related to those functions. The class starts with no schemas stored.\n\n- **`get_or_create_tool_schema`**: This method accepts one or more function references (`target_functions`) as arguments. For each function provided, it checks whether the schema for that function already exists in the `_tools` dictionary. If a schema does not exist for the function, the method creates it using a class method `Tool.create_schema_from_function` and then stores it in the `_tools` dictionary. After the schema is retrieved or created, it is added to a list and returned. This method ensures that schemas are not repeatedly created for the same functions, promoting efficiency and reuse.\n\n    - **Arguments**:\n      - `*target_functions`: One or more functions whose schemas need to be retrieved or created.\n    - **Returns**: A list of dictionaries representing the schemas of the provided functions.\n\nIn the context of the larger project, the `ToolRegistry` class is used in the `BaseAgent` class (found in `src/criticsearch/base_agent.py`). Specifically, instances of `ToolRegistry` are used to manage the schemas for different tools within the agent, such as `search_aggregator` and `content_scraper`. When initializing these tools, `BaseAgent` calls `get_or_create_tool_schema` to retrieve or create the schemas associated with their functions. These schemas are essential for the tools to be correctly used in subsequent operations, such as when the agent interacts with external services or processes data.\n\nThe `ToolRegistry` class plays a crucial role in ensuring that the agent can consistently access the correct schema for its tools, avoiding the need to repeatedly recreate schemas and thus improving efficiency.\n\n**Note**:  \n- The `Tool.create_schema_from_function` method (referenced in `get_or_create_tool_schema`) is expected to be responsible for creating a schema from a function. This method should handle the specifics of schema creation and may include validation or other processing steps.\n- The `_tools` dictionary is managed entirely within the `ToolRegistry` class. Users of this class do not need to directly modify this attribute.\n- This class assumes that function names are unique and can be used as reliable keys for storing schemas.\n\n**Output Example**:  \nWhen calling `get_or_create_tool_schema` with the `search` function of `search_aggregator` and the `scrape` function of `content_scraper`, a possible return value could look like this:\n\n```python\n[\n    {\n        \"function_name\": \"search\",\n        \"schema_details\": { ... }  # Detailed schema information for the 'search' function\n    },\n    {\n        \"function_name\": \"scrape\",\n        \"schema_details\": { ... }  # Detailed schema information for the 'scrape' function\n    }\n]\n```"
      ],
      "code_start_line": 8,
      "code_end_line": 55,
      "params": [],
      "have_return": true,
      "code_content": "class ToolRegistry:\n    \"\"\"\n    A registry for managing tools using their function names as keys.\n\n    This class provides functionality to retrieve or create schemas for tools\n    based on provided functions, storing them for reuse and easy access.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize an empty registry for storing tool schemas.\n\n        Attributes:\n            _tools (Dict[str, dict]): A dictionary mapping function names\n                                      to their respective schemas.\n        \"\"\"\n        self._tools: Dict[str, dict] = {}\n\n    def get_or_create_tool_schema(self, *target_functions: Callable) -> List[Dict]:\n        \"\"\"\n        Retrieve or create tool schemas for the given functions.\n\n        If a function's schema is not already registered, it will be created\n        using `Tool.create_schema_from_function` and added to the registry.\n\n        Args:\n            *target_functions (Callable): One or more functions for which\n                                          schemas are to be retrieved or created.\n\n        Returns:\n            List[Dict]: A list of schemas corresponding to the provided functions.\n        \"\"\"\n        schemas = []\n        for target_function in target_functions:\n            func_name = target_function.__name__\n\n            # Create schema if not already registered\n            if func_name not in self._tools:\n                self._tools[func_name] = Tool.create_schema_from_function(\n                    target_function\n                )\n                logger.debug(\n                    f\"Created tool schema for: {func_name}, schema: {self._tools[func_name]}\"\n                )\n\n            schemas.append(self._tools[func_name])\n\n        return schemas\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py",
        "src/criticsearch/base_agent.py/BaseAgent",
        "src/criticsearch/tools/__init__.py"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an empty registry for storing tool schemas.\n\n**parameters**: The parameters of this Function.\n· There are no parameters for this function.\n\n**Code Description**: The __init__ function is a constructor method that is called when an instance of the ToolRegistry class is created. This function initializes an instance variable named _tools, which is a dictionary. The purpose of this dictionary is to map function names (as strings) to their respective schemas (as dictionaries). By initializing _tools as an empty dictionary, the function sets up a clean state for the ToolRegistry instance, allowing it to store tool schemas that can be added later. This design ensures that the registry starts without any pre-existing data, providing a fresh environment for subsequent operations.\n\n**Note**: It is important to understand that this function does not take any parameters and does not return any value. It solely serves the purpose of setting up the initial state of the ToolRegistry instance. Users should ensure that the _tools dictionary is populated with valid tool schemas through other methods provided in the ToolRegistry class after the instance is initialized."
      ],
      "code_start_line": 16,
      "code_end_line": 24,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self):\n        \"\"\"\n        Initialize an empty registry for storing tool schemas.\n\n        Attributes:\n            _tools (Dict[str, dict]): A dictionary mapping function names\n                                      to their respective schemas.\n        \"\"\"\n        self._tools: Dict[str, dict] = {}\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "get_or_create_tool_schema",
      "md_content": [
        "**get_or_create_tool_schema**: The function of get_or_create_tool_schema is to retrieve or create tool schemas for specified functions.\n\n**parameters**: The parameters of this Function.\n· target_functions: One or more functions for which schemas are to be retrieved or created.\n\n**Code Description**: The get_or_create_tool_schema method is a member of the ToolRegistry class, responsible for managing the schemas associated with various tools (functions) within the application. This method accepts one or more callable functions as arguments and checks if a schema for each function is already registered in the internal registry (self._tools). \n\nIf a function's schema is not found, the method invokes the Tool class's create_schema_from_function method to generate a new schema based on the function's metadata, including its name, description, and parameters. This newly created schema is then stored in the registry for future reference. The method logs the creation of the schema for debugging purposes.\n\nThe method returns a list of schemas corresponding to the provided functions, ensuring that all requested schemas are either retrieved from the registry or newly created. This functionality is crucial for maintaining a structured representation of functions within the application, allowing for consistent access to their metadata.\n\nThe get_or_create_tool_schema method is called within the __init__ method of the BaseAgent class. During the initialization of a BaseAgent instance, it retrieves or creates schemas for the search aggregator and content scraper tools. These schemas are then stored in the conversation manager's available tools, facilitating their use in subsequent interactions.\n\n**Note**: When using this method, ensure that the functions passed as arguments are callable and properly defined, as the method relies on their metadata to generate the schemas.\n\n**Output Example**: A possible appearance of the code's return value when invoking get_or_create_tool_schema might look like this:\n```json\n[\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"search\",\n            \"description\": \"Performs a search operation.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"str\",\n                        \"description\": \"The search query.\"\n                    },\n                    \"limit\": {\n                        \"type\": \"int\",\n                        \"description\": \"The maximum number of results to return.\"\n                    }\n                },\n                \"required\": [\"query\"],\n                \"additionalProperties\": false\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"scrape\",\n            \"description\": \"Scrapes content from a given URL.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"url\": {\n                        \"type\": \"str\",\n                        \"description\": \"The URL to scrape.\"\n                    }\n                },\n                \"required\": [\"url\"],\n                \"additionalProperties\": false\n            }\n        }\n    }\n]\n```"
      ],
      "code_start_line": 26,
      "code_end_line": 55,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def get_or_create_tool_schema(self, *target_functions: Callable) -> List[Dict]:\n        \"\"\"\n        Retrieve or create tool schemas for the given functions.\n\n        If a function's schema is not already registered, it will be created\n        using `Tool.create_schema_from_function` and added to the registry.\n\n        Args:\n            *target_functions (Callable): One or more functions for which\n                                          schemas are to be retrieved or created.\n\n        Returns:\n            List[Dict]: A list of schemas corresponding to the provided functions.\n        \"\"\"\n        schemas = []\n        for target_function in target_functions:\n            func_name = target_function.__name__\n\n            # Create schema if not already registered\n            if func_name not in self._tools:\n                self._tools[func_name] = Tool.create_schema_from_function(\n                    target_function\n                )\n                logger.debug(\n                    f\"Created tool schema for: {func_name}, schema: {self._tools[func_name]}\"\n                )\n\n            schemas.append(self._tools[func_name])\n\n        return schemas\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/__init__"
      ],
      "reference_who": [
        "src/criticsearch/tools/models.py/Tool",
        "src/criticsearch/tools/models.py/Tool/create_schema_from_function"
      ],
      "special_reference_type": [
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/content_scraper/__init__.py": [
    {
      "type": "ClassDef",
      "name": "ContentScraper",
      "md_content": [
        "**ContentScraper**: The function of ContentScraper is to scrape content from the provided URLs by using an external API (Tavily) with a fallback mechanism for custom scraping.\n\n**attributes**: \n- urls: List[str] - A list of URLs from which content is to be scraped.\n\n**Code Description**: \nThe `ContentScraper` class provides a static method, `scrape`, that is used to extract content from a list of URLs. The method follows these main steps:\n\n1. **API Key and Initialization**: The method starts by retrieving an API key from the project settings (`settings.tavily.api_key`) and initializes an instance of `TavilyExtract` with the API key.\n   \n2. **Tavily Extraction**: The method attempts to scrape content from the provided URLs using the `TavilyExtract` instance by calling `extract_content` on the `tavily` object. This method returns results that are either successful or failed.\n\n3. **Error Handling**: If the Tavily extraction results contain an error (indicated by the presence of the \"error\" key), the method logs the error and proceeds to fall back to a custom web scraping solution by invoking `FallbackWebScraper.scrape`. This is done to ensure that content scraping continues even if the Tavily service fails.\n\n4. **Processing Successful Results**: If the Tavily extraction is successful, the results (contained in the `results` key) are iterated through. For each result, the URL and raw content are extracted and stored as `ScrapedData` objects, which are then added to a list of successful results.\n\n5. **Handling Failed Results**: If any URLs are marked as failed in the Tavily results (`failed_results`), the method logs a warning and retries scraping those URLs using the custom fallback scraper.\n\n6. **Final Results**: After processing both successful and failed results, the method merges these into a final list and returns them encapsulated within a `ScrapedDataList` object, which is serialized using the `model_dump` method before being returned.\n\nThis approach ensures a robust content scraping process with error handling and fallback mechanisms for cases when the primary extraction method (Tavily) fails.\n\nThe `scrape` method is used within the `BaseAgent` class (located in `src/criticsearch/base_agent.py`), which initializes an instance of `ContentScraper` and adds it to the list of available tools for the conversation manager. This allows the agent to call the `scrape` method when it requires content extraction from a set of URLs.\n\n**Note**: \n- The `scrape` method is asynchronous, meaning it must be awaited when called.\n- The method handles both successful and failed scraping attempts by using a combination of the Tavily API and a custom fallback scraper.\n- Ensure the API key for Tavily is correctly set in the project settings for successful integration.\n\n**Output Example**: \nThe `scrape` method will return a serialized `ScrapedDataList` object that contains a list of `ScrapedData` objects. Each `ScrapedData` object includes the URL and the raw content extracted from the source. Here's a mock example:\n\n```json\n{\n  \"data\": [\n    {\n      \"url\": \"https://example.com/page1\",\n      \"content\": \"This is the raw content from page 1.\"\n    },\n    {\n      \"url\": \"https://example.com/page2\",\n      \"content\": \"This is the raw content from page 2.\"\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 11,
      "code_end_line": 63,
      "params": [],
      "have_return": true,
      "code_content": "class ContentScraper:\n    @staticmethod\n    async def scrape(urls: List[str]) -> ScrapedDataList:\n        \"\"\"\n        Scrapes content using the provided URLs.\n\n        Args:\n            urls (List[str]): A list of URLs to scrape content from.\n        \"\"\"\n        api_key = settings.tavily.api_key\n        tavily = TavilyExtract(api_key)\n\n        # Try to extract using Tavily\n        tavily_results = await tavily.extract_content(urls)\n        final_results = []\n\n        # Check for errors or failed results in the Tavily response\n        if \"error\" in tavily_results:\n            # If Tavily extraction fails, fall back to custom web scraping\n            logger.error(f\"Tavily API extraction failed: {tavily_results.get('error')}\")\n            logger.info(\n                \"Tavily API extraction failed, falling back to custom scraping...\"\n            )\n            final_results = await FallbackWebScraper.scrape(urls)\n        else:\n            # Process successful results from Tavily\n            successful_results = []\n\n            results = tavily_results.get(\"results\", [])\n            for result in results:\n                # Extract the necessary data from the Tavily API response\n                url = result.get(\"url\")\n                raw_content = result.get(\"raw_content\")\n\n                successful_results.append(\n                    ScrapedData(\n                        url=url,\n                        content=raw_content,\n                    )\n                )\n\n            failed_results = tavily_results.get(\"failed_results\", [])\n\n            # If Tavily has failed results, log them and proceed with fallback\n            if failed_results:\n                logger.warning(f\"Some URLs failed in Tavily extraction.\")\n                failed_urls = [result.get(\"url\") for result in failed_results]\n                failed_results = await FallbackWebScraper.scrape(failed_urls)\n\n            # Merge both successful and failed results into ScrapedDataList\n            final_results = successful_results + failed_results\n\n        return ScrapedDataList(data=final_results).model_dump()\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py",
        "src/criticsearch/base_agent.py/BaseAgent/__init__",
        "src/criticsearch/tools/__init__.py"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "scrape",
      "md_content": [
        "**scrape**: The function of scrape is to asynchronously scrape content from a list of provided URLs, utilizing the Tavily API for extraction and falling back to a custom web scraping method if necessary.\n\n**parameters**: The parameters of this Function.\n· urls: List[str] - A list of URLs to scrape content from.\n\n**Code Description**: The `scrape` function is an asynchronous method designed to extract content from a list of URLs. It first initializes an instance of the `TavilyExtract` class using an API key retrieved from the settings. This instance is responsible for interacting with the Tavily API to perform the content extraction.\n\nThe function begins by calling the `extract_content` method of the `TavilyExtract` instance, passing the list of URLs. This method sends an asynchronous POST request to the Tavily API, which returns a JSON response containing the results of the extraction. If the response includes an error, the function logs the error message and proceeds to invoke the `FallbackWebScraper.scrape` method, which serves as a backup scraping mechanism.\n\nIn the case of successful extraction, the function processes the results returned by the Tavily API. It iterates through the successful results, extracting the URL and raw content from each result. For each successful extraction, it creates a `ScrapedData` object, which encapsulates the URL and the corresponding content.\n\nAdditionally, if there are any failed results in the Tavily API response, the function logs a warning and attempts to scrape the failed URLs using the `FallbackWebScraper.scrape` method. The results from both successful and fallback scraping are merged into a final list of `ScrapedData` objects.\n\nFinally, the function returns a `ScrapedDataList` object, which contains all the scraped data, including both successful and failed attempts. This object is serialized using the `model_dump` method, providing a structured output of the scraping results.\n\nThe `scrape` function is called within the `BaseAgent` class, specifically in the `search_and_browse` method. This method orchestrates the overall search and scraping process, first performing a search using the `SearchAggregator` and then invoking the `scrape` function to gather additional content from the URLs identified during the search. This integration ensures that the scraping functionality is seamlessly incorporated into the broader search and retrieval workflow of the application.\n\n**Note**: When using this function, ensure that the URLs provided are valid and accessible. Additionally, be aware of the legal and ethical considerations surrounding web scraping, including compliance with the target website's terms of service.\n\n**Output Example**: A possible appearance of the code's return value could be:\n```\n[\n    ScrapedData(url=\"http://example.com\", title=\"Example Title\", content=\"This is the main content of the page.\"),\n    ScrapedData(url=\"http://anotherexample.com\", title=\"Another Example\", content=\"No content available\")\n]\n```"
      ],
      "code_start_line": 13,
      "code_end_line": 63,
      "params": [
        "urls"
      ],
      "have_return": true,
      "code_content": "    async def scrape(urls: List[str]) -> ScrapedDataList:\n        \"\"\"\n        Scrapes content using the provided URLs.\n\n        Args:\n            urls (List[str]): A list of URLs to scrape content from.\n        \"\"\"\n        api_key = settings.tavily.api_key\n        tavily = TavilyExtract(api_key)\n\n        # Try to extract using Tavily\n        tavily_results = await tavily.extract_content(urls)\n        final_results = []\n\n        # Check for errors or failed results in the Tavily response\n        if \"error\" in tavily_results:\n            # If Tavily extraction fails, fall back to custom web scraping\n            logger.error(f\"Tavily API extraction failed: {tavily_results.get('error')}\")\n            logger.info(\n                \"Tavily API extraction failed, falling back to custom scraping...\"\n            )\n            final_results = await FallbackWebScraper.scrape(urls)\n        else:\n            # Process successful results from Tavily\n            successful_results = []\n\n            results = tavily_results.get(\"results\", [])\n            for result in results:\n                # Extract the necessary data from the Tavily API response\n                url = result.get(\"url\")\n                raw_content = result.get(\"raw_content\")\n\n                successful_results.append(\n                    ScrapedData(\n                        url=url,\n                        content=raw_content,\n                    )\n                )\n\n            failed_results = tavily_results.get(\"failed_results\", [])\n\n            # If Tavily has failed results, log them and proceed with fallback\n            if failed_results:\n                logger.warning(f\"Some URLs failed in Tavily extraction.\")\n                failed_urls = [result.get(\"url\") for result in failed_results]\n                failed_results = await FallbackWebScraper.scrape(failed_urls)\n\n            # Merge both successful and failed results into ScrapedDataList\n            final_results = successful_results + failed_results\n\n        return ScrapedDataList(data=final_results).model_dump()\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/__init__",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse"
      ],
      "reference_who": [
        "src/criticsearch/tools/content_scraper/fallback_web_scraper.py/FallbackWebScraper",
        "src/criticsearch/tools/content_scraper/models.py/ScrapedData",
        "src/criticsearch/tools/content_scraper/models.py/ScrapedDataList",
        "src/criticsearch/tools/content_scraper/tavily_extract.py/TavilyExtract",
        "src/criticsearch/tools/content_scraper/tavily_extract.py/TavilyExtract/extract_content"
      ],
      "special_reference_type": [
        false,
        false,
        true,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/content_scraper/fallback_web_scraper.py": [
    {
      "type": "ClassDef",
      "name": "FallbackWebScraper",
      "md_content": [
        "**FallbackWebScraper**: The function of FallbackWebScraper is to scrape content from a list of webpages asynchronously, serving as a fallback mechanism when the Tavily API fails.\n\n**attributes**: The attributes of this Class.\n· urls: List[str] - A list of URLs to scrape content from.\n\n**Code Description**: The FallbackWebScraper class contains a static method named `scrape`, which is designed to handle the asynchronous scraping of web content from a provided list of URLs. This method is particularly useful in scenarios where the primary content extraction method, the Tavily API, encounters issues or fails to return valid results. \n\nThe `scrape` method begins by defining a set of HTTP headers to mimic a standard web browser request, enhancing the likelihood of successful content retrieval. It then defines an inner asynchronous function `fetch_url`, which takes a single URL as an argument. This function is responsible for making the actual HTTP GET request using the `httpx` library, which supports asynchronous operations and HTTP/2.\n\nWithin `fetch_url`, the method attempts to fetch the content of the specified URL. If the response status code is not 200 (indicating a successful request), it returns a `ScrapedData` object containing the URL and an error message detailing the HTTP status code and reason. If the request is successful, the HTML content is parsed using BeautifulSoup, where unwanted elements such as scripts and styles are removed to focus on the main content.\n\nThe main content is extracted by searching for common HTML structures like `<main>`, `<article>`, or `<div>` elements that typically contain the primary content of a webpage. If no main content is found, a default message indicating \"No content available\" is returned. Otherwise, the text from paragraph tags is concatenated and cleaned up to form the final content string. The method then returns a `ScrapedData` object containing the URL, the page title, and the extracted content.\n\nThe `scrape` method utilizes `asyncio.gather` to concurrently fetch content from all provided URLs, improving efficiency and reducing overall scraping time.\n\nThis class is called by the `scrape` method of the `ContentScraper` class, which first attempts to extract content using the Tavily API. If the Tavily API fails, the `FallbackWebScraper.scrape` method is invoked to handle the fallback scraping process. This relationship ensures that the FallbackWebScraper serves as a reliable alternative for content extraction when the primary method is unavailable.\n\n**Note**: When using this code, ensure that the URLs provided are valid and accessible. Additionally, be aware of the legal and ethical considerations surrounding web scraping, including compliance with the target website's terms of service.\n\n**Output Example**: A possible appearance of the code's return value could be:\n```\n[\n    ScrapedData(url=\"http://example.com\", title=\"Example Title\", content=\"This is the main content of the page.\"),\n    ScrapedData(url=\"http://anotherexample.com\", title=\"Another Example\", content=\"No content available\")\n]\n```"
      ],
      "code_start_line": 11,
      "code_end_line": 67,
      "params": [],
      "have_return": true,
      "code_content": "class FallbackWebScraper:\n    @staticmethod\n    async def scrape(urls: List[str]) -> List[ScrapedData]:\n        \"\"\"\n        Scrapes content from a list of webpages asynchronously.\n        If Tavily API fails, fall back to scraping.\n        \"\"\"\n        headers = {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n        }\n\n        async def fetch_url(url: str) -> ScrapedData:\n            try:\n                async with httpx.AsyncClient(\n                    http2=True, follow_redirects=True\n                ) as client:\n                    response = await client.get(url, headers=headers, timeout=10)\n\n                    if response.status_code != 200:\n                        return ScrapedData(\n                            url=url,\n                            error=f\"HTTP {response.status_code}: {response.reason_phrase}\",\n                        )\n\n                    html = response.text\n                    soup = BeautifulSoup(html, \"html.parser\")\n\n                    # Remove unwanted elements\n                    for script in soup([\"script\", \"style\", \"meta\", \"noscript\"]):\n                        script.decompose()\n\n                    # Extract content\n                    main_content = (\n                        soup.find(\"main\")\n                        or soup.find(\"article\")\n                        or soup.find(\"div\", class_=re.compile(r\"content|main|article\"))\n                    )\n                    content = (\n                        \"No content available\"\n                        if not main_content\n                        else \"\\n\".join(\n                            [\n                                re.sub(r\"\\s+\", \" \", p.get_text(strip=True))\n                                for p in main_content.find_all(\"p\")\n                            ]\n                        )\n                    )\n\n                    return ScrapedData(\n                        url=url,\n                        title=soup.title.string if soup.title else \"Untitled\",\n                        content=content,\n                    )\n            except Exception as e:\n                return ScrapedData(url=url, error=f\"Error: {str(e)}\")\n\n        return await asyncio.gather(*(fetch_url(url) for url in urls))\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/content_scraper/__init__.py",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "scrape",
      "md_content": [
        "**scrape**: The function of scrape is to asynchronously scrape content from a list of webpages, utilizing a fallback mechanism if the Tavily API fails.\n\n**parameters**: The parameters of this Function.\n· urls: List[str] - A list of URLs from which the content will be scraped.\n\n**Code Description**: The scrape function is designed to handle the asynchronous scraping of multiple webpages. It takes a list of URLs as input and returns a list of ScrapedData objects, which encapsulate the results of the scraping operation for each URL. The function begins by defining a headers dictionary that includes a User-Agent string to mimic a typical web browser request, which helps avoid potential blocks from the target websites.\n\nWithin the scrape function, an inner asynchronous function named fetch_url is defined. This function is responsible for making the actual HTTP requests to each URL. It utilizes the httpx library's AsyncClient to send GET requests with the specified headers and a timeout of 10 seconds. If the response status code is not 200 (indicating a successful request), the function constructs a ScrapedData object containing the URL and an error message detailing the HTTP status code and reason.\n\nIf the request is successful, the function processes the HTML content of the response using BeautifulSoup. It removes unwanted elements such as scripts, styles, and meta tags to focus on the main content of the page. The function then attempts to locate the main content area by searching for common HTML tags like <main>, <article>, or <div> with class names that suggest they contain the primary content. If no main content is found, it defaults to a message indicating that no content is available.\n\nThe content is extracted from the identified main content area by joining the text of all <p> tags, ensuring that excessive whitespace is removed. A ScrapedData object is then created with the URL, the title of the page (if available), and the extracted content.\n\nThe scrape function ultimately calls asyncio.gather to execute the fetch_url function concurrently for all URLs in the input list. This allows for efficient scraping of multiple pages at once, significantly reducing the time required compared to synchronous requests.\n\nFrom a functional perspective, the scrape function is integral to the FallbackWebScraper module, providing a mechanism to retrieve webpage content when other methods, such as the Tavily API, are unavailable. The results are structured in ScrapedData objects, which standardize the output format, making it easier for other components of the system to handle both successful and failed scraping attempts.\n\n**Note**: It is important to handle the ScrapedData objects carefully, particularly by checking the error attribute to determine if the scraping was successful. The content and title attributes may be None if the scraping process encounters issues or if the content is not available on the page.\n\n**Output Example**: \n[\n    ScrapedData(url=\"http://example.com\", title=\"Example Domain\", content=\"This domain is for use in illustrative examples in documents.\", error=None),\n    ScrapedData(url=\"http://nonexistent.com\", title=None, content=None, error=\"HTTP 404: Not Found\")\n]"
      ],
      "code_start_line": 13,
      "code_end_line": 67,
      "params": [
        "urls"
      ],
      "have_return": true,
      "code_content": "    async def scrape(urls: List[str]) -> List[ScrapedData]:\n        \"\"\"\n        Scrapes content from a list of webpages asynchronously.\n        If Tavily API fails, fall back to scraping.\n        \"\"\"\n        headers = {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n        }\n\n        async def fetch_url(url: str) -> ScrapedData:\n            try:\n                async with httpx.AsyncClient(\n                    http2=True, follow_redirects=True\n                ) as client:\n                    response = await client.get(url, headers=headers, timeout=10)\n\n                    if response.status_code != 200:\n                        return ScrapedData(\n                            url=url,\n                            error=f\"HTTP {response.status_code}: {response.reason_phrase}\",\n                        )\n\n                    html = response.text\n                    soup = BeautifulSoup(html, \"html.parser\")\n\n                    # Remove unwanted elements\n                    for script in soup([\"script\", \"style\", \"meta\", \"noscript\"]):\n                        script.decompose()\n\n                    # Extract content\n                    main_content = (\n                        soup.find(\"main\")\n                        or soup.find(\"article\")\n                        or soup.find(\"div\", class_=re.compile(r\"content|main|article\"))\n                    )\n                    content = (\n                        \"No content available\"\n                        if not main_content\n                        else \"\\n\".join(\n                            [\n                                re.sub(r\"\\s+\", \" \", p.get_text(strip=True))\n                                for p in main_content.find_all(\"p\")\n                            ]\n                        )\n                    )\n\n                    return ScrapedData(\n                        url=url,\n                        title=soup.title.string if soup.title else \"Untitled\",\n                        content=content,\n                    )\n            except Exception as e:\n                return ScrapedData(url=url, error=f\"Error: {str(e)}\")\n\n        return await asyncio.gather(*(fetch_url(url) for url in urls))\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/content_scraper/models.py/ScrapedData"
      ],
      "special_reference_type": [
        true
      ]
    },
    {
      "type": "FunctionDef",
      "name": "fetch_url",
      "md_content": [
        "**fetch_url**: The function of fetch_url is to asynchronously retrieve and scrape content from a specified URL, returning structured data about the page, including its title and main content, or an error message if the retrieval fails.\n\n**parameters**: The parameters of this Function.\n· url: str - The URL from which the content is to be scraped.\n\n**Code Description**: The fetch_url function is designed to perform an asynchronous HTTP GET request to a specified URL using the httpx library. It initiates an asynchronous context with an HTTP client that supports HTTP/2 and follows redirects. The function attempts to retrieve the content of the page within a timeout period of 10 seconds.\n\nUpon receiving a response, the function checks the HTTP status code. If the status code is not 200 (indicating a successful request), it constructs and returns a ScrapedData object containing the URL and an error message that specifies the HTTP status code and reason phrase.\n\nIf the response is successful, the function proceeds to parse the HTML content using BeautifulSoup. It removes unwanted elements such as scripts, styles, meta tags, and noscript tags to clean the document. The function then attempts to extract the main content of the page by searching for specific HTML tags, such as <main>, <article>, or <div> elements with class names that include \"content\", \"main\", or \"article\".\n\nThe extracted content is processed to ensure that it is clean and well-formatted, specifically by stripping unnecessary whitespace from paragraph elements. If no main content is found, a default message \"No content available\" is returned.\n\nFinally, the function returns a ScrapedData object populated with the URL, the title of the page (if available), and the extracted content. If any exceptions occur during the process, the function captures the exception and returns a ScrapedData object with the URL and an error message indicating the nature of the error.\n\nThis function is integral to the web scraping process as it provides a structured way to handle both successful and failed scraping attempts. The results are encapsulated in ScrapedData objects, which can be further processed or aggregated by other components of the system, such as the FallbackWebScraper.\n\n**Note**: It is important to handle the returned ScrapedData object with care, particularly by checking the error attribute to determine if the scraping was successful. The title and content attributes may be optional and could be None if the information is not available.\n\n**Output Example**: \nA possible return value from the fetch_url function could look like this:\n```\nScrapedData(\n    url=\"https://example.com\",\n    title=\"Example Domain\",\n    content=\"This domain is for use in illustrative examples in documents.\"\n)\n```\nOr in the case of an error:\n```\nScrapedData(\n    url=\"https://example.com\",\n    error=\"HTTP 404: Not Found\"\n)\n```"
      ],
      "code_start_line": 22,
      "code_end_line": 65,
      "params": [
        "url"
      ],
      "have_return": true,
      "code_content": "        async def fetch_url(url: str) -> ScrapedData:\n            try:\n                async with httpx.AsyncClient(\n                    http2=True, follow_redirects=True\n                ) as client:\n                    response = await client.get(url, headers=headers, timeout=10)\n\n                    if response.status_code != 200:\n                        return ScrapedData(\n                            url=url,\n                            error=f\"HTTP {response.status_code}: {response.reason_phrase}\",\n                        )\n\n                    html = response.text\n                    soup = BeautifulSoup(html, \"html.parser\")\n\n                    # Remove unwanted elements\n                    for script in soup([\"script\", \"style\", \"meta\", \"noscript\"]):\n                        script.decompose()\n\n                    # Extract content\n                    main_content = (\n                        soup.find(\"main\")\n                        or soup.find(\"article\")\n                        or soup.find(\"div\", class_=re.compile(r\"content|main|article\"))\n                    )\n                    content = (\n                        \"No content available\"\n                        if not main_content\n                        else \"\\n\".join(\n                            [\n                                re.sub(r\"\\s+\", \" \", p.get_text(strip=True))\n                                for p in main_content.find_all(\"p\")\n                            ]\n                        )\n                    )\n\n                    return ScrapedData(\n                        url=url,\n                        title=soup.title.string if soup.title else \"Untitled\",\n                        content=content,\n                    )\n            except Exception as e:\n                return ScrapedData(url=url, error=f\"Error: {str(e)}\")\n",
      "name_column": 18,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/content_scraper/models.py/ScrapedData"
      ],
      "special_reference_type": [
        true
      ]
    }
  ],
  "src/criticsearch/tools/content_scraper/models.py": [
    {
      "type": "ClassDef",
      "name": "ScrapedData",
      "md_content": [
        "**ScrapedData**: The function of ScrapedData is to represent a data object that holds information scraped from a given URL, including content, title, and potential errors.\n\n**attributes**: The attributes of this Class.\n· url: str - The URL from which the data is scraped.\n· title: Optional[str] - The title of the scraped page, which can be None if unavailable.\n· content: Optional[str] - The main content of the scraped page, which can be None if not found or unavailable.\n· error: Optional[str] - An error message, if there was an issue during scraping.\n\n**Code Description**: The ScrapedData class is a data container that is designed to store and structure the information extracted from web scraping operations. It inherits from `BaseModel`, which likely provides data validation and serialization functionality. The class includes four attributes:\n\n1. **url** (str): This is the URL from which content is scraped, making it an essential identifier for the scraped data.\n2. **title** (Optional[str]): This attribute holds the title of the webpage or content if available, providing a reference to the type or subject of the page. It is optional and can be None if the title is not present.\n3. **content** (Optional[str]): The main content that was extracted from the webpage is stored in this field. It is optional, as some pages might not have meaningful content or may not be accessible.\n4. **error** (Optional[str]): This attribute is used to store any error message that might have occurred during the scraping process. If an error was encountered, this field will contain the error message; otherwise, it will be None.\n\nThe ScrapedData class plays a crucial role in both successful and failed scraping scenarios. When content is scraped successfully, the `url` and `content` attributes are populated. If there are any issues during scraping, such as an HTTP error or a failure to retrieve meaningful content, the `error` attribute will contain details about what went wrong. This class is used by the `scrape` functions found in the `FallbackWebScraper` and `ContentScraper` modules.\n\nFrom a functional perspective, ScrapedData objects are instantiated during the scraping process to store the results of individual scraping attempts. If the scraping process is successful, the object is populated with data like the content of the page and its title. If scraping fails, the object includes an error message to provide insight into the issue. These instances are then collected in lists, such as `ScrapedDataList`, which is used to return the aggregated results.\n\nThe `scrape` function in `ContentScraper` first tries to extract content using the Tavily API and constructs a ScrapedData object for each URL it processes. In case of failure, it uses `FallbackWebScraper.scrape`, which also returns ScrapedData objects. These instances are used throughout the system to ensure that scraping results are handled consistently, even when some URLs result in errors.\n\n**Note**: The `ScrapedData` class should always be handled with care, especially when dealing with failed scrapes. The presence of the `error` attribute should be checked to ensure that the scraping process was successful. Additionally, it is important to understand that content and title are optional attributes and may be missing in certain cases."
      ],
      "code_start_line": 6,
      "code_end_line": 10,
      "params": [],
      "have_return": false,
      "code_content": "class ScrapedData(BaseModel):\n    url: str\n    title: Optional[str] = None\n    content: Optional[str] = None\n    error: Optional[str] = None\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/content_scraper/__init__.py",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape",
        "src/criticsearch/tools/content_scraper/fallback_web_scraper.py",
        "src/criticsearch/tools/content_scraper/fallback_web_scraper.py/FallbackWebScraper/scrape",
        "src/criticsearch/tools/content_scraper/fallback_web_scraper.py/FallbackWebScraper/scrape/fetch_url",
        "src/criticsearch/tools/content_scraper/models.py/ScrapedDataList"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "ScrapedDataList",
      "md_content": [
        "**ScrapedDataList**: The function of ScrapedDataList is to represent a collection of ScrapedData objects, holding the results of web scraping, including both successful and failed attempts, with serialization capabilities to output the data in a readable format.\n\n**attributes**: The attributes of this Class.\n· data: List[ScrapedData] - A list of ScrapedData objects, representing the individual scraping results for each URL processed. It contains both successful and failed results.\n· max_content_length: int - The maximum allowed length for individual scraped content. If the content exceeds this length, it will be truncated.\n· max_output_length: int - The maximum length of the serialized result that can be returned. If the output exceeds this length, it will be truncated.\n\n**Code Description**: \nThe ScrapedDataList class is designed to manage a collection of ScrapedData objects, which store the results of scraping attempts for multiple URLs. It inherits from BaseModel, providing data validation and serialization capabilities. The class contains three key attributes:\n\n1. **data** (List[ScrapedData]): This attribute holds a list of ScrapedData instances, which represent the individual results of the scraping process. Each ScrapedData object can contain information like the scraped URL, title, content, and any errors encountered during scraping. This list forms the core of the class, containing all the data gathered during scraping.\n\n2. **max_content_length** (int): This attribute defines the maximum allowable length for the content of each scraped data object. If any scraped content exceeds this length, it will be truncated and appended with the string \"[TOO LONG, END]\" to indicate that the content has been cut off. The default value is set to 10,000 characters.\n\n3. **max_output_length** (int): This attribute controls the maximum length of the entire serialized output. If the concatenated result of all scraped data exceeds this length, the output will be truncated with the message \"[OUTPUT TOO LONG, TRUNCATED]\" to avoid excessive output. The default value is set to 100,000 characters.\n\nThe class includes the method `ser_model`, which performs the serialization of the ScrapedDataList object into a human-readable string format. The function iterates over each ScrapedData object in the `data` attribute and processes it as follows:\n\n- If the ScrapedData object contains an error, the method appends an error message to the result, specifying the URL and the associated error.\n- If no error is found, the content is checked against the `max_content_length`. If the content exceeds this length, it is truncated to the specified limit, with the string \"[TOO LONG, END]\" appended to signal the truncation.\n- The method then constructs a string for each ScrapedData object, including the URL, title, and content.\n- All these strings are concatenated with a separator (\"---\") between each entry.\n\nFinally, the complete serialized string is checked against the `max_output_length`. If the overall string exceeds the defined length, it will be truncated with the message \"[OUTPUT TOO LONG, TRUNCATED]\".\n\nFrom a functional perspective, ScrapedDataList is typically used to aggregate multiple ScrapedData objects that represent the results of a scraping operation. For example, the `scrape` function in the `ContentScraper` module calls this class to collect the results of web scraping and returns a serialized version of the results as a string.\n\nThe ScrapedDataList class provides an efficient way to manage and output scraped data, ensuring that even large datasets are handled appropriately by applying length restrictions at both the individual content level and the overall output level. This ensures that the serialized results remain within acceptable limits for processing or logging.\n\n**Note**: When using ScrapedDataList, ensure that the content length and output length are managed effectively, especially when handling large sets of data, to avoid data truncation. Additionally, be aware that the `error` field in ScrapedData objects may be present, and it should be checked to handle failed scraping attempts appropriately.\n\n**Output Example**:\nHere is an example of a serialized output that might be returned by the `ser_model` method:\n\n```\nURL: https://example.com/page1\nTitle: Example Page 1\nContent:\nThis is the content of the first page. It contains relevant information about the topic.\n\n---\nURL: https://example.com/page2\nTitle: Example Page 2\nContent:\nThis page has too much content. It is truncated here: Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. [TOO LONG, END]\n\n[OUTPUT TOO LONG, TRUNCATED]\n```"
      ],
      "code_start_line": 13,
      "code_end_line": 46,
      "params": [],
      "have_return": true,
      "code_content": "class ScrapedDataList(BaseModel):\n    data: List[ScrapedData] = Field(default_factory=list)\n    max_content_length: int = 10000  # Max length for individual content\n    max_output_length: int = 100000  # Max length for the entire serialized result\n\n    @model_serializer\n    def ser_model(self) -> str:\n        # List to store concatenated strings\n        result = []\n\n        for data in self.data:\n            if data.error:\n                result.append(f\"Error for URL {data.url}: {data.error}\\n\")\n                continue  # Skip further processing if there's an error\n\n            assert data.content is not None\n\n            # Truncate content to ensure it does not exceed max_content_length\n            if len(data.content) > self.max_content_length:\n                data.content = (\n                    data.content[: self.max_content_length] + \"[TOO LONG, END]\"\n                )\n\n            result.append(\n                f\"URL: {data.url}\\nTitle: {data.title}\\nContent:\\n{data.content}\\n\"\n            )\n\n        output = \"\\n---\\n\".join(result)\n\n        # Apply final length truncation to the overall result\n        if len(output) > self.max_output_length:\n            output = output[: self.max_output_length] + \"\\n[OUTPUT TOO LONG, TRUNCATED]\"\n\n        return output\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/content_scraper/__init__.py",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape"
      ],
      "reference_who": [
        "src/criticsearch/tools/content_scraper/models.py/ScrapedData"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "ser_model",
      "md_content": [
        "**ser_model**: The function of ser_model is to generate a formatted string representation of scraped data, including error handling and content truncation.\n\n**parameters**: The parameters of this Function.\n· self: An instance of the class that contains the scraped data and configuration settings.\n\n**Code Description**: The ser_model function processes a collection of scraped data stored in the instance variable `self.data`. It initializes an empty list called `result` to accumulate formatted strings for each data entry. The function iterates over each item in `self.data`, checking for any errors associated with the data. If an error is found, it appends an error message to the `result` list and skips further processing for that entry.\n\nFor valid entries, the function asserts that the content is not None. It then checks if the length of the content exceeds a predefined maximum length (`self.max_content_length`). If it does, the content is truncated, and a suffix indicating truncation is added. The function constructs a formatted string that includes the URL, title, and content of the data entry, which is then appended to the `result` list.\n\nAfter processing all entries, the function joins the strings in the `result` list with a separator (\"---\") to create a single output string. It then checks if the total length of this output exceeds another predefined maximum length (`self.max_output_length`). If it does, the output is truncated, and a message indicating truncation is appended.\n\nFinally, the function returns the formatted output string, which contains the processed information of all the scraped data entries.\n\n**Note**: It is important to ensure that `self.data` is properly populated with valid data objects before calling this function. Additionally, the maximum lengths for content and output should be set appropriately to avoid unintended truncation.\n\n**Output Example**: \n```\nURL: http://example.com/page1\nTitle: Example Page 1\nContent:\nThis is the content of the first example page.\n\n---\nURL: http://example.com/page2\nTitle: Example Page 2\nContent:\nError for URL http://example.com/page2: Page not found\n\n---\nURL: http://example.com/page3\nTitle: Example Page 3\nContent:\nThis is the content of the third example page, which is quite informative and exceeds the maximum length set for content. [TOO LONG, END]\n```"
      ],
      "code_start_line": 19,
      "code_end_line": 46,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def ser_model(self) -> str:\n        # List to store concatenated strings\n        result = []\n\n        for data in self.data:\n            if data.error:\n                result.append(f\"Error for URL {data.url}: {data.error}\\n\")\n                continue  # Skip further processing if there's an error\n\n            assert data.content is not None\n\n            # Truncate content to ensure it does not exceed max_content_length\n            if len(data.content) > self.max_content_length:\n                data.content = (\n                    data.content[: self.max_content_length] + \"[TOO LONG, END]\"\n                )\n\n            result.append(\n                f\"URL: {data.url}\\nTitle: {data.title}\\nContent:\\n{data.content}\\n\"\n            )\n\n        output = \"\\n---\\n\".join(result)\n\n        # Apply final length truncation to the overall result\n        if len(output) > self.max_output_length:\n            output = output[: self.max_output_length] + \"\\n[OUTPUT TOO LONG, TRUNCATED]\"\n\n        return output\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/content_scraper/tavily_extract.py": [
    {
      "type": "ClassDef",
      "name": "TavilyExtract",
      "md_content": [
        "**TavilyExtract**: The function of TavilyExtract is to interact with the Tavily API to extract content from a list of provided URLs.\n\n**attributes**: The attributes of this Class.\n· base_url: The base URL for the Tavily API endpoint used for content extraction.\n· _api_key: The API key used for authentication with the Tavily API.\n· headers: The headers required for making requests to the Tavily API, including content type and authorization.\n\n**Code Description**: The TavilyExtract class is designed to facilitate the extraction of content from specified URLs using the Tavily API. Upon initialization, it requires an API key, which is stored as a private attribute (_api_key). The class constructs the necessary headers for API requests, ensuring that the content type is set to JSON and that the API key is included in the authorization header.\n\nThe primary method of the class, `extract_content`, takes a list of URLs as input. It constructs a JSON payload containing these URLs and makes an asynchronous POST request to the Tavily API using the httpx library. The method handles potential HTTP errors by raising exceptions for any 4xx or 5xx responses, and it captures request errors as well. If the request is successful, the method parses the JSON response and returns the data. In case of errors, it returns a dictionary containing the error message.\n\nThis class is utilized within the `scrape` function of the ContentScraper module. The `scrape` function first initializes an instance of TavilyExtract with the API key retrieved from the settings. It then calls the `extract_content` method, passing the list of URLs to be scraped. The results from the Tavily API are checked for errors; if any errors are present, the function logs the error and falls back to a custom web scraping method. If the extraction is successful, it processes the results, extracting the necessary data and merging successful and failed results into a final output.\n\n**Note**: Ensure that the API key is valid and has the necessary permissions to access the Tavily API. The URLs provided should be accessible and valid to avoid unnecessary errors during the extraction process.\n\n**Output Example**: A possible appearance of the code's return value could be:\n{\n  \"results\": [\n    {\n      \"url\": \"https://example.com\",\n      \"raw_content\": \"<html>...</html>\"\n    }\n  ],\n  \"failed_results\": [\n    {\n      \"url\": \"https://failed-url.com\"\n    }\n  ]\n}"
      ],
      "code_start_line": 6,
      "code_end_line": 32,
      "params": [],
      "have_return": true,
      "code_content": "class TavilyExtract:\n    def __init__(self, api_key: str):\n        self.base_url = \"https://api.tavily.com/extract\"\n        self._api_key = api_key\n        self.headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self._api_key}\",\n        }\n\n    async def extract_content(self, urls: List[str]):\n        payload = {\"urls\": urls}\n\n        async with httpx.AsyncClient(http2=True) as client:\n            try:\n                response = await client.post(\n                    self.base_url, headers=self.headers, json=payload\n                )\n                response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n\n                # Parse the response data and return the whole response object\n                data = response.json()\n                return data\n\n            except httpx.HTTPStatusError as e:\n                return {\"error\": f\"HTTP error occurred: {str(e)}\"}\n            except httpx.RequestError as e:\n                return {\"error\": f\"Request error occurred: {str(e)}\"}\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/content_scraper/__init__.py",
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the TavilyExtract object by setting up the base URL for API requests and configuring the necessary headers for authentication.\n\n**parameters**: The parameters of this function.\n· api_key: str - This is the API key required for authenticating requests to the Tavily API.\n\n**Code Description**: \nThe `__init__` function is the constructor method of the `TavilyExtract` class. It is responsible for setting up the essential attributes needed to interact with the Tavily API. Upon initialization:\n\n1. The `base_url` attribute is assigned a fixed value, `\"https://api.tavily.com/extract\"`. This URL is the endpoint used for making API requests.\n  \n2. The `_api_key` attribute is initialized with the provided `api_key` parameter, which is a string containing the user's personal API key. This key is used to authenticate requests made to the Tavily API.\n\n3. The `headers` attribute is a dictionary containing two key-value pairs:\n   - `\"Content-Type\": \"application/json\"`: This specifies that the data being sent in requests will be formatted as JSON.\n   - `\"Authorization\": f\"Bearer {self._api_key}\"`: This header is used for bearer token authentication, where the API key is included in the Authorization header to verify the identity of the requester.\n\nThis constructor ensures that an instance of the `TavilyExtract` class is correctly set up with the necessary API URL and authentication details for subsequent API interactions.\n\n**Note**: \n- The `api_key` parameter is mandatory for initializing the `TavilyExtract` class and must be kept secure to prevent unauthorized access.\n- The `base_url` and `headers` are automatically configured and cannot be modified directly through the constructor. Any changes to these values would require altering the code itself."
      ],
      "code_start_line": 7,
      "code_end_line": 13,
      "params": [
        "self",
        "api_key"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, api_key: str):\n        self.base_url = \"https://api.tavily.com/extract\"\n        self._api_key = api_key\n        self.headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self._api_key}\",\n        }\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "extract_content",
      "md_content": [
        "**extract_content**: The function of extract_content is to asynchronously request and retrieve content data from an external service based on a list of provided URLs.\n\n**parameters**:\n· urls: List[str]  \n  - A list of URLs for which content needs to be extracted.\n\n**Code Description**:  \nThe `extract_content` function is an asynchronous method that facilitates the extraction of content from a specified external service. The method is designed to take a list of URLs as input and then make an HTTP POST request to a remote API to retrieve the content associated with these URLs.\n\n1. **Payload Creation**:  \n   The function first constructs a payload dictionary containing the `urls` parameter passed to the function. This payload is intended to be sent as the body of the POST request.\n\n2. **Making the API Call**:  \n   Using the `httpx.AsyncClient` with HTTP/2 support enabled, the function sends an asynchronous POST request to the service’s base URL (stored in `self.base_url`). The headers (stored in `self.headers`) and the payload (containing the URLs) are included in the request. This is performed within an asynchronous context to ensure non-blocking behavior during the request.\n\n3. **Handling Responses**:  \n   Upon receiving the response, the function checks whether the request was successful by calling `response.raise_for_status()`. If the status code indicates an error (4xx/5xx), an exception is raised and caught.\n\n4. **Error Handling**:  \n   If an HTTP error occurs (e.g., 404 or 500), the function will return a dictionary with the key `error` and a message indicating that an HTTP error occurred. Similarly, if there’s an issue with the request itself (e.g., network issues), a `RequestError` is caught, and an error message is returned.\n\n5. **Returning Data**:  \n   If the request is successful, the function parses the response as JSON and returns the resulting data. This JSON data is typically structured to contain content related to the requested URLs.\n\nIn terms of its usage, the `extract_content` method is invoked within the `scrape` function found in the `src/criticsearch/tools/content_scraper/__init__.py` file. The `scrape` function calls `extract_content` to attempt content extraction using the Tavily API. If successful, it processes the returned results into a list of `ScrapedData` objects. If the extraction fails or encounters errors, it falls back to a custom web scraping mechanism via `FallbackWebScraper`. This integration ensures the robustness of the scraping process, allowing for alternative methods when the primary API fails.\n\n**Note**:  \n- The function is asynchronous and requires an `await` keyword when calling it.  \n- The `httpx` library should be installed and configured correctly to ensure successful HTTP requests.  \n- Proper error handling is implemented to catch both HTTP-specific and general request errors, returning meaningful error messages for each type of failure.\n\n**Output Example**:  \nA possible response when the request is successful could look like the following:\n\n```json\n{\n  \"results\": [\n    {\n      \"url\": \"http://example.com/page1\",\n      \"raw_content\": \"This is the content of the first page.\"\n    },\n    {\n      \"url\": \"http://example.com/page2\",\n      \"raw_content\": \"This is the content of the second page.\"\n    }\n  ],\n  \"failed_results\": []\n}\n```\n\nIf there is an error, the returned dictionary may look like this:\n\n```json\n{\n  \"error\": \"HTTP error occurred: 404 Client Error: Not Found for url: http://example.com/page1\"\n}\n```"
      ],
      "code_start_line": 15,
      "code_end_line": 32,
      "params": [
        "self",
        "urls"
      ],
      "have_return": true,
      "code_content": "    async def extract_content(self, urls: List[str]):\n        payload = {\"urls\": urls}\n\n        async with httpx.AsyncClient(http2=True) as client:\n            try:\n                response = await client.post(\n                    self.base_url, headers=self.headers, json=payload\n                )\n                response.raise_for_status()  # Raise an exception for 4xx/5xx responses\n\n                # Parse the response data and return the whole response object\n                data = response.json()\n                return data\n\n            except httpx.HTTPStatusError as e:\n                return {\"error\": f\"HTTP error occurred: {str(e)}\"}\n            except httpx.RequestError as e:\n                return {\"error\": f\"Request error occurred: {str(e)}\"}\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/content_scraper/__init__.py/ContentScraper/scrape"
      ],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/search_adapter/duckduckgo_client.py": [
    {
      "type": "ClassDef",
      "name": "DuckDuckGoClient",
      "md_content": [
        "**DuckDuckGoClient**: The function of DuckDuckGoClient is to implement a search client that interacts with the DuckDuckGo search engine, providing search results based on specified query parameters.\n\n**attributes**: \n- None.\n\n**Code Description**: \nThe `DuckDuckGoClient` class is a subclass of the `BaseSearchClient` class. It is specifically designed to perform search operations via DuckDuckGo's search engine. This class implements the asynchronous `search` method, which retrieves search results by sending a query to DuckDuckGo's API, processes the results, and returns a structured response.\n\nThe class contains the following key components:\n\n1. **_convert_days_to_timelimit**: This helper method converts a specified number of days into DuckDuckGo's internal time limit format. It accepts an integer `days` as input and returns a string corresponding to one of the following time periods:\n   - `\"d\"` for the last 24 hours\n   - `\"w\"` for the last week\n   - `\"m\"` for the last month\n   - `\"y\"` for the last year\n   The method is essential for formatting the time-related parameter when calling the DuckDuckGo search API.\n\n2. **search**: This asynchronous method is responsible for sending a search query to DuckDuckGo's API. It accepts the following parameters:\n   - `query`: A string representing the search query.\n   - `days`: An optional integer that filters results to a specific time frame. It defaults to 7 (last week).\n   - `max_results`: An optional integer specifying the maximum number of results to return. It defaults to 10.\n   - `region`: A string that defines the search region. It can be `\"us-en\"` for the United States or `\"cn-zh\"` for China, with a default value of `\"us-en\"`.\n   \n   The method utilizes the `_convert_days_to_timelimit` helper to determine the time frame for the search, constructs a request to DuckDuckGo, and processes the response into a list of `SearchResult` objects. Each `SearchResult` contains the title, URL, and content of a search result. Finally, the method returns a `SearchResponse` object that contains the query and the processed search results, limited to the specified `max_results`.\n\n3. **retry decorator**: The `search` method is wrapped with a retry decorator that handles retries in case of failures. The retry logic is configured to stop after 5 attempts (`stop_after_attempt(5)`) and apply an exponential backoff strategy with random jitter (`wait_exponential` and `wait_random`). The decorator specifically targets the `RatelimitException`, which is likely raised when the DuckDuckGo API is being rate-limited.\n\nIn terms of functionality, the `DuckDuckGoClient` integrates with the `AsyncDDGS` (asynchronous DuckDuckGo search) client, which is responsible for sending the query and receiving raw search results. These results are then transformed into a structured format suitable for further use in the system. \n\n**Note**: \n- The `search` method is asynchronous, so it must be awaited when called.\n- The method supports time-based filtering, allowing users to retrieve results from the last 24 hours, week, month, or year.\n- The retry logic ensures robustness in case of rate limiting or temporary failures in the API interaction.\n\n**Output Example**:\nA possible return value from the `search` method might look like this:\n\n```json\n{\n  \"query\": \"example search query\",\n  \"results\": [\n    {\n      \"title\": \"Example Result 1\",\n      \"url\": \"https://www.example1.com\",\n      \"content\": \"This is the content of the first search result.\"\n    },\n    {\n      \"title\": \"Example Result 2\",\n      \"url\": \"https://www.example2.com\",\n      \"content\": \"This is the content of the second search result.\"\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 18,
      "code_end_line": 74,
      "params": [],
      "have_return": true,
      "code_content": "class DuckDuckGoClient(BaseSearchClient):\n    def _convert_days_to_timelimit(self, days: int) -> str:\n        \"\"\"\n        Convert days to DuckDuckGo's timelimit format.\n\n        Args:\n            days (int): Number of days to filter results.\n\n        Returns:\n            str: A string representing DuckDuckGo's timelimit format ('d', 'w', 'm', 'y').\n        \"\"\"\n        if days <= 1:\n            return \"d\"  # Last 24 hours\n        elif days <= 7:\n            return \"w\"  # Last week\n        elif days <= 30:\n            return \"m\"  # Last month\n        else:\n            return \"y\"  # Last year\n\n    @retry(\n        stop=stop_after_attempt(5),  # 重试最多5次\n        wait=wait_exponential(multiplier=1, min=4, max=30)\n        + wait_random(min=1, max=5),  # 指数退避 + 随机抖动\n        retry=retry_if_exception_type(RatelimitException),\n    )\n    async def search(\n        self,\n        query: str,\n        days: int = 7,\n        max_results: int = 10,\n        region: Literal[\"us-en\", \"cn-zh\"] = \"us-en\",\n    ) -> SearchResponse:\n        timelimit = self._convert_days_to_timelimit(days)\n\n        logger.debug(f\"Using 'duckduckgo-search-client' for query '{query}'.\")\n\n        raw_results = await AsyncDDGS(timeout=10).atext(\n            query,\n            region=region,\n            safesearch=\"on\",\n            timelimit=timelimit,\n            max_results=max_results,\n        )\n\n        results = [\n            SearchResult(\n                title=result[\"title\"],\n                url=result[\"href\"],\n                content=result[\"body\"],\n            )\n            for result in raw_results\n        ]\n        return SearchResponse(\n            query=query,\n            results=results[:max_results],\n        )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/base_search_client.py/BaseSearchClient"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "_convert_days_to_timelimit",
      "md_content": [
        "**_convert_days_to_timelimit**: The function of _convert_days_to_timelimit is to convert a given number of days into a timelimit format used by DuckDuckGo's search client.\n\n**parameters**:\n· days: An integer representing the number of days to filter results.\n\n**Code Description**:  \nThe function _convert_days_to_timelimit takes an integer value for `days` and returns a corresponding string representing DuckDuckGo's timelimit format. This format is used to filter search results based on the specified timeframe.\n\nThe function works as follows:\n1. If the `days` value is less than or equal to 1, the function returns `\"d\"`, which stands for results from the last 24 hours.\n2. If the `days` value is greater than 1 but less than or equal to 7, the function returns `\"w\"`, representing results from the last week.\n3. If the `days` value is greater than 7 but less than or equal to 30, the function returns `\"m\"`, indicating results from the last month.\n4. If the `days` value exceeds 30, the function returns `\"y\"`, indicating results from the last year.\n\nThis function is crucial for the `search` method within the `DuckDuckGoClient` class. Specifically, it is called to determine the appropriate timelimit format when initiating a search request. The `search` method passes the `days` argument to _convert_days_to_timelimit, which then returns the timelimit string to be used in the search query. The timelimit helps filter search results based on recency, allowing the user to retrieve results relevant to a specific timeframe.\n\n**Note**: The `days` parameter should be an integer, and the function will return one of the following string values:\n- `\"d\"` for the last 24 hours,\n- `\"w\"` for the last week,\n- `\"m\"` for the last month,\n- `\"y\"` for the last year.\n\n**Output Example**:\nFor `days = 3`, the output would be `\"w\"`, representing results from the last week.  \nFor `days = 40`, the output would be `\"y\"`, representing results from the last year."
      ],
      "code_start_line": 19,
      "code_end_line": 36,
      "params": [
        "self",
        "days"
      ],
      "have_return": true,
      "code_content": "    def _convert_days_to_timelimit(self, days: int) -> str:\n        \"\"\"\n        Convert days to DuckDuckGo's timelimit format.\n\n        Args:\n            days (int): Number of days to filter results.\n\n        Returns:\n            str: A string representing DuckDuckGo's timelimit format ('d', 'w', 'm', 'y').\n        \"\"\"\n        if days <= 1:\n            return \"d\"  # Last 24 hours\n        elif days <= 7:\n            return \"w\"  # Last week\n        elif days <= 30:\n            return \"m\"  # Last month\n        else:\n            return \"y\"  # Last year\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py/DuckDuckGoClient/search"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "search",
      "md_content": [
        "**search**: The function of search is to perform an asynchronous search query using the DuckDuckGo search client and return the results in a structured format.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the search term to be queried.  \n· days: An integer representing the number of days to filter results, defaulting to 7.  \n· max_results: An integer indicating the maximum number of search results to return, defaulting to 10.  \n· region: A string literal that specifies the region for the search results, defaulting to \"us-en\".  \n\n**Code Description**: The `search` function is an asynchronous method designed to query the DuckDuckGo search engine. It accepts a search term (`query`) and several optional parameters that allow users to customize the search results based on recency and quantity.\n\n1. The method begins by converting the `days` parameter into a timelimit format using the `_convert_days_to_timelimit` method. This conversion is crucial as it determines how recent the search results should be, based on the specified number of days.\n\n2. A debug log statement is executed to indicate the initiation of a search query, providing visibility into the operation being performed.\n\n3. The function then calls the `atext` method of the `AsyncDDGS` class, which is part of the DuckDuckGo search client. This method is awaited, meaning that the function will pause execution until the search results are retrieved. The parameters passed to `atext` include the search `query`, the `region`, a safesearch setting, the `timelimit`, and the maximum number of results to return.\n\n4. Once the raw results are obtained, the function processes these results into a list of `SearchResult` objects. Each `SearchResult` is instantiated with the title, URL, and content extracted from the raw results.\n\n5. Finally, the function returns a `SearchResponse` object that encapsulates the original query and the list of search results, limited to the specified `max_results`.\n\nThe `search` function is integral to the `DuckDuckGoClient` class, facilitating user queries and structuring the response in a way that is easy to consume by other components of the application. It relies on the `_convert_days_to_timelimit` method to filter results based on recency and utilizes the `SearchResult` and `SearchResponse` classes to format the output.\n\n**Note**: \n- The `query` parameter is mandatory and should be a valid search term. \n- The `days`, `max_results`, and `region` parameters are optional and have default values, allowing for flexible usage.\n- The function is asynchronous, which means it should be awaited when called to ensure proper execution flow.\n\n**Output Example**: \nA possible return value of the `search` function could look like this:\n```json\n{\n  \"query\": \"Python programming\",\n  \"results\": [\n    {\n      \"title\": \"Learn Python - Full Course for Beginners\",\n      \"url\": \"https://www.example.com/learn-python\",\n      \"content\": \"This comprehensive course covers Python basics and advanced topics.\"\n    },\n    {\n      \"title\": \"Python Programming Language\",\n      \"url\": \"https://www.example.com/python\",\n      \"content\": \"Python is a popular programming language known for its simplicity.\"\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 44,
      "code_end_line": 74,
      "params": [
        "self",
        "query",
        "days",
        "max_results",
        "region"
      ],
      "have_return": true,
      "code_content": "    async def search(\n        self,\n        query: str,\n        days: int = 7,\n        max_results: int = 10,\n        region: Literal[\"us-en\", \"cn-zh\"] = \"us-en\",\n    ) -> SearchResponse:\n        timelimit = self._convert_days_to_timelimit(days)\n\n        logger.debug(f\"Using 'duckduckgo-search-client' for query '{query}'.\")\n\n        raw_results = await AsyncDDGS(timeout=10).atext(\n            query,\n            region=region,\n            safesearch=\"on\",\n            timelimit=timelimit,\n            max_results=max_results,\n        )\n\n        results = [\n            SearchResult(\n                title=result[\"title\"],\n                url=result[\"href\"],\n                content=result[\"body\"],\n            )\n            for result in raw_results\n        ]\n        return SearchResponse(\n            query=query,\n            results=results[:max_results],\n        )\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py/DuckDuckGoClient/_convert_days_to_timelimit",
        "src/criticsearch/tools/search_adapter/models.py/SearchResult",
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/search_adapter/__init__.py": [],
  "src/criticsearch/tools/search_adapter/models.py": [
    {
      "type": "ClassDef",
      "name": "SearchResult",
      "md_content": [
        "**SearchResult**: The function of SearchResult is to represent an individual search result, encapsulating details such as the title, URL, and content.\n\n**attributes**: The attributes of this Class.\n· title: A string representing the title of the search result.  \n· url: A string representing the URL of the search result.  \n· content: A string containing a brief description or snippet of the content of the search result.  \n\n**Code Description**:  \nThe `SearchResult` class is a data model that stores information about a single search result retrieved from a search engine API. It inherits from `BaseModel`, suggesting that it is likely used with Pydantic or a similar library for data validation and serialization. \n\n- `title`: This attribute holds the title of the search result. It is represented as a string and typically corresponds to the main heading or name of the webpage or resource returned in the search results.\n  \n- `url`: This attribute contains the URL string that directs to the search result. It is essential for linking directly to the content described in the `title`.\n\n- `content`: This is a string attribute that contains a brief snippet or preview of the content found at the given URL. This snippet is often a portion of text extracted from the webpage to give users a preview of what the page is about.\n\nThe `SearchResult` class is frequently used in the context of search operations, where it is populated with relevant data for each individual search result. This can be seen in the `search` methods of both `BingClient` and `DuckDuckGoClient`. In these classes, after performing a search query, a list of `SearchResult` instances is created, each representing an individual result in the response from the respective search engine API.\n\nIn the `BingClient.search` method, for example, the response from the Bing API is parsed, and each item in the list of results is used to instantiate a `SearchResult` object with the corresponding title, URL, and content snippet. The resulting list of `SearchResult` instances is then included in a `SearchResponse` object, which encapsulates the entire search result for further use.\n\nSimilarly, in the `DuckDuckGoClient.search` method, the search results are processed, and a list of `SearchResult` objects is created, each holding the title, URL, and content for the results returned by DuckDuckGo.\n\n**Note**:  \n- The attributes `title`, `url`, and `content` are expected to be provided when creating an instance of `SearchResult`. Missing or malformed values may lead to errors, especially in systems that rely on proper data validation.\n- The `SearchResult` class is often used as part of a larger response object, such as `SearchResponse`, which groups together multiple `SearchResult` instances along with metadata like the search query and potential error messages.\n- It is important that each `SearchResult` contains relevant and accurate data, as it directly reflects the results returned by external search APIs, which may vary in structure."
      ],
      "code_start_line": 11,
      "code_end_line": 14,
      "params": [],
      "have_return": false,
      "code_content": "class SearchResult(BaseModel):\n    title: str\n    url: str\n    content: str\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/bing_client.py",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient/search",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py/DuckDuckGoClient/search",
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "SearchResponse",
      "md_content": [
        "## Class: `SearchResponse`\n\n### Overview\nThe `SearchResponse` class is a data model used to represent the results of a search query. It encapsulates the query itself, the list of search results, and any potential error messages that may have occurred during the search process. This class is commonly used to structure the response from a search API client, such as a Bing or DuckDuckGo search client.\n\n### Attributes\n- **query** (`str`): The search query string that was submitted by the user.\n- **results** (`List[SearchResult]`): A list of `SearchResult` objects representing the individual search results. If no results are found, this list will be empty.\n- **error_message** (`Optional[str]`): An optional string that contains an error message, if applicable. If an error occurred during the search, this attribute will contain a descriptive error message.\n\n### Method\n\n#### `ser_model() -> str`\nThe `ser_model` method is used to serialize the `SearchResponse` object into a human-readable string. It formats the response based on the availability of results and error messages.\n\n- **Returns**: A formatted string representing the search response, including the query, any error message, and the details of the search results.\n  \n  **Behavior**:\n  - If an `error_message` is provided, the method will include it in the formatted response.\n  - If no results are found (i.e., `results` is an empty list), the method will indicate that no results were found.\n  - If results are available, the method will format the response with the titles, URLs, and content of the search results.\n\n### Usage Example\n```python\nsearch_response = SearchResponse(query=\"Python programming\", results=[...], error_message=None)\nprint(search_response.ser_model())\n```\n\n### Notes\n- The `SearchResult` class is used to structure each individual search result, containing attributes like `title`, `url`, and `content`. These details are displayed when the `ser_model` method is called, allowing for easy inspection of the search results.\n- The `error_message` is optional, and if there are no errors, the response will display the search results or indicate that no results were found.\n\nThis class is useful in the context of search client responses, enabling structured representation and easy presentation of the query and search outcomes."
      ],
      "code_start_line": 17,
      "code_end_line": 39,
      "params": [],
      "have_return": true,
      "code_content": "class SearchResponse(BaseModel):\n    query: str\n    results: List[SearchResult] = Field(default_factory=list)\n    error_message: Optional[str] = None\n\n    @model_serializer\n    def ser_model(self) -> str:\n        if self.error_message:\n            formatted_response = (\n                f\"\\nQuery: {self.query}\\nError: {self.error_message}\\n\" + \"-\" * 50\n            )\n        elif self.results == []:\n            formatted_response = (\n                f\"\\nQuery: {self.query}\\nError: No results found.\" + \"-\" * 50\n            )\n        else:\n            formatted_response = f\"\\nQuery: {self.query}\\nSearch Results:\\n\" + \"-\" * 50\n            for i, res in enumerate(self.results, 1):\n                formatted_response += (\n                    f\"\\n[{i}]:\\nTITLE: {res.title}\\nURL: {res.url}\\nCONTENT: {res.content}\\n\"\n                    + \"-\" * 50\n                )\n        return formatted_response\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/bing_client.py",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient/search",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py/DuckDuckGoClient/search",
        "src/criticsearch/tools/search_adapter/models.py/SearchResponseList",
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query",
        "src/criticsearch/tools/search_adapter/tavily_client.py",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResult"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "ser_model",
      "md_content": [
        "**ser_model**: The function of ser_model is to generate a formatted string representation of the search response based on the query, error messages, and results.\n\n**parameters**: The parameters of this Function.\n· self: An instance of the class that contains the attributes query, error_message, and results.\n\n**Code Description**: The ser_model function constructs a formatted response string that summarizes the outcome of a search operation. It first checks if there is an error message present in the instance. If an error message exists, it formats the response to include the query and the error message, followed by a line of dashes for separation. If there are no results (i.e., the results list is empty), it similarly formats the response to indicate that no results were found. In the case where there are valid search results, the function constructs a response that includes the query and iterates through the results list. For each result, it appends the index, title, URL, and content of the result to the formatted response, again followed by a line of dashes for clarity. Finally, the function returns the complete formatted response string.\n\n**Note**: It is important to ensure that the attributes query, error_message, and results are properly initialized in the class before calling this function. The results should be a list of objects that contain title, url, and content attributes for the function to work correctly.\n\n**Output Example**: \n```\nQuery: \"How to use Python for data analysis?\"\nError: No results found.--------------------------------------------------\n```\nor \n```\nQuery: \"How to use Python for data analysis?\"\nSearch Results:\n--------------------------------------------------\n[1]:\nTITLE: \"Data Analysis with Python\"\nURL: \"https://example.com/data-analysis-python\"\nCONTENT: \"This article provides an overview of data analysis techniques using Python.\"\n--------------------------------------------------\n[2]:\nTITLE: \"Python for Data Science\"\nURL: \"https://example.com/python-data-science\"\nCONTENT: \"Learn how Python is used in data science and analytics.\"\n--------------------------------------------------\n```"
      ],
      "code_start_line": 23,
      "code_end_line": 39,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def ser_model(self) -> str:\n        if self.error_message:\n            formatted_response = (\n                f\"\\nQuery: {self.query}\\nError: {self.error_message}\\n\" + \"-\" * 50\n            )\n        elif self.results == []:\n            formatted_response = (\n                f\"\\nQuery: {self.query}\\nError: No results found.\" + \"-\" * 50\n            )\n        else:\n            formatted_response = f\"\\nQuery: {self.query}\\nSearch Results:\\n\" + \"-\" * 50\n            for i, res in enumerate(self.results, 1):\n                formatted_response += (\n                    f\"\\n[{i}]:\\nTITLE: {res.title}\\nURL: {res.url}\\nCONTENT: {res.content}\\n\"\n                    + \"-\" * 50\n                )\n        return formatted_response\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "SearchResponseList",
      "md_content": [
        "**SearchResponseList**: The function of SearchResponseList is to represent a list of search response objects and provide functionality to serialize them, ensuring that duplicate content across queries is removed.\n\n**attributes**: The attributes of this Class.\n· responses: A list of `SearchResponse` objects that represent the responses from multiple search queries.\n\n**Code Description**: \nThe `SearchResponseList` class is used to hold a collection of `SearchResponse` objects, each representing an individual search query's response. It provides a method, `ser_model()`, which serializes these responses into a formatted string while ensuring the removal of duplicate content across the search results.\n\n- The class inherits from `BaseModel`, indicating that it is part of a data model system, likely designed for serialization or structured data handling.\n- The primary attribute, `responses`, is a list that holds instances of `SearchResponse`. This attribute holds the individual responses from search queries and is initialized as an empty list by default.\n  \nThe key functionality of this class is in the `ser_model()` method. This method iterates over the `SearchResponse` objects in the `responses` list and performs several actions:\n1. It maintains a set of `global_seen_contents` to ensure that duplicate search results are removed across queries.\n2. For each `SearchResponse`, if there is an error message (i.e., `error_message` is not `None`), the method will log the error and skip processing that response.\n3. For each result in a valid `SearchResponse`, it checks if the content of the result has been seen before across all responses. If the content is unique, it is added to a list of unique results, and this result is serialized.\n4. After processing, the method updates the `SearchResponse` object to reflect only unique results and keeps track of the total number of results and the unique results count. It then generates a string representation of the serialized results.\n5. The method logs the number of duplicates removed and returns the final serialized string.\n\nThe `SearchResponseList` class is primarily used in the context of aggregating and serializing multiple search responses in a way that filters out redundant results. It plays a crucial role in handling multiple search queries, especially when working with multiple search engines or sources. \n\nFrom a functional perspective, this class is invoked in the `search` method of the `SearchAggregator` class. The `search` method performs concurrent searches for a list of queries, collects the responses, and returns them as an instance of `SearchResponseList`. This allows for streamlined processing and serialization of the search results, ensuring that the final output only includes unique search results from the queries.\n\n**Note**: \n- The `ser_model()` method only includes `SearchResponse` objects that do not contain error messages in its serialization.\n- It ensures that any duplicate content across multiple responses is filtered out based on the content of the search results, which helps in returning cleaner and more relevant data.\n- This class uses logging to provide feedback on the serialization process, including information on skipped responses due to errors and the number of duplicates removed.\n\n**Output Example**:\nAn example output of the `ser_model()` method might look like this:\n\n```\nQuery: \"Python programming\"\nSearch Results:\n--------------------------------------------------\n[1]:\nTITLE: Introduction to Python\nURL: https://example.com/python\nCONTENT: Python is a high-level programming language.\n--------------------------------------------------\n[2]:\nTITLE: Python Tutorials\nURL: https://example.com/tutorials\nCONTENT: Learn Python programming with these tutorials.\n--------------------------------------------------\nSerialization completed. Total results: 5, Unique results: 3, Duplicates removed: 2.\n``` \n\nThis output shows the results of the search query, including the serialized format of unique results, and a summary of the serialization process."
      ],
      "code_start_line": 42,
      "code_end_line": 87,
      "params": [],
      "have_return": true,
      "code_content": "class SearchResponseList(BaseModel):\n    responses: List[SearchResponse] = Field(default_factory=list)\n\n    @model_serializer\n    def ser_model(self) -> str:\n        \"\"\"\n        Serialize the list of SearchResponse objects into a dictionary,\n        ensuring unique content across queries.\n\n        Returns:\n            Dict[str, str]: A dictionary where the key is the query,\n                            and the value is a formatted string representation of the search response.\n        \"\"\"\n        global_seen_contents = set()  # 全局去重逻辑\n        total_results = 0\n        unique_results_count = 0\n        result_str = \"\"\n\n        for response in self.responses:\n            if response.error_message:\n                logger.debug(\n                    f\"Skipping serialize query '{response.query}' due to error: {response.error_message}\"\n                )\n                continue  # 跳过有 error_message 的响应\n\n            unique_results = []\n            for res in response.results:\n                total_results += 1\n                if res.content not in global_seen_contents:\n                    global_seen_contents.add(res.content)\n                    unique_results.append(res)\n\n            # 将去重后的结果更新到当前 response\n            response.results = unique_results\n            unique_results_count += len(unique_results)\n            result_str += response.model_dump()  # type: ignore\n\n        # 打印提示信息\n        duplicates_removed = total_results - unique_results_count\n        logger.success(\n            f\"Serialization completed. Total results: {total_results}, \"\n            f\"Unique results: {unique_results_count}, \"\n            f\"Duplicates removed: {duplicates_removed}.\"\n        )\n\n        return result_str\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "ser_model",
      "md_content": [
        "**ser_model**: The function of ser_model is to serialize a list of SearchResponse objects into a string, ensuring uniqueness in the content across different queries.\n\n**parameters**: This function does not take any parameters.\n\n**Code Description**:  \nThe `ser_model` method is responsible for serializing the list of `SearchResponse` objects contained within the instance. It processes each `SearchResponse` object to ensure that the search results are unique by comparing their content against a global set of previously seen content.\n\n1. **Global Uniqueness Tracking**:  \n   A set named `global_seen_contents` is used to store the content of the results encountered so far, ensuring that each result is unique across all queries processed by this method.\n\n2. **Response Processing**:  \n   The method loops over each `SearchResponse` object in `self.responses`. For each `response`, if it contains an error message, it is skipped, and the serialization continues with the next response.\n\n3. **Result Deduplication**:  \n   For each `response`, the method iterates through its `results` and checks whether the `content` of each result has already been encountered (using the `global_seen_contents` set). If a result’s content is unique (i.e., not found in the set), it is added to the list `unique_results` and the content is added to the set to prevent future duplicates. The total number of results and unique results are tracked during this process.\n\n4. **Updating the Response**:  \n   After deduplication, the `results` attribute of the `response` is updated with the `unique_results`. The count of unique results is accumulated in `unique_results_count`.\n\n5. **Serialization**:  \n   The `model_dump()` method is called on each `response` to generate its serialized string representation, which is appended to `result_str`. This `result_str` will contain the serialized data of all responses, with duplicates removed.\n\n6. **Logging**:  \n   After processing all responses, the method logs a summary message, indicating the total number of results processed, the number of unique results, and the number of duplicates removed.\n\n7. **Return Value**:  \n   Finally, the method returns the `result_str`, which contains the serialized data of the unique results.\n\n**Note**: \n- The method ensures that only unique search results are included in the serialized output, removing any duplicates based on content.\n- The method relies on the `model_dump()` method of the `SearchResponse` object to generate its string representation, which may vary depending on the implementation of that method.\n- If any `SearchResponse` contains an error message, it will be skipped entirely, and no results from that response will be included in the final serialized output.\n\n**Output Example**:  \nAssuming `self.responses` contains two `SearchResponse` objects with some duplicate results, the returned `result_str` might look like this:\n\n```\n\"SearchResponse(query='query1', results=[{'content': 'unique content 1'}, {'content': 'unique content 2'}])SearchResponse(query='query2', results=[{'content': 'unique content 3'}, {'content': 'unique content 1'}])\"\n```\n\nIn this example, 'unique content 1' is only included once, even though it appeared in multiple responses."
      ],
      "code_start_line": 46,
      "code_end_line": 87,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def ser_model(self) -> str:\n        \"\"\"\n        Serialize the list of SearchResponse objects into a dictionary,\n        ensuring unique content across queries.\n\n        Returns:\n            Dict[str, str]: A dictionary where the key is the query,\n                            and the value is a formatted string representation of the search response.\n        \"\"\"\n        global_seen_contents = set()  # 全局去重逻辑\n        total_results = 0\n        unique_results_count = 0\n        result_str = \"\"\n\n        for response in self.responses:\n            if response.error_message:\n                logger.debug(\n                    f\"Skipping serialize query '{response.query}' due to error: {response.error_message}\"\n                )\n                continue  # 跳过有 error_message 的响应\n\n            unique_results = []\n            for res in response.results:\n                total_results += 1\n                if res.content not in global_seen_contents:\n                    global_seen_contents.add(res.content)\n                    unique_results.append(res)\n\n            # 将去重后的结果更新到当前 response\n            response.results = unique_results\n            unique_results_count += len(unique_results)\n            result_str += response.model_dump()  # type: ignore\n\n        # 打印提示信息\n        duplicates_removed = total_results - unique_results_count\n        logger.success(\n            f\"Serialization completed. Total results: {total_results}, \"\n            f\"Unique results: {unique_results_count}, \"\n            f\"Duplicates removed: {duplicates_removed}.\"\n        )\n\n        return result_str\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/search_adapter/bing_client.py": [
    {
      "type": "ClassDef",
      "name": "BingClient",
      "md_content": [
        "**BingClient**: The function of BingClient is to serve as a client for the Bing Search API, facilitating search queries and handling responses.\n\n**attributes**: The attributes of this Class.\n· base_url: str - This attribute stores the base URL for the Bing Search API endpoint.\n· _api_key: str - This attribute holds the API key required for authenticating requests to the Bing Search API.\n· _client_name: str - This attribute defines the name of the client, which is \"BingClient\".\n\n**Code Description**: The `BingClient` class is an implementation of the `BaseSearchClient`, specifically designed to interact with the Bing Search API. It initializes with an API key, which is essential for authenticating requests to the Bing service. The class defines a method `search`, which is an asynchronous function that takes a search query as input and returns a structured response containing search results.\n\nUpon instantiation, the `BingClient` sets the `base_url` to the Bing Search API endpoint and stores the provided API key. The `search` method is decorated with a retry mechanism that allows it to attempt the request up to five times in case of a `RatelimitException`, which indicates that the rate limit for API requests has been exceeded. The retry logic employs exponential backoff combined with random jitter to manage the timing of retries effectively.\n\nIn the `search` method, an HTTP GET request is made to the Bing API using the `httpx.AsyncClient`. The request includes headers for authentication and parameters that specify the search query and additional options such as the number of results to return, safe search settings, and response filters. The method processes the API response, extracting relevant information from the JSON payload, and constructs a list of `SearchResult` objects that encapsulate the title, URL, and snippet of each search result.\n\nThe `BingClient` is utilized within the `SearchAggregator` class, which manages multiple search clients. When the `SearchAggregator` is initialized, it checks for the presence of the Bing API key in the settings. If the key is available, it creates an instance of `BingClient` and adds it to its collection of clients. This design allows the `SearchAggregator` to leverage the Bing search functionality alongside other search clients, providing a unified interface for executing search queries across different services.\n\n**Note**: It is crucial to handle exceptions such as `RatelimitException` and `InvalidAPIKeyError` when using the `BingClient` to ensure robust error management and user experience. The `search` method should be called asynchronously to comply with its design.\n\nA possible appearance of the code's return value from the `search` method could look like this:\n```json\n{\n    \"query\": \"fishing\",\n    \"results\": [\n        {\n            \"title\": \"Fishing Tips and Techniques\",\n            \"url\": \"https://www.example.com/fishing-tips\",\n            \"content\": \"Learn the best fishing tips and techniques for a successful day on the water.\"\n        },\n        {\n            \"title\": \"Top Fishing Spots\",\n            \"url\": \"https://www.example.com/top-fishing-spots\",\n            \"content\": \"Discover the top fishing spots in your area for a great fishing experience.\"\n        }\n    ]\n}\n```"
      ],
      "code_start_line": 17,
      "code_end_line": 93,
      "params": [],
      "have_return": true,
      "code_content": "class BingClient(BaseSearchClient):\n    \"\"\"\n    Bing Search API client.\n    \"\"\"\n\n    def __init__(self, api_key: str):\n        self.base_url = \"https://api.bing.microsoft.com/v7.0/search\"\n        self._api_key = api_key\n\n        self._client_name = \"BingClient\"\n\n    @retry(\n        stop=stop_after_attempt(5),  # 重试最多5次\n        wait=wait_exponential(multiplier=1, min=4, max=30)\n        + wait_random(min=1, max=5),  # 指数退避 + 随机抖动\n        retry=retry_if_exception_type(RatelimitException),\n    )\n    async def search(\n        self,\n        query: str,\n    ) -> SearchResponse:\n        headers = {\"Ocp-Apim-Subscription-Key\": self._api_key}\n\n        params = {\n            \"q\": query,  # 用户的搜索查询词。不能为空。\n            # 查询词可以包含 Bing 高级操作符，例如使用 site: 操作符限定结果来源于特定域名。\n            # 示例：q=\"fishing+site:fishing.contoso.com\"。\n            # 注意：即使使用了 site: 操作符，结果可能仍会包含其他站点的内容，具体取决于相关结果的数量。\n            \"count\": 2,  # 返回的搜索结果数量。默认值为 10，最大值为 50。\n            # 可以与 offset 参数结合使用来分页结果。\n            # 示例：如果每页显示 10 个搜索结果，第一页设置 count=10 和 offset=0，\n            # 第二页设置 offset=10，以此类推。分页时可能存在部分结果重叠。\n            \"safeSearch\": \"strict\",  # 过滤成人内容的设置。\n            # 可选值：\n            # - \"Off\": 返回包含成人文本和图片但不包括成人视频的内容。\n            # - \"Moderate\": 返回包含成人文本但不包括成人图片或视频的内容。\n            # - \"Strict\": 不返回任何成人文本、图片或视频内容。\n            \"responseFilter\": \"Webpages\",  # 用逗号分隔的答案类型，指定要在响应中包含的内容。\n            # 如果未指定此参数，则响应包含所有相关的数据类型。\n            # 可选值包括：\n            # - Computation, Entities, Images, News, Places, RelatedSearches,\n            #   SpellSuggestions, TimeZone, Translations, Videos, Webpages。\n            # 示例：使用 &responseFilter=-images 排除图片结果。\n            # 注意：若想获得单一答案类型，应优先使用特定的 API 端点。\n        }\n\n        async with httpx.AsyncClient(timeout=10) as client:\n            response = await client.get(self.base_url, headers=headers, params=params)\n\n        if response.status_code == 200:\n            json_response = response.json()\n\n            # 解析 Bing 的响应\n            web_pages = json_response.get(\"webPages\", {})\n            items = web_pages.get(\"value\", [])\n\n            results = []\n            for item in items:\n                results.append(\n                    SearchResult(\n                        title=item.get(\"name\", \"\"),\n                        url=item.get(\"url\", \"\"),\n                        content=item.get(\"snippet\", \"\"),\n                    )\n                )\n\n            return SearchResponse(query=query, results=results)\n        # 处理 HTTP 状态码\n        if response.status_code == 429:\n            raise RatelimitException()\n        elif response.status_code == 401:\n            raise InvalidAPIKeyError()\n        else:\n            return SearchResponse(\n                query=query,\n                error_message=f\"Unexpected status code: {response.status_code}. Response: {response.text}\",\n            )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/__init__"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/base_search_client.py/BaseSearchClient",
        "src/criticsearch/tools/search_adapter/exceptions.py/RatelimitException"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the BingClient object with necessary configuration values.\n\n**parameters**: The parameters of this Function.\n· api_key: A string representing the API key required to authenticate the client with Bing's search API.\n\n**Code Description**:  \nThe `__init__` method is a constructor function for the `BingClient` class. It is called when an instance of the class is created. This method performs the following actions:\n\n1. It assigns a fixed string URL (`\"https://api.bing.microsoft.com/v7.0/search\"`) to the `base_url` attribute, which is the endpoint for Bing's search API. This URL will be used in API requests to interact with Bing's search service.\n  \n2. It stores the provided `api_key` parameter in a private attribute `_api_key`. This API key is essential for authenticating requests to Bing's API. The key is passed to the class upon instantiation, and it is stored for later use in making authorized API calls.\n\n3. It initializes the `self._client_name` attribute with the string value `\"BingClient\"`. This can be used to identify the client or for logging purposes to track requests made by this client.\n\nThe constructor ensures that an instance of `BingClient` is ready for making authenticated API requests to the Bing search service.\n\n**Note**: \n- The `api_key` parameter must be correctly provided when creating an instance of the `BingClient`, as it is required for API authentication.\n- The `base_url` is fixed and does not change during the lifetime of the object, which makes it reusable for all API requests initiated from the same instance."
      ],
      "code_start_line": 22,
      "code_end_line": 26,
      "params": [
        "self",
        "api_key"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, api_key: str):\n        self.base_url = \"https://api.bing.microsoft.com/v7.0/search\"\n        self._api_key = api_key\n\n        self._client_name = \"BingClient\"\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "search",
      "md_content": [
        "**search**: The function of search is to perform an asynchronous search query using the Bing search API and return the results encapsulated in a SearchResponse object.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the user's search query. This parameter cannot be empty.\n\n**Code Description**: The `search` function is an asynchronous method that interacts with the Bing search API to retrieve search results based on a specified query. It begins by setting the necessary headers, including the API key required for authentication. The function constructs a parameters dictionary that includes the search query, the number of results to return, safe search settings, and response filters.\n\nThe function utilizes the `httpx.AsyncClient` to send an asynchronous GET request to the Bing API endpoint. The response is awaited, and upon receiving a successful status code (200), the function processes the JSON response. It extracts the relevant search results from the response, specifically focusing on the \"webPages\" section. Each result is then instantiated as a `SearchResult` object, which includes the title, URL, and content snippet of the search result.\n\nIf the response indicates a rate limit error (status code 429), the function raises a `RatelimitException`. If the API key is invalid (status code 401), it raises an `InvalidAPIKeyError`. For any other unexpected status codes, the function returns a `SearchResponse` object that includes the query and an error message detailing the unexpected status.\n\nThis function is called by the `_search_single_query` method in the `SearchAggregator` class. The `_search_single_query` method iterates through a list of available search engines and attempts to execute the `search` function for each engine. If the search is successful, it logs the result and returns it. In case of exceptions such as `RetryError`, `InvalidAPIKeyError`, or `UsageLimitExceededError`, the method handles these by marking the engine as unavailable and logging the appropriate error messages.\n\n**Note**: It is essential to ensure that the query parameter is not empty when calling this function, as it will lead to an error. Additionally, proper handling of the exceptions raised by this function is crucial for maintaining the robustness of the application, especially in scenarios where API limits or invalid keys may affect search operations.\n\n**Output Example**: A possible return value of the `search` function could be a `SearchResponse` object structured as follows:\n```python\nSearchResponse(\n    query=\"fishing\",\n    results=[\n        SearchResult(title=\"Fishing Tips\", url=\"https://example.com/fishing-tips\", content=\"Learn the best tips for fishing.\"),\n        SearchResult(title=\"Fishing Gear\", url=\"https://example.com/fishing-gear\", content=\"Find the best gear for your fishing adventures.\")\n    ],\n    error_message=None\n)\n```"
      ],
      "code_start_line": 34,
      "code_end_line": 93,
      "params": [
        "self",
        "query"
      ],
      "have_return": true,
      "code_content": "    async def search(\n        self,\n        query: str,\n    ) -> SearchResponse:\n        headers = {\"Ocp-Apim-Subscription-Key\": self._api_key}\n\n        params = {\n            \"q\": query,  # 用户的搜索查询词。不能为空。\n            # 查询词可以包含 Bing 高级操作符，例如使用 site: 操作符限定结果来源于特定域名。\n            # 示例：q=\"fishing+site:fishing.contoso.com\"。\n            # 注意：即使使用了 site: 操作符，结果可能仍会包含其他站点的内容，具体取决于相关结果的数量。\n            \"count\": 2,  # 返回的搜索结果数量。默认值为 10，最大值为 50。\n            # 可以与 offset 参数结合使用来分页结果。\n            # 示例：如果每页显示 10 个搜索结果，第一页设置 count=10 和 offset=0，\n            # 第二页设置 offset=10，以此类推。分页时可能存在部分结果重叠。\n            \"safeSearch\": \"strict\",  # 过滤成人内容的设置。\n            # 可选值：\n            # - \"Off\": 返回包含成人文本和图片但不包括成人视频的内容。\n            # - \"Moderate\": 返回包含成人文本但不包括成人图片或视频的内容。\n            # - \"Strict\": 不返回任何成人文本、图片或视频内容。\n            \"responseFilter\": \"Webpages\",  # 用逗号分隔的答案类型，指定要在响应中包含的内容。\n            # 如果未指定此参数，则响应包含所有相关的数据类型。\n            # 可选值包括：\n            # - Computation, Entities, Images, News, Places, RelatedSearches,\n            #   SpellSuggestions, TimeZone, Translations, Videos, Webpages。\n            # 示例：使用 &responseFilter=-images 排除图片结果。\n            # 注意：若想获得单一答案类型，应优先使用特定的 API 端点。\n        }\n\n        async with httpx.AsyncClient(timeout=10) as client:\n            response = await client.get(self.base_url, headers=headers, params=params)\n\n        if response.status_code == 200:\n            json_response = response.json()\n\n            # 解析 Bing 的响应\n            web_pages = json_response.get(\"webPages\", {})\n            items = web_pages.get(\"value\", [])\n\n            results = []\n            for item in items:\n                results.append(\n                    SearchResult(\n                        title=item.get(\"name\", \"\"),\n                        url=item.get(\"url\", \"\"),\n                        content=item.get(\"snippet\", \"\"),\n                    )\n                )\n\n            return SearchResponse(query=query, results=results)\n        # 处理 HTTP 状态码\n        if response.status_code == 429:\n            raise RatelimitException()\n        elif response.status_code == 401:\n            raise InvalidAPIKeyError()\n        else:\n            return SearchResponse(\n                query=query,\n                error_message=f\"Unexpected status code: {response.status_code}. Response: {response.text}\",\n            )\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResult",
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse",
        "src/criticsearch/tools/search_adapter/exceptions.py/InvalidAPIKeyError",
        "src/criticsearch/tools/search_adapter/exceptions.py/RatelimitException"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/search_adapter/__main__.py": [
    {
      "type": "FunctionDef",
      "name": "main",
      "md_content": [
        "## Function Documentation: `main`\n\n### Overview:\nThe `main` function serves as the entry point for executing a search query using the `SearchAggregator` class. It is an asynchronous function that initializes the search aggregator, performs a search, and prints the results.\n\n### Function Signature:\n```python\nasync def main()\n```\n\n### Description:\nThe `main` function is responsible for initiating the search process by utilizing the `SearchAggregator` class to handle search queries. It performs the following steps:\n\n1. **Initialization**: The function first creates an instance of the `SearchAggregator` class, which is used to manage and execute searches across multiple available search engines.\n\n2. **Search Execution**: It calls the `search` method of the `SearchAggregator` instance, passing a list of queries. In this case, the query is a single string: `\"Who is Leo Messi?\"`.\n\n3. **Results Handling**: After executing the search, the function awaits the response from the `search` method. The results are then printed to the console.\n\n### Purpose:\nThe function provides an example of how to interact with the `SearchAggregator` class to perform searches. It demonstrates the process of query submission and result handling within an asynchronous context.\n\n### Parameters:\nThis function does not accept any parameters.\n\n### Execution Flow:\n1. An instance of the `SearchAggregator` is created.\n2. The `search` method of the `SearchAggregator` is called with a predefined query.\n3. The search results are printed to the console.\n\n### Example Output:\n```json\n{\n  \"responses\": [\n    {\n      \"query\": \"Who is Leo Messi?\",\n      \"results\": [\n        {\n          \"title\": \"Lionel Messi - Wikipedia\",\n          \"url\": \"https://en.wikipedia.org/wiki/Lionel_Messi\",\n          \"snippet\": \"Lionel Andrés Messi is an Argentine professional footballer widely regarded as one of the greatest players of all time.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### Notes:\n- The function demonstrates basic usage of the `SearchAggregator` class, performing an asynchronous search and printing the response.\n- The search query used in this example is predefined, but in a real-world scenario, queries could be dynamic, and multiple queries could be passed to the `search` method concurrently.\n"
      ],
      "code_start_line": 6,
      "code_end_line": 12,
      "params": [],
      "have_return": false,
      "code_content": "    async def main():\n        search_aggregator = SearchAggregator()\n\n        # 调用异步搜索方法\n        response = await search_aggregator.search(query=[\"Who is Leo Messi?\"])\n\n        print(response)\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/search"
      ],
      "special_reference_type": [
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/search_adapter/base_search_client.py": [
    {
      "type": "ClassDef",
      "name": "BaseSearchClient",
      "md_content": [
        "**BaseSearchClient**: The function of BaseSearchClient is to define the structure and interface for search clients. \n\n**attributes**: \n- There are no attributes in this class.\n\n**Code Description**: \nThe `BaseSearchClient` class is an abstract base class, designed to be inherited by other search client classes that implement specific search API integrations. It contains a single abstract method, `search`, which must be implemented by any subclass. The method signature specifies that `search` should be an asynchronous method that accepts a `query` string and potentially other keyword arguments (`kwargs`) to allow flexibility. The return type for `search` is expected to be any type, which provides a broad scope for returning various formats of search responses depending on the specific implementation in the subclasses.\n\nThis class does not implement any functionality itself; it serves as a contract for all subclasses that handle search functionality. Subclasses such as `BingClient`, `DuckDuckGoClient`, and `TavilyClient` inherit from `BaseSearchClient` and implement the `search` method to interact with specific search engines. These subclasses are responsible for providing the actual logic for sending search requests, handling responses, and structuring the search results.\n\nThe `BaseSearchClient` class is crucial in this context as it standardizes the interface for search functionality, allowing the rest of the system to interact with any specific search engine implementation in a uniform way, without needing to worry about the underlying details of the API being used. Any object or module in the system that relies on search results can use `BaseSearchClient` as the reference for interacting with any subclass that implements the `search` method.\n\n**Note**: \n- The `BaseSearchClient` class is not intended to be instantiated directly. It is meant to be subclassed, and the `search` method should be implemented in those subclasses to provide the actual search functionality.\n- This class enforces the asynchronous nature of search operations, ensuring that any subclass providing the `search` method must handle asynchronous behavior."
      ],
      "code_start_line": 5,
      "code_end_line": 8,
      "params": [],
      "have_return": false,
      "code_content": "class BaseSearchClient(ABC):\n    @abstractmethod\n    async def search(self, query: str, **kwargs: Any) -> Any:\n        pass\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/bing_client.py",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py",
        "src/criticsearch/tools/search_adapter/duckduckgo_client.py/DuckDuckGoClient",
        "src/criticsearch/tools/search_adapter/tavily_client.py",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "search",
      "md_content": [
        "**search**: The function of search is to asynchronously process a search query and return the result.\n\n**parameters**: The parameters of this Function.\n· query: A string representing the search query to be executed.\n· kwargs: A variable number of additional keyword arguments, which may provide further customization or configuration for the search operation.\n\n**Code Description**: \nThe `search` function is defined as an asynchronous method, which implies that it will likely handle operations that may take time to complete, such as making network requests or querying a database. The function signature takes in two parameters: `query` and `kwargs`. \n- The `query` parameter is a required string that holds the search term or phrase the function will process.\n- The `kwargs` parameter allows for the inclusion of additional keyword arguments, which could be used for supplementary parameters such as pagination, filters, or sorting criteria in the search operation.\n\nHowever, the function body itself is currently not implemented, which means it lacks the specific logic to execute the search and return results. The `pass` statement indicates that this function is a placeholder or is intended to be overridden in a subclass or future implementation. The function is defined to return a result of type `Any`, indicating that the return type is flexible and could be adjusted based on the actual implementation.\n\n**Note**: \n- The `search` function is expected to be part of an asynchronous workflow, so it should be awaited when called in an asynchronous context.\n- The behavior and utility of the `kwargs` parameter are not defined here and would depend on the actual implementation of the method."
      ],
      "code_start_line": 7,
      "code_end_line": 8,
      "params": [
        "self",
        "query"
      ],
      "have_return": false,
      "code_content": "    async def search(self, query: str, **kwargs: Any) -> Any:\n        pass\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/search_adapter/exceptions.py": [
    {
      "type": "ClassDef",
      "name": "SearchClientError",
      "md_content": [
        "**SearchClientError**: The function of SearchClientError is to define a base exception class for errors related to the search client.\n\n**attributes**:\n· message: str - This attribute stores the error message that is associated with the exception.\n\n**Code Description**:  \nThe `SearchClientError` class is a custom exception that extends Python's built-in `Exception` class. It is used as a base class for specific error types related to the search client functionality. The class constructor (`__init__`) accepts a message parameter, which defaults to \"An error occurred in the search client.\" This message is passed to the parent `Exception` class using `super().__init__(message)`, enabling the `SearchClientError` instance to store and propagate the message to whoever handles the exception.\n\nThe class is intended to be subclassed by other specific error classes that need to indicate particular search client-related errors, such as exceeded usage limits, bad requests, or invalid API keys. In the project, we can see that multiple exceptions inherit from `SearchClientError`, such as `UsageLimitExceededError`, `BadRequestError`, `InvalidAPIKeyError`, `RatelimitException`, and `TimeoutException`. Each of these subclasses customizes the default error message to reflect a more specific error condition, but they all share the same base behavior provided by `SearchClientError`. \n\nThe subclasses inherit the core functionality of the `SearchClientError` class, while modifying the error message for clarity and relevance to the particular situation. These subclasses ensure that the search client exceptions are appropriately handled in different cases, providing clear and specific error messages to the developers working with the search client.\n\n**Note**:  \n- The `SearchClientError` class serves as a foundational class for defining more granular exception types.\n- It is important that any custom error related to the search client extend from `SearchClientError` to maintain consistency across the project.\n- The default message can be overridden when raising exceptions, but the base class guarantees that a message is always available, which helps in debugging and troubleshooting."
      ],
      "code_start_line": 4,
      "code_end_line": 6,
      "params": [],
      "have_return": false,
      "code_content": "class SearchClientError(Exception):\n    def __init__(self, message: str = \"An error occurred in the search client.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/exceptions.py/UsageLimitExceededError",
        "src/criticsearch/tools/search_adapter/exceptions.py/BadRequestError",
        "src/criticsearch/tools/search_adapter/exceptions.py/InvalidAPIKeyError",
        "src/criticsearch/tools/search_adapter/exceptions.py/RatelimitException",
        "src/criticsearch/tools/search_adapter/exceptions.py/TimeoutException"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the SearchClientError class with a specified error message.\n\n**parameters**: The parameters of this Function.\n· message: A string that represents the error message to be displayed. It defaults to \"An error occurred in the search client.\"\n\n**Code Description**: This __init__ function is a constructor for the SearchClientError class, which is likely a custom exception class used to handle errors related to a search client in the application. The function takes one optional parameter, `message`, which allows the user to specify a custom error message. If no message is provided when an instance of the class is created, the default message \"An error occurred in the search client.\" will be used. The constructor calls the `__init__` method of its superclass (presumably a built-in exception class) using `super().__init__(message)`, which initializes the base class with the provided message. This ensures that the error message is properly set up for the exception handling mechanism in Python.\n\n**Note**: It is important to provide a meaningful error message when raising this exception to facilitate debugging and error tracking. Users of this class should be aware that the default message may not always convey the specific issue encountered, so customizing the message is recommended when applicable."
      ],
      "code_start_line": 5,
      "code_end_line": 6,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"An error occurred in the search client.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "UsageLimitExceededError",
      "md_content": [
        "**UsageLimitExceededError**: The function of UsageLimitExceededError is to indicate that the usage limit for the search client has been exceeded.\n\n**attributes**:\n· message: str - This attribute stores the error message that is associated with the exception.\n\n**Code Description**: The `UsageLimitExceededError` class is a custom exception that inherits from the `SearchClientError` base class. It is specifically designed to handle scenarios where the usage limit of the search client has been surpassed. The constructor of the `UsageLimitExceededError` class accepts a single parameter, `message`, which defaults to \"Usage limit exceeded.\" This message provides a clear indication of the error condition when the exception is raised.\n\nWhen an instance of `UsageLimitExceededError` is created, it calls the constructor of its parent class, `SearchClientError`, using `super().__init__(message)`. This ensures that the error message is properly initialized and can be accessed by any exception handling mechanisms that catch this specific error.\n\nIn the context of the project, the `UsageLimitExceededError` is utilized within the `search` method of the `TavilyClient` class. When a search request is made and the server responds with a status code of 429, indicating that the usage limit has been exceeded, the `UsageLimitExceededError` is raised. This allows the error to propagate up the call stack, where it can be handled appropriately, such as logging the error and marking the search engine as unavailable.\n\nAdditionally, the `UsageLimitExceededError` is caught in the `_search_single_query` method of the `SearchAggregator` class. When this exception is encountered, it logs a warning message indicating that the engine has failed due to the usage limit being exceeded and subsequently marks the engine as unavailable. This structured approach to error handling ensures that the application can gracefully manage situations where the search client cannot fulfill requests due to usage constraints.\n\n**Note**: \n- The `UsageLimitExceededError` class is intended to be used specifically for signaling that the search client's usage limit has been reached.\n- It is essential to handle this exception in the calling code to maintain robust error management and provide meaningful feedback to users or developers regarding the state of the search client."
      ],
      "code_start_line": 9,
      "code_end_line": 11,
      "params": [],
      "have_return": false,
      "code_content": "class UsageLimitExceededError(SearchClientError):\n    def __init__(self, message: str = \"Usage limit exceeded.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query",
        "src/criticsearch/tools/search_adapter/tavily_client.py",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/exceptions.py/SearchClientError"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the UsageLimitExceededError class with a specific error message.\n\n**parameters**: The parameters of this Function.\n· message: A string that represents the error message to be displayed when the exception is raised. It defaults to \"Usage limit exceeded.\"\n\n**Code Description**: The __init__ method is a constructor for the UsageLimitExceededError class, which is a custom exception that inherits from the built-in Exception class. When an instance of UsageLimitExceededError is created, this method is called to set up the instance. The method takes one optional parameter, message, which allows the user to specify a custom error message. If no message is provided, it defaults to \"Usage limit exceeded.\" The constructor then calls the constructor of the parent class (Exception) using super().__init__(message), which initializes the base class with the provided message. This ensures that the error message is properly stored and can be accessed when the exception is raised.\n\n**Note**: It is important to provide a meaningful message when raising this exception to ensure that the context of the error is clear to the user. If the default message is used, it may not provide sufficient information about the specific situation that caused the exception."
      ],
      "code_start_line": 10,
      "code_end_line": 11,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"Usage limit exceeded.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "BadRequestError",
      "md_content": [
        "**BadRequestError**: The function of BadRequestError is to represent an exception that occurs when a bad request is made to the search client.\n\n**attributes**:\n· message: str - This attribute stores the error message that is associated with the exception. The default message is \"Bad request.\"\n\n**Code Description**:  \nThe `BadRequestError` class is a custom exception that extends the `SearchClientError` base exception class. This class is designed to handle errors that arise specifically from a bad request made to the search client. It inherits the core functionality of `SearchClientError`, which means it can propagate an error message and be caught by any exception handling mechanism designed to manage `SearchClientError` exceptions.\n\nThe constructor of the `BadRequestError` class accepts a message parameter, which has a default value of \"Bad request.\" If no message is provided, this default message will be used when raising the exception. The message is passed to the parent class `SearchClientError` using `super().__init__(message)`, ensuring that the error message is properly stored and can be accessed by the exception handler.\n\nAs a subclass of `SearchClientError`, the `BadRequestError` inherits the attributes and behaviors of its parent, but it customizes the default message to indicate that the error specifically pertains to a bad request. This helps in distinguishing it from other types of errors in the search client, such as those related to invalid API keys, rate limits, or usage limits.\n\nIn terms of functionality, the `BadRequestError` is useful for handling scenarios where the client makes a request that the search service cannot process due to an issue with the request itself (such as invalid parameters or incorrect syntax). The error message provides clarity about the nature of the issue, assisting developers in debugging and resolving the problem.\n\n**Note**:  \n- The `BadRequestError` class is intended to be raised when a bad request is made to the search client, providing a clear and specific error message.\n- This class inherits from `SearchClientError`, so it benefits from the structure and behavior defined in the base class.\n- The default message for this exception can be overridden when raising the exception, but the base class ensures that an appropriate message is always available.\n"
      ],
      "code_start_line": 14,
      "code_end_line": 16,
      "params": [],
      "have_return": false,
      "code_content": "class BadRequestError(SearchClientError):\n    def __init__(self, message: str = \"Bad request.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/exceptions.py/SearchClientError"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the BadRequestError class with a specified error message.\n\n**parameters**: The parameters of this Function.\n· message: A string that represents the error message to be associated with the BadRequestError instance. It defaults to \"Bad request.\" if no message is provided.\n\n**Code Description**: The __init__ function is a constructor for the BadRequestError class, which is likely a custom exception class used to indicate that a client has made a bad request to a server or an API. This function takes one optional parameter, message, which allows the user to specify a custom error message. If the user does not provide a message, the default value \"Bad request.\" is used. The function then calls the constructor of its superclass (presumably Exception or a subclass thereof) using super().__init__(message), which initializes the base class with the provided message. This ensures that the error message is properly set up for the exception handling mechanism in Python.\n\n**Note**: It is important to provide meaningful error messages when raising exceptions to facilitate debugging and improve the user experience. Users of this class should be aware that the message parameter is optional, but providing a specific message can help clarify the nature of the error encountered."
      ],
      "code_start_line": 15,
      "code_end_line": 16,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"Bad request.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "InvalidAPIKeyError",
      "md_content": [
        "**InvalidAPIKeyError**: The function of InvalidAPIKeyError is to define a specific exception that signals an invalid API key error.\n\n**attributes**:\n· message: str - This attribute stores the error message associated with the exception.\n\n**Code Description**:  \nThe `InvalidAPIKeyError` class is a custom exception that extends from the `SearchClientError` base exception class. It is specifically designed to handle errors related to invalid API keys when interacting with a search engine client. This class inherits the functionality of the `SearchClientError` class, ensuring that it shares the same message handling mechanism, but it customizes the error message to indicate that the error is due to an invalid API key.\n\nThe constructor of the `InvalidAPIKeyError` class accepts an optional `message` parameter that defaults to \"Invalid API key.\" If no specific message is provided when the exception is raised, this default message is used. The constructor calls the parent class's (`SearchClientError`) constructor using `super().__init__(message)`, allowing the error message to be passed to the parent class, which ensures consistent exception handling and message propagation throughout the system.\n\nThis class is primarily used within the project to signal when an API key used for making requests to a search engine is invalid. It is invoked in the `search` methods of different client classes like `BingClient` and `TavilyClient`. For example, in the case of a 401 HTTP status code (Unauthorized), the `InvalidAPIKeyError` is raised to indicate that the API key is incorrect. Once raised, it can be caught and handled appropriately by the surrounding code, such as marking the search engine as unavailable, as seen in the `SearchAggregator` class.\n\nIn the project, this exception serves as a clear and specific indicator of issues related to invalid API keys, providing a more precise understanding of the problem than more generic error messages.\n\n**Note**:  \n- The `InvalidAPIKeyError` class is a subclass of `SearchClientError`, ensuring it follows the same error-handling structure as other search client exceptions.\n- This exception should be used whenever an invalid API key is encountered in the system, providing consistency in error reporting and debugging.\n- The default message can be customized by providing a different `message` value when raising the exception, but the base message is helpful for general use cases."
      ],
      "code_start_line": 19,
      "code_end_line": 21,
      "params": [],
      "have_return": false,
      "code_content": "class InvalidAPIKeyError(SearchClientError):\n    def __init__(self, message: str = \"Invalid API key.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/bing_client.py",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient/search",
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query",
        "src/criticsearch/tools/search_adapter/tavily_client.py",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/exceptions.py/SearchClientError"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the InvalidAPIKeyError class, setting a custom error message.\n\n**parameters**:\n· message: str (default value: \"Invalid API key.\") - A string message that is used to describe the error.\n\n**Code Description**:  \nThe __init__ method in this class is responsible for initializing an instance of the InvalidAPIKeyError exception. It inherits from the built-in Exception class, and its purpose is to provide a custom error message when an invalid API key is encountered. \n\nWhen an instance of InvalidAPIKeyError is created, the method first checks if a custom message has been provided by the caller. If no message is given, it defaults to \"Invalid API key.\" This message is then passed to the parent class' constructor using `super().__init__(message)`, which ensures that the Exception class is properly initialized with the message string. This allows the InvalidAPIKeyError to carry the custom or default error message when raised.\n\n**Note**:  \n- The message parameter is optional. If not provided, the default message \"Invalid API key.\" will be used.\n- The super() function is used to call the parent class constructor (Exception) to ensure that the error message is properly handled by the base Exception class."
      ],
      "code_start_line": 20,
      "code_end_line": 21,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"Invalid API key.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "RatelimitException",
      "md_content": [
        "**RatelimitException**: The function of RatelimitException is to indicate that the rate limit for API requests has been exceeded.\n\n**attributes**:\n· message: str - This attribute stores the error message that is associated with the exception.\n\n**Code Description**: The `RatelimitException` class is a custom exception that inherits from the `SearchClientError` base class. It is specifically designed to handle scenarios where the rate limit for API requests has been exceeded. The constructor of `RatelimitException` accepts a message parameter, which defaults to \"Rate limit exceeded.\" This message is passed to the parent class `SearchClientError` using `super().__init__(message)`, ensuring that the exception carries a relevant error message when raised.\n\nIn the context of the project, `RatelimitException` is utilized within the `BingClient` and `TavilyClient` classes, which are responsible for interacting with their respective search APIs. When a request to these APIs results in a 429 HTTP status code, which signifies that the rate limit has been reached, the `RatelimitException` is raised. This allows the application to handle the situation appropriately, such as by implementing retry logic or notifying the user of the issue.\n\nThe `RatelimitException` serves as a clear indication to developers that the application has encountered a rate limiting issue, allowing for better error handling and user experience. It is part of a broader hierarchy of exceptions that extend from `SearchClientError`, which includes other specific error types like `UsageLimitExceededError` and `InvalidAPIKeyError`. Each of these exceptions provides a way to manage different error conditions that may arise while interacting with search client functionalities.\n\n**Note**: \n- It is essential to handle `RatelimitException` in the application logic to ensure that the user is informed of the rate limit issue and that appropriate measures are taken, such as retrying the request after a delay.\n- The default message can be overridden if a more specific message is required when raising the exception, but the base functionality ensures that a message is always available for debugging purposes."
      ],
      "code_start_line": 24,
      "code_end_line": 26,
      "params": [],
      "have_return": false,
      "code_content": "class RatelimitException(SearchClientError):\n    def __init__(self, message: str = \"Rate limit exceeded.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/bing_client.py",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient/search",
        "src/criticsearch/tools/search_adapter/tavily_client.py",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/exceptions.py/SearchClientError"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize a RatelimitException instance with a specific error message.\n\n**parameters**: The parameters of this Function.\n· message: A string that represents the error message to be displayed when the exception is raised. It defaults to \"Rate limit exceeded.\"\n\n**Code Description**: The __init__ method is a constructor for the RatelimitException class, which is likely a custom exception used to indicate that a rate limit has been exceeded in an application. When an instance of RatelimitException is created, it calls the constructor of its superclass (presumably Exception) using the super() function, passing the message parameter to it. This ensures that the base exception class is properly initialized with the provided message. If no message is specified when the exception is raised, it defaults to \"Rate limit exceeded,\" providing a clear indication of the error condition.\n\n**Note**: It is important to provide a meaningful message when raising this exception to ensure that the context of the error is clear to the developers or users handling the exception."
      ],
      "code_start_line": 25,
      "code_end_line": 26,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"Rate limit exceeded.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "TimeoutException",
      "md_content": [
        "**TimeoutException**: The function of TimeoutException is to represent an error that occurs when a timeout condition is encountered in the search client operations.\n\n**attributes**: The attributes of this Class.\n· message: str - This attribute stores the error message that is associated with the exception, defaulting to \"Timeout occurred.\"\n\n**Code Description**: The `TimeoutException` class is a custom exception that extends the `SearchClientError` class. It is specifically designed to handle timeout errors that may arise during the execution of search client operations. When an instance of `TimeoutException` is created, it invokes the constructor of its parent class, `SearchClientError`, passing a default message that indicates a timeout has occurred. This allows the exception to carry a meaningful message that can be used for debugging and error handling.\n\nThe `TimeoutException` class inherits all the properties and methods of the `SearchClientError` class, which serves as a base for various search client-related exceptions. By extending `SearchClientError`, `TimeoutException` ensures that it maintains a consistent structure and behavior with other exceptions in the search client domain, such as `UsageLimitExceededError`, `BadRequestError`, and others. This design promotes a clear hierarchy of exceptions, making it easier for developers to handle specific error cases effectively.\n\nIn practical terms, when a timeout occurs during a search operation, the `TimeoutException` can be raised to signal this specific issue. Developers can catch this exception in their code to implement appropriate error handling strategies, such as retrying the operation, logging the error, or notifying users of the timeout condition.\n\n**Note**: \n- It is essential to use `TimeoutException` in scenarios where a timeout is a relevant error condition, ensuring that the error handling is precise and informative.\n- The default message can be customized when raising the exception, but it is advisable to maintain clarity regarding the nature of the timeout error for effective debugging and user communication."
      ],
      "code_start_line": 29,
      "code_end_line": 31,
      "params": [],
      "have_return": false,
      "code_content": "class TimeoutException(SearchClientError):\n    def __init__(self, message: str = \"Timeout occurred.\"):\n        super().__init__(message)\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/exceptions.py/SearchClientError"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the TimeoutException class with a specific error message.\n\n**parameters**: The parameters of this Function.\n· message: A string that represents the error message to be displayed when the exception is raised. It defaults to \"Timeout occurred.\" if no message is provided.\n\n**Code Description**: The __init__ function is a constructor for the TimeoutException class, which is likely a custom exception used to indicate that a timeout has occurred in a process or operation. This function takes one optional parameter, `message`, which allows the user to specify a custom error message. If the user does not provide a message, the default message \"Timeout occurred.\" will be used. The constructor calls the superclass's __init__ method using `super().__init__(message)`, which ensures that the base class (likely Exception or a subclass thereof) is properly initialized with the provided message. This allows the TimeoutException to inherit all the properties and methods of the base exception class, enabling it to be used effectively in exception handling.\n\n**Note**: It is important to provide a meaningful message when raising this exception to ensure that the context of the timeout is clear to the developers or users handling the exception."
      ],
      "code_start_line": 30,
      "code_end_line": 31,
      "params": [
        "self",
        "message"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, message: str = \"Timeout occurred.\"):\n        super().__init__(message)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    }
  ],
  "src/criticsearch/tools/search_adapter/tavily_client.py": [
    {
      "type": "ClassDef",
      "name": "TavilyClient",
      "md_content": [
        "**TavilyClient**: The function of TavilyClient is to serve as an API client for interacting with the Tavily search service.\n\n**attributes**: The attributes of this Class.\n· base_url: str - This attribute stores the base URL for the Tavily API.\n· _api_key: str - This attribute holds the API key required for authenticating requests to the Tavily API.\n· headers: dict - This attribute contains the headers that will be sent with each API request, specifically setting the content type to JSON.\n\n**Code Description**: The TavilyClient class inherits from the BaseSearchClient class, establishing itself as a specific implementation for interacting with the Tavily API. Upon initialization, it sets the base URL for the Tavily API and stores the provided API key for use in subsequent requests. The class is designed to facilitate asynchronous search operations through the `search` method, which allows users to query the Tavily API with various parameters.\n\nThe `search` method is decorated with a retry mechanism, which attempts to resend the request up to five times in case of a rate limit exception (RatelimitException). This method accepts several parameters: `query`, `search_depth`, `topic`, `days`, and `max_results`, allowing for flexible search configurations. The method constructs a JSON payload containing these parameters along with the API key and sends an asynchronous POST request to the Tavily API's search endpoint.\n\nUpon receiving a response, the method checks the status code to determine the outcome of the request. A successful response (HTTP status code 200) results in the parsing of the JSON response into a SearchResponse object. If the response indicates a rate limit has been exceeded (HTTP status code 429), it raises a UsageLimitExceededError or RatelimitException based on the details provided in the response. An unauthorized access attempt (HTTP status code 401) raises an InvalidAPIKeyError. For any other unexpected status codes, the method returns a SearchResponse object containing an error message.\n\nThe TavilyClient is utilized within the SearchAggregator class, where it is instantiated if a valid Tavily API key is available. This integration allows the SearchAggregator to manage multiple search clients, including TavilyClient and BingClient, enabling it to perform searches across different services seamlessly.\n\n**Note**: It is essential to ensure that the API key provided to the TavilyClient is valid and that the application handles exceptions appropriately, particularly those related to rate limits and unauthorized access. Proper error handling will enhance the robustness of the application when interacting with the Tavily API.\n\nA possible appearance of the code's return value from the `search` method could be:\n```json\n{\n    \"query\": \"example search\",\n    \"results\": [\n        {\n            \"title\": \"Example Result 1\",\n            \"link\": \"https://example.com/result1\",\n            \"snippet\": \"This is a snippet of the first result.\"\n        },\n        {\n            \"title\": \"Example Result 2\",\n            \"link\": \"https://example.com/result2\",\n            \"snippet\": \"This is a snippet of the second result.\"\n        }\n    ],\n    \"error_message\": null\n}\n```"
      ],
      "code_start_line": 19,
      "code_end_line": 88,
      "params": [],
      "have_return": true,
      "code_content": "class TavilyClient(BaseSearchClient):\n    \"\"\"\n    Tavily API client class.\n    \"\"\"\n\n    def __init__(self, api_key: str):\n        self.base_url = \"https://api.tavily.com\"\n        self._api_key = api_key\n        self.headers = {\n            \"Content-Type\": \"application/json\",\n        }\n\n    @retry(\n        stop=stop_after_attempt(5),  # 重试最多5次\n        wait=wait_exponential(multiplier=1, min=4, max=30)\n        + wait_random(min=1, max=5),  # 指数退避 + 随机抖动\n        retry=retry_if_exception_type(RatelimitException),\n    )\n    async def search(\n        self,\n        query: str,\n        search_depth: Literal[\"basic\", \"advanced\"] = \"basic\",\n        topic: Literal[\"general\", \"news\"] = \"general\",\n        days: int = 7,\n        max_results: int = 10,\n    ) -> SearchResponse:\n        \"\"\"\n        异步搜索方法\n        \"\"\"\n\n        logger.debug(f\"Attempting to use engine 'Tavily' for query '{query}'. \")\n\n        # 发起异步请求\n        data = {\n            \"query\": query,\n            \"search_depth\": search_depth,\n            \"topic\": topic,\n            \"days\": days,\n            \"max_results\": max_results,\n            \"api_key\": self._api_key,\n        }\n\n        async with httpx.AsyncClient(timeout=30, http2=True) as client:\n            response = await client.post(\n                self.base_url + \"/search\", json=data, headers=self.headers\n            )\n\n        if response.status_code == 200:\n            return SearchResponse.model_validate(response.json())\n        elif response.status_code == 429:\n            try:\n                detail = response.json().get(\"detail\", {}).get(\"error\")\n                if detail:\n                    raise UsageLimitExceededError(detail)  # 抛出后直接传播，不被捕获\n            except UsageLimitExceededError:\n                raise  # 直接传播 UsageLimitExceededError，避免被后续捕获\n            except Exception as e:\n                # 捕获其他异常并记录日志\n                logger.error(f\"Failed to process 429 response: {e}\")\n                logger.error(f\"Response content: {response.text}\")\n                raise RatelimitException()  # 抛出通用限流异常\n\n            raise RatelimitException()\n        elif response.status_code == 401:\n            raise InvalidAPIKeyError()\n        else:\n            return SearchResponse(\n                query=query,\n                error_message=f\"Unexpected status code: {response.status_code}. Response: {response.text}\",\n            )\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/__init__"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/base_search_client.py/BaseSearchClient",
        "src/criticsearch/tools/search_adapter/exceptions.py/RatelimitException"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the TavilyClient object with the required API key and configure default settings for the instance.\n\n**parameters**: The parameters of this Function.\n- api_key: A string representing the API key used for authentication with the Tavily API.\n\n**Code Description**: The `__init__` method is the constructor of the `TavilyClient` class. It initializes an instance of the class by setting up default values and configurations necessary for interacting with the Tavily API.\n  \n1. **self.base_url**: This attribute is set to the string \"https://api.tavily.com\", which represents the base URL of the Tavily API. It is used as the root URL for all API requests made by this client.\n  \n2. **self._api_key**: This attribute is initialized with the value of the `api_key` parameter. It stores the API key provided when the instance of the client is created. This key will likely be used in API requests for authentication purposes.\n\n3. **self.headers**: A dictionary is created with the key `\"Content-Type\"` set to `\"application/json\"`. This header is typically included in HTTP requests to specify that the body of the request is in JSON format. It ensures that the client interacts with the API in a manner that is compatible with its expected input format.\n\nThe method does not return any value. It simply prepares the object with the necessary attributes to interact with the Tavily API.\n\n**Note**: \n- The `api_key` is essential for authentication with the Tavily API and must be provided when creating an instance of the `TavilyClient`.\n- The `base_url` and headers are set to default values, which can be further customized or extended by other methods in the `TavilyClient` class for specific API requests."
      ],
      "code_start_line": 24,
      "code_end_line": 29,
      "params": [
        "self",
        "api_key"
      ],
      "have_return": false,
      "code_content": "    def __init__(self, api_key: str):\n        self.base_url = \"https://api.tavily.com\"\n        self._api_key = api_key\n        self.headers = {\n            \"Content-Type\": \"application/json\",\n        }\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "search",
      "md_content": [
        "## Function: `search`\n\n### Overview\nThe `search` function is an asynchronous method designed to perform a search query using the Tavily engine. It allows users to specify search parameters, such as the query string, search depth, topic, date range, and maximum number of results. The function interacts with an API endpoint and returns a structured response encapsulated in the `SearchResponse` class. In case of errors such as rate limiting or invalid API keys, appropriate exceptions are raised.\n\n### Parameters\n- **query** (`str`): The search query string to be used in the search request. This parameter is required.\n- **search_depth** (`Literal[\"basic\", \"advanced\"]`): The depth of the search. The default value is `\"basic\"`, and the available options are:\n  - `\"basic\"`: A standard search depth.\n  - `\"advanced\"`: A more detailed search.\n  \n- **topic** (`Literal[\"general\", \"news\"]`): The topic of the search query. The default value is `\"general\"`, and the options available are:\n  - `\"general\"`: General search results.\n  - `\"news\"`: Results specifically related to news topics.\n  \n- **days** (`int`): The time frame in days for filtering results. The default value is `7`, meaning results from the past 7 days will be included.\n  \n- **max_results** (`int`): The maximum number of search results to return. The default value is `10`, and it can be adjusted as needed.\n\n### Returns\n- **SearchResponse**: The function returns an instance of the `SearchResponse` class, which contains the results of the search query. The `SearchResponse` includes the query string, a list of search results, and any error messages encountered during the process.\n\n### Exceptions\nThe function raises the following exceptions in case of errors:\n- **UsageLimitExceededError**: Raised when the API usage limit is exceeded. This is specifically handled when a `429` status code is returned.\n- **RatelimitException**: Raised when a rate-limiting issue occurs, typically in the event of frequent API requests or when an exception other than `UsageLimitExceededError` is encountered due to rate-limiting issues.\n- **InvalidAPIKeyError**: Raised when the provided API key is invalid, typically corresponding to a `401` status code.\n\n### Behavior\n1. The function sends an asynchronous POST request to the Tavily search API with the specified parameters.\n2. If the request is successful (status code `200`), the function returns a `SearchResponse` object containing the search results.\n3. If the API response returns a `429` status code (rate limiting), the function checks if the response contains a usage limit error. If found, it raises a `UsageLimitExceededError`. If any other error occurs while handling the response, a `RatelimitException` is raised.\n4. If the API response returns a `401` status code (authentication error), the function raises an `InvalidAPIKeyError`.\n5. If the status code is not `200`, `429`, or `401`, the function returns a `SearchResponse` with an error message indicating an unexpected status code.\n\n### Usage Example\n```python\ntavily_client = TavilyClient(api_key=\"your_api_key\")\nresponse = await tavily_client.search(query=\"Python programming\", search_depth=\"advanced\", topic=\"general\", days=7, max_results=5)\nprint(response.ser_model())\n```\n\n### Notes\n- The `SearchResponse` class is used to structure the response from the search API, which includes the query, results, and any error messages.\n- The `UsageLimitExceededError` is raised when the search client has exceeded the API usage limits."
      ],
      "code_start_line": 37,
      "code_end_line": 88,
      "params": [
        "self",
        "query",
        "search_depth",
        "topic",
        "days",
        "max_results"
      ],
      "have_return": true,
      "code_content": "    async def search(\n        self,\n        query: str,\n        search_depth: Literal[\"basic\", \"advanced\"] = \"basic\",\n        topic: Literal[\"general\", \"news\"] = \"general\",\n        days: int = 7,\n        max_results: int = 10,\n    ) -> SearchResponse:\n        \"\"\"\n        异步搜索方法\n        \"\"\"\n\n        logger.debug(f\"Attempting to use engine 'Tavily' for query '{query}'. \")\n\n        # 发起异步请求\n        data = {\n            \"query\": query,\n            \"search_depth\": search_depth,\n            \"topic\": topic,\n            \"days\": days,\n            \"max_results\": max_results,\n            \"api_key\": self._api_key,\n        }\n\n        async with httpx.AsyncClient(timeout=30, http2=True) as client:\n            response = await client.post(\n                self.base_url + \"/search\", json=data, headers=self.headers\n            )\n\n        if response.status_code == 200:\n            return SearchResponse.model_validate(response.json())\n        elif response.status_code == 429:\n            try:\n                detail = response.json().get(\"detail\", {}).get(\"error\")\n                if detail:\n                    raise UsageLimitExceededError(detail)  # 抛出后直接传播，不被捕获\n            except UsageLimitExceededError:\n                raise  # 直接传播 UsageLimitExceededError，避免被后续捕获\n            except Exception as e:\n                # 捕获其他异常并记录日志\n                logger.error(f\"Failed to process 429 response: {e}\")\n                logger.error(f\"Response content: {response.text}\")\n                raise RatelimitException()  # 抛出通用限流异常\n\n            raise RatelimitException()\n        elif response.status_code == 401:\n            raise InvalidAPIKeyError()\n        else:\n            return SearchResponse(\n                query=query,\n                error_message=f\"Unexpected status code: {response.status_code}. Response: {response.text}\",\n            )\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse",
        "src/criticsearch/tools/search_adapter/exceptions.py/UsageLimitExceededError",
        "src/criticsearch/tools/search_adapter/exceptions.py/InvalidAPIKeyError",
        "src/criticsearch/tools/search_adapter/exceptions.py/RatelimitException"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false
      ]
    }
  ],
  "src/criticsearch/tools/search_adapter/search_aggregator.py": [
    {
      "type": "ClassDef",
      "name": "SearchAggregator",
      "md_content": [
        "**SearchAggregator**: The function of SearchAggregator is to aggregate and execute search queries across multiple search engines while handling various error conditions and API limitations.\n\n**attributes**:\n- clients: A dictionary holding instances of different search engine clients, such as TavilyClient and BingClient, which are used to execute search queries.\n- available_clients: A set that tracks the search engines that are currently available for use, excluding any that are marked as unavailable due to errors or limitations.\n\n**Code Description**:  \nThe `SearchAggregator` class is responsible for managing multiple search engines and executing queries across them. Upon initialization, it checks for API keys for both Tavily and Bing search engines from the settings. If valid keys are found, it initializes corresponding clients for these engines and stores them in the `clients` attribute. The `available_clients` set is then populated with the keys (names) of the initialized clients. \n\nThe class includes the following key methods:\n\n- `mark_engine_unavailable(engine: str)`: This method marks a specified search engine as unavailable by removing it from the `available_clients` set. This is used when an error or limitation (such as an invalid API key, retry limit reached, or usage limit exceeded) occurs with a particular search engine.\n  \n- `_search_single_query(query: str, engines: List[str])`: This asynchronous method attempts to search a given query across the provided list of search engines. For each engine, it checks if the engine is available and then tries to perform the search. If the search is successful, the result is returned. If an exception occurs, the engine is marked as unavailable, and the method moves on to the next engine in the list. Various exceptions are handled, including `RetryError`, `InvalidAPIKeyError`, and `UsageLimitExceededError`.\n\n- `search(query: List[str])`: This is the primary method that allows the user to perform searches using a list of queries. It first checks if there are any available search engines. If none are available, it raises an exception. It then creates asynchronous tasks for each query and executes them concurrently. The method returns the aggregated search results as a list of responses.\n\nThe `SearchAggregator` class is used in other components of the project to facilitate search functionality. For instance, in `BaseAgent`, it is instantiated and its search method is called to perform searches with specific queries. This enables the broader application to conduct searches in a robust and fault-tolerant manner by leveraging multiple search engines. Additionally, in the main entry point (`src/criticsearch/tools/search_adapter/__main__.py/main`), an asynchronous search is triggered, and the results are printed.\n\n**Note**:  \n- Ensure that valid API keys for the search engines (Tavily and Bing) are provided in the settings, as the functionality depends on these keys to initialize the respective clients.\n- The `search` method handles multiple queries simultaneously, making it efficient in handling concurrent searches.\n- If all search engines are marked unavailable, the method returns a `SearchResponse` indicating the failure to execute the search, along with an appropriate error message.\n  \n**Output Example**:\nA possible return value of the `search` method might look like this:\n\n```json\n{\n  \"responses\": [\n    {\n      \"query\": \"Who is Leo Messi?\",\n      \"results\": [\n        {\n          \"title\": \"Lionel Messi - Wikipedia\",\n          \"url\": \"https://en.wikipedia.org/wiki/Lionel_Messi\",\n          \"snippet\": \"Lionel Andrés Messi is an Argentine professional footballer widely regarded as one of the greatest players of all time.\"\n        }\n      ]\n    }\n  ]\n}\n```"
      ],
      "code_start_line": 14,
      "code_end_line": 97,
      "params": [],
      "have_return": true,
      "code_content": "class SearchAggregator:\n    def __init__(self):\n        self.clients: Dict[str, TavilyClient | BingClient] = {}\n\n        # 如果 Tavily 的 API key 存在，初始化客户端\n        tavily_api_key = settings.tavily.api_key\n        if tavily_api_key:\n            self.clients[\"tavily\"] = TavilyClient(tavily_api_key)\n\n        # 如果 Bing 的 API key 存在，初始化客户端\n        bing_api_key = settings.search_engine.bing.api_key\n        if bing_api_key:\n            self.clients[\"bing\"] = BingClient(bing_api_key)\n\n        self.available_clients = set(self.clients.keys())\n\n    def mark_engine_unavailable(self, engine: str):\n        \"\"\"\n        Mark a specific search engine as unavailable.\n\n        Args:\n            engine (str): The name of the engine to mark as unavailable.\n        \"\"\"\n        if engine in self.available_clients:\n            self.available_clients.remove(engine)\n\n    async def _search_single_query(\n        self, query: str, engines: List[str]\n    ) -> SearchResponse:\n        for engine in engines:\n            if engine in self.available_clients:\n                try:\n                    # Call the asynchronous search method for the specified engine\n                    result = await self.clients[engine].search(query)\n                    logger.info(f\"{result.model_dump()}\")\n                    return result\n                except RetryError:\n                    logger.warning(\n                        f\"Engine '{engine}' for query: {query} failed after multiple retries. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except InvalidAPIKeyError:\n                    logger.error(\n                        f\"Engine '{engine}' for query: {query} failed because of wrong api key. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except UsageLimitExceededError:\n                    logger.warning(\n                        f\"Engine '{engine}' for query: {query} failed because of usage limit exceeded. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except Exception:\n                    logger.exception(\n                        f\"Engine '{engine}' encountered error. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n\n        logger.error(\"All specified search engines are unavailable.\")\n        return SearchResponse(\n            query=query,\n            error_message=\"Search failed: No available search engines for this query.\",\n        )\n\n    async def search(self, query: List[str]) -> str:\n        \"\"\"\n        Performs a search using the provided query.\n        Supports various search techniques using special syntax.\n\n        Args:\n            query (List[str]): A list of search queries.\n        \"\"\"\n        # Get the list of currently available search engines\n        engines = list(self.available_clients)\n        if not engines:\n            raise ValueError(\"No available engines to perform the search.\")\n\n        # Create tasks for concurrent search\n        tasks = [self._search_single_query(q, engines) for q in query]\n\n        # Execute all tasks and gather the responses\n        responses = await gather(*tasks)\n\n        # Return the search responses as a dictionary\n        return SearchResponseList(responses=responses).model_dump()  # type: ignore\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py",
        "src/criticsearch/base_agent.py/BaseAgent/__init__",
        "src/criticsearch/tools/__init__.py",
        "src/criticsearch/tools/search_adapter/__init__.py",
        "src/criticsearch/tools/search_adapter/__main__.py",
        "src/criticsearch/tools/search_adapter/__main__.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize the SearchAggregator class, setting up the necessary search clients based on available API keys.\n\n**parameters**: The parameters of this Function.\n· None\n\n**Code Description**: The __init__ method is the constructor for the SearchAggregator class. It initializes an empty dictionary named `clients`, which is intended to hold instances of search clients that can be used for executing search queries. The method first checks for the presence of an API key for the Tavily search service by accessing `settings.tavily.api_key`. If a valid API key is found, an instance of the TavilyClient is created and added to the `clients` dictionary with the key \"tavily\". \n\nSimilarly, the method checks for the Bing search service API key using `settings.search_engine.bing.api_key`. If this API key is available, an instance of the BingClient is created and added to the `clients` dictionary with the key \"bing\". \n\nAfter initializing the clients, the method creates a set called `available_clients`, which contains the keys of the clients that have been successfully instantiated. This allows the SearchAggregator to keep track of which search clients are available for use.\n\nThe SearchAggregator class is designed to manage multiple search clients, enabling it to perform searches across different services. By initializing the clients in the constructor, the class ensures that it can leverage the functionalities of both TavilyClient and BingClient, provided that the necessary API keys are available. This design promotes flexibility and extensibility, allowing for easy integration of additional search clients in the future.\n\n**Note**: It is important to ensure that the API keys for both Tavily and Bing are correctly configured in the settings. If the keys are missing or invalid, the corresponding clients will not be initialized, which may affect the functionality of the SearchAggregator. Proper error handling should be implemented when using the SearchAggregator to manage search requests."
      ],
      "code_start_line": 15,
      "code_end_line": 28,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self):\n        self.clients: Dict[str, TavilyClient | BingClient] = {}\n\n        # 如果 Tavily 的 API key 存在，初始化客户端\n        tavily_api_key = settings.tavily.api_key\n        if tavily_api_key:\n            self.clients[\"tavily\"] = TavilyClient(tavily_api_key)\n\n        # 如果 Bing 的 API key 存在，初始化客户端\n        bing_api_key = settings.search_engine.bing.api_key\n        if bing_api_key:\n            self.clients[\"bing\"] = BingClient(bing_api_key)\n\n        self.available_clients = set(self.clients.keys())\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient"
      ],
      "special_reference_type": [
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "mark_engine_unavailable",
      "md_content": [
        "**mark_engine_unavailable**: The function of mark_engine_unavailable is to mark a specific search engine as unavailable.\n\n**parameters**:\n· engine: str - The name of the engine to mark as unavailable.\n\n**Code Description**:  \nThe `mark_engine_unavailable` method is part of a class and is responsible for updating the status of a specified search engine by marking it as unavailable. This is achieved by removing the engine's name from the `available_clients` collection. The parameter `engine` is expected to be a string, which represents the name of the search engine that needs to be marked as unavailable.\n\nIn terms of its usage, this function is typically called within error-handling blocks. Specifically, it is invoked whenever an exception is raised during a search operation, indicating that a particular engine is no longer functional for the query being processed. The method ensures that once an engine fails due to errors like retries, invalid API keys, or usage limits, it is effectively removed from the list of available search engines, preventing any further attempts to use that engine in future queries.\n\n**Note**:  \n- The `mark_engine_unavailable` function operates by directly modifying the `available_clients` list. Therefore, it is essential that `available_clients` is a mutable collection that supports the `remove` operation, like a list or set.\n- The engine's unavailability is handled automatically through exception handling in related functions (like `_search_single_query`), ensuring that engines that fail during the search process are excluded from subsequent attempts. \n- It is important to note that this function does not handle the re-inclusion of the engine once it has been marked as unavailable; this would need to be managed separately if required."
      ],
      "code_start_line": 30,
      "code_end_line": 38,
      "params": [
        "self",
        "engine"
      ],
      "have_return": false,
      "code_content": "    def mark_engine_unavailable(self, engine: str):\n        \"\"\"\n        Mark a specific search engine as unavailable.\n\n        Args:\n            engine (str): The name of the engine to mark as unavailable.\n        \"\"\"\n        if engine in self.available_clients:\n            self.available_clients.remove(engine)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "_search_single_query",
      "md_content": [
        "**_search_single_query**: The function of _search_single_query is to perform an asynchronous search query using specified search engines and return the results encapsulated in a SearchResponse object.\n\n**parameters**: The parameters of this Function.\n· query: str - A string representing the user's search query. This parameter cannot be empty.\n· engines: List[str] - A list of search engine names that are available for performing the search.\n\n**Code Description**: The `_search_single_query` function is an asynchronous method designed to execute a search query against a list of specified search engines. It iterates through each engine in the provided `engines` list and checks if the engine is available in the `available_clients` collection. If the engine is available, it attempts to call the asynchronous `search` method of the corresponding client.\n\nThe function handles various exceptions that may arise during the search process:\n- If a `RetryError` occurs, it logs a warning indicating that the engine has failed after multiple retries and marks the engine as unavailable using the `mark_engine_unavailable` method.\n- If an `InvalidAPIKeyError` is raised, it logs an error message indicating that the search engine's API key is invalid and marks the engine as unavailable.\n- If a `UsageLimitExceededError` is encountered, it logs a warning about the usage limit being exceeded and marks the engine as unavailable.\n- For any other exceptions, it logs the exception details and marks the engine as unavailable.\n\nIf all specified search engines are unavailable, the function logs an error message and returns a `SearchResponse` object containing the original query and an error message indicating that no available search engines could fulfill the request.\n\nThis function is called by the `search` method of the `SearchAggregator` class. The `search` method gathers a list of currently available search engines and creates tasks for concurrent execution of `_search_single_query` for each query in the provided list. The results from these tasks are then collected and returned as a structured response.\n\n**Note**: It is essential to ensure that the engines passed to this function are valid and that the `available_clients` collection is properly maintained to reflect the current state of search engines. The function does not handle the re-inclusion of engines marked as unavailable; this must be managed separately if required.\n\n**Output Example**: A possible return value of the `_search_single_query` function could be a `SearchResponse` object structured as follows:\n```python\nSearchResponse(\n    query=\"latest technology news\",\n    results=[\n        SearchResult(title=\"Tech Innovations\", url=\"https://example.com/tech-innovations\", content=\"Explore the latest in technology.\"),\n        SearchResult(title=\"Gadget Reviews\", url=\"https://example.com/gadget-reviews\", content=\"Read reviews on the newest gadgets.\")\n    ],\n    error_message=None\n)\n```"
      ],
      "code_start_line": 40,
      "code_end_line": 75,
      "params": [
        "self",
        "query",
        "engines"
      ],
      "have_return": true,
      "code_content": "    async def _search_single_query(\n        self, query: str, engines: List[str]\n    ) -> SearchResponse:\n        for engine in engines:\n            if engine in self.available_clients:\n                try:\n                    # Call the asynchronous search method for the specified engine\n                    result = await self.clients[engine].search(query)\n                    logger.info(f\"{result.model_dump()}\")\n                    return result\n                except RetryError:\n                    logger.warning(\n                        f\"Engine '{engine}' for query: {query} failed after multiple retries. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except InvalidAPIKeyError:\n                    logger.error(\n                        f\"Engine '{engine}' for query: {query} failed because of wrong api key. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except UsageLimitExceededError:\n                    logger.warning(\n                        f\"Engine '{engine}' for query: {query} failed because of usage limit exceeded. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n                except Exception:\n                    logger.exception(\n                        f\"Engine '{engine}' encountered error. Marking as unavailable.\"\n                    )\n                    self.mark_engine_unavailable(engine)\n\n        logger.error(\"All specified search engines are unavailable.\")\n        return SearchResponse(\n            query=query,\n            error_message=\"Search failed: No available search engines for this query.\",\n        )\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/search"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResponse",
        "src/criticsearch/tools/search_adapter/bing_client.py/BingClient/search",
        "src/criticsearch/tools/search_adapter/exceptions.py/UsageLimitExceededError",
        "src/criticsearch/tools/search_adapter/exceptions.py/InvalidAPIKeyError",
        "src/criticsearch/tools/search_adapter/tavily_client.py/TavilyClient/search",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/mark_engine_unavailable"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "search",
      "md_content": [
        "**search**: The function of search is to perform a search using the provided query and return the results as a serialized response.\n\n**parameters**: The parameters of this Function.\n· query: List[str] - A list of search queries that the user wants to search for.\n\n**Code Description**: The `search` method is an asynchronous function designed to execute multiple search queries concurrently using available search engines. It takes a list of search queries as input and returns a serialized string representation of the search results.\n\nThe method begins by retrieving the list of currently available search engines from the `available_clients` attribute. If there are no available engines, it raises a `ValueError`, indicating that the search cannot be performed. This ensures that the function does not attempt to execute a search when there are no resources to handle it.\n\nNext, the method creates a list of tasks, where each task corresponds to a single search query. This is done by calling the `_search_single_query` method for each query in the provided list, passing the list of available engines to it. The `_search_single_query` method is responsible for executing the search against each engine and returning the results encapsulated in a `SearchResponse` object.\n\nOnce the tasks are created, the method uses the `gather` function from the `asyncio` library to execute all the search tasks concurrently. This allows for efficient handling of multiple queries, as it does not block the execution while waiting for each individual search to complete.\n\nAfter all tasks are executed, the method collects the responses and constructs an instance of `SearchResponseList`, which is designed to hold and serialize the search results. The `model_dump()` method of `SearchResponseList` is called to generate a formatted string representation of the results, ensuring that any duplicate content across the responses is removed.\n\nThe `search` method is called by various components in the project, including the `search_and_browse` method in the `BaseAgent` class and the `main` function in the `__main__.py` module. In `search_and_browse`, it is invoked to handle user prompts for search queries, while in `main`, it demonstrates a simple use case of performing a search for a specific query.\n\n**Note**: It is important to ensure that the search engines are properly configured and available before calling this method. The method handles the serialization of results, ensuring that duplicates are filtered out, which enhances the relevance of the returned data.\n\n**Output Example**: A possible return value of the `search` function could be a serialized string representing the search results, structured as follows:\n```\n{\n  \"results\": [\n    {\n      \"title\": \"Introduction to Python\",\n      \"url\": \"https://example.com/python\",\n      \"content\": \"Python is a high-level programming language.\"\n    },\n    {\n      \"title\": \"Python Tutorials\",\n      \"url\": \"https://example.com/tutorials\",\n      \"content\": \"Learn Python programming with these tutorials.\"\n    }\n  ],\n  \"summary\": {\n    \"total_results\": 5,\n    \"unique_results\": 3,\n    \"duplicates_removed\": 2\n  }\n}\n``` \nThis output illustrates the results of the search queries, including a summary of the total results and the number of unique results returned."
      ],
      "code_start_line": 77,
      "code_end_line": 97,
      "params": [
        "self",
        "query"
      ],
      "have_return": true,
      "code_content": "    async def search(self, query: List[str]) -> str:\n        \"\"\"\n        Performs a search using the provided query.\n        Supports various search techniques using special syntax.\n\n        Args:\n            query (List[str]): A list of search queries.\n        \"\"\"\n        # Get the list of currently available search engines\n        engines = list(self.available_clients)\n        if not engines:\n            raise ValueError(\"No available engines to perform the search.\")\n\n        # Create tasks for concurrent search\n        tasks = [self._search_single_query(q, engines) for q in query]\n\n        # Execute all tasks and gather the responses\n        responses = await gather(*tasks)\n\n        # Return the search responses as a dictionary\n        return SearchResponseList(responses=responses).model_dump()  # type: ignore\n",
      "name_column": 14,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "src/criticsearch/base_agent.py/BaseAgent/__init__",
        "src/criticsearch/base_agent.py/BaseAgent/search_and_browse",
        "src/criticsearch/tools/search_adapter/__main__.py/main"
      ],
      "reference_who": [
        "src/criticsearch/tools/search_adapter/models.py/SearchResponseList",
        "src/criticsearch/tools/search_adapter/search_aggregator.py/SearchAggregator/_search_single_query"
      ],
      "special_reference_type": [
        false,
        false
      ]
    }
  ]
}